{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9941bb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\git\\\\ai_medical_agent'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92e33809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08f43e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\git\\\\ai_medical_agent'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "40a4a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d18ea9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(pdf_path):\n",
    "    loader = DirectoryLoader(pdf_path, glob = \"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5a956a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "16aa5ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 0, 'page_label': '1'}, page_content=''),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 1, 'page_label': '2'}, page_content='Andriy Burkov\\nThe Hundred-Page Machine Learning Book'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 2, 'page_label': '3'}, page_content='МАШ ИННОЕ ОБУЧЕНИЕ \\nАндрей Бурков\\nбез лишних слов\\n2020'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 3, 'page_label': '4'}, page_content='ББК 32.813\\nУДК 004.8\\nБ91 \\n\\t Бурков\\tАндрей\\nБ91   Машинное обучение без лишних слов. — СПб.: Питер, 2020. — 192 с.: ил. — (Се-\\nрия «Библиотека программиста»).\\n ISBN 978-5-4461-1560-0\\nВсе, что вам действительно нужно знать о машинном обучении, может уместиться на паре сотен \\nстраниц.\\nНачнем с простой истины: машины не учатся. Типичное машинное обучение заключается в по-\\nиске математической формулы, которая при применении к набору входных данных (называемых \\nобучающими данными) даст желаемые результаты.\\nАндрей Бурков постарался дать все необходимое, чтобы каждый мог стать отличным совре -\\nменным аналитиком или специалистом по машинному обучению. То, что удалось вместить в пару \\nсотен страниц, в других книгах растянуто на тысячи. Типичные книги по машинному обучению \\nконсервативны и академичны, здесь же упор сделан на алгоритмах и методах, которые пригодятся \\nв повседневной работе.\\n16+ (В соответствии с Федеральным законом от 29 декабря 2010 г. № 436-ФЗ.)\\n ББК 32.813\\n УДК 004.8\\nПрава на издание получены по соглашению с Andriy Burkov. Все права защищены. Никакая часть данной книги \\nне может быть воспроизведена в какой бы то ни было форме без письменного разрешения владельцев автор -\\nских прав.\\nИнформация, содержащаяся в данной книге, получена из источников, рассматриваемых издательством как на-\\nдежные. Тем не менее, имея в виду возможные человеческие или технические ошибки, издательство не может \\nгарантировать абсолютную точность и полноту приводимых сведений и не несет ответственности за возможные \\nошибки, связанные с использованием книги. Издательство не несет ответственности за доступность матери -\\nалов, ссылки на которые вы можете найти в этой книге. На момент подготовки книги к изданию все ссылки на \\nинтернет-ресурсы были действующими.\\nISBN 978-1999579500 англ. © Andriy Burkov, 2019\\nISBN 978-5-4461-1560-0 © Перевод на русский язык ООО Издательство «Питер», 2020\\n ©  Издание на русском языке, оформление ООО Издательство «Питер», \\n2020\\n © Серия «Библиотека программиста», 2020'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 4, 'page_label': '5'}, page_content='Оглавление\\nПредисловие к русскому изданию ....................................................................10\\nПредисловие из оригинального издания ..........................................................13\\nВступление .............................................................................................................15\\nКому адресована эта книга ...................................................................................16\\nОт издательства ...................................................................................................17\\nГлава 1. Введение ....................................................................................................18\\n1.1. Что такое машинное обучение ....................................................................... 18\\n1.2. Типы обучения .............................................................................................. 18\\n1.3. Как работает обучение с учителем ................................................................20\\n1.4. Почему модель способна работать с новыми данными ...................................25\\nГлава 2. Обозначения и определения ....................................................................... 27\\n2.1. Обозначения ..................................................................................................27\\n2.2. Случайная величина ......................................................................................34\\n2.3. Несмещенные оценки .................................................................................... 37\\n2.4. Правило Байеса ............................................................................................. 37\\n2.5. Оценка параметров ........................................................................................ 38\\n2.6. Параметры и гиперпараметры ....................................................................... 39\\n2.7. Классификация и регрессия ...........................................................................39\\n2.8. Обучение на основе моделей и на основе примеров ...................................... 40\\n2.9. Поверхностное и глубокое обучение ..............................................................41\\nГлава 3. Фундаментальные алгоритмы .....................................................................42\\n3.1. Линейная регрессия ....................................................................................... 42\\n3.2. Логистическая регрессия ............................................................................... 46\\n3.3. Обучение дерева решений ............................................................................. 49'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 5, 'page_label': '6'}, page_content='6   Оглавление\\n3.4. Метод опорных векторов ............................................................................... 53\\n3.5. Метод k ближайших соседей ..........................................................................57\\nГлава 4. Анатомия алгоритмов обучения ..................................................................59\\n4.1. Строительные блоки алгоритмов обучения .................................................... 59\\n4.2. Градиентный спуск ........................................................................................ 60\\n4.3. Как работают инженеры, занимающиеся машинным обучением .....................66\\n4.4. Особенности алгоритмов обучения ................................................................ 67\\nГлава 5. Практические основы ................................................................................. 69\\n5.1. Проектирование признаков ............................................................................ 69\\n5.2. Выбор алгоритма обучения ............................................................................ 74\\n5.3. Три набора .................................................................................................... 76\\n5.4. Недообучение и переобучение ....................................................................... 78\\n5.5. Регуляризация ...............................................................................................81\\n5.6. Оценка эффективности модели ......................................................................82\\n5.7. Настройка гиперпараметров ...........................................................................88\\nГлава 6. Нейронные сети и глубокое обучение .........................................................91\\n6.1. Нейронные сети ............................................................................................. 91\\n6.2. Глубокое обучение ........................................................................................ 95\\nГлава 7. Проблемы и решения ................................................................................ 110\\n7.1. Ядерная регрессия .......................................................................................110\\n7.2. Многоклассовая классификация ...................................................................112\\n7.3. Одноклассовая классификация .................................................................... 113\\n7.4. Классификация с многими метками .............................................................. 116\\n7.5. Обучение ансамбля ......................................................................................118\\n7.6. Обучение маркировке последовательностей ................................................123\\n7.7. Обучение преобразованию последовательностей в последовательности ......124\\n7.8. Активное обучение....................................................................................... 126\\n7.9. Обучение с частичным привлечением учителя ............................................. 128\\n7.10. Обучение с первого раза ............................................................................ 131\\n7.11. Обучение без подготовки ........................................................................... 133'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 6, 'page_label': '7'}, page_content='Оглавление   7\\nГлава 8. Продвинутые методики ............................................................................. 135\\n8.1. Работа с несбалансированными наборами данных .......................................135\\n8.2. Объединение моделей ................................................................................. 137\\n8.3. Обучение нейронных сетей ..........................................................................139\\n8.4. Продвинутая регуляризация ........................................................................ 140\\n8.5. Обработка нескольких входов ...................................................................... 141\\n8.6. Обработка нескольких выходов ................................................................... 142\\n8.7. Перенос обучения ........................................................................................143\\n8.8. Эффективность алгоритмов ......................................................................... 144\\nГлава 9. Обучение без учителя .............................................................................. 147\\n9.1. Оценка плотности ........................................................................................147\\n9.2. Кластеризация ............................................................................................. 149\\n9.3. Сокращение размерности ............................................................................. 159\\n9.4. Обнаружение аномалий ............................................................................... 164\\nГлава 10. Другие формы обучения ......................................................................... 165\\n10.1. Определение метрик ..................................................................................165\\n10.2. Определение ранга ....................................................................................167\\n10.3. Обучение делать рекомендации ................................................................. 170\\n10.4. Самообучение с учителем: вложения слов .................................................174\\nГлава 11. Заключение ............................................................................................ 177\\n11.1. Что не было затронуто ...............................................................................177\\n11.2. Благодарности ...........................................................................................181\\nАлфавитный указатель ....................................................................................... 183'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 7, 'page_label': '8'}, page_content='Моим родителям Татьяне и Валерию и моей семье:  \\nдочерям Катрин и Еве и брату Дмитрию'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 8, 'page_label': '9'}, page_content='Все модели ошибочны, но некоторые \\n полезны.\\nДжордж Бокс\\nПисьмо это вышло более длинным \\nтолько потому, что мне некогда было \\nнаписать его короче.\\nБлез Паскаль'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 9, 'page_label': '10'}, page_content='Предисловие \\nк русскому изданию\\nМашинное обучение, наверное, самая горячая и быстроразвивающаяся дисци -\\nплина в современной информатике, если не в современной науке вообще. Каж -\\nдый день появляются новые модели и выходят новые статьи, раз в пару месяцев \\nпроисходит очередной прорыв, который попадает в новости и открывает новые \\nвозможности, а раз в год-два происходит переворот в целой отрасли. Вот уже \\nдесять лет, после революции глубокого обучения, мы живем на новой (третьей) \\nволне хайпа искусственного интеллекта, и пока ничто не предвещает, что она \\nскоро закончится.\\nНеудивительно, что сейчас машинное обучение привлекает множество людей, \\nкоторые никогда раньше им не занимались. Кто-то узнал о заработках в инду -\\nстрии и хочет «разрабатывать искусственный интеллект за 300 К/сек», кто-то \\nхочет узнать, не пора ли «перевести свой бизнес с big data на machine learning», \\nа кто-то приходит в AI с глубокими идеями о том, как сделать этичным общий \\nискусственный интеллект, который не поработит и не убьет людей, а будет по -\\nмогать им (в целом это вполне серьезный разговор, но любому профессионалу \\nочевидно, что до практики или содержательных исследований этого еще очень, \\nочень, очень далеко).\\nПоэтому в наше время действительно очень полезно иметь краткое введение \\nв машинное обучение, на которое всегда можно давать ссылку и после которого \\nможно быть уверенным, что человек говорит на одном с тобой языке. Попытку \\nдать именно такое введение я вижу в этой книге, и мне кажется, что эта попытка \\nполучилась очень удачной. Книга действительно представляет читателю широкий \\nспектр основных понятий и методов машинного обучения, которые здесь изложены \\nкорректно, хоть и по понятным причинам очень кратко. Но если освоить эту книгу, \\nдальше самообразование может пойти куда проще и быстрее, ведь вы уже сможете \\nчитать более специальные источники. Кроме того, вам будет куда понятнее, что \\nименно делает код библиотек машинного обучения — для специалиста в этом не \\nдолжно оставаться никакой магии.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 10, 'page_label': '11'}, page_content='Предисловие к русскому изданию   11\\nНе стоит обольщаться: царского пути нет ни в геометрии, ни в машинном обу-\\nчении, ни вообще где бы то ни было. На свете нет и не может быть волшебного \\nспособа «обучиться разрабатывать искусственный интеллект за 30 дней без sms и \\nрегистрации». И эта книга тоже, конечно, такого способа не дает. С одной стороны, \\nвам потребуется некоторая математическая квалификация, чтобы понять изло -\\nженное здесь (хотя глава 2 начинается буквально с того, что такое «множество», \\nее, конечно, следует рассматривать скорее как напоминание для тех, кто когда-то \\nэто уже изучал). С другой стороны, эта книга — только самое начало пути в ин -\\nтересный и разнообразный мир машинного обучения; прочитав ее, вы не станете \\nпрофессионалом — вы сделаете первый маленький шаг.\\nНо если книгу прочитать вдумчиво и действительно освоить то, о чем здесь го -\\nворится, этот шаг может превратиться в большой скачок. Чего я и желаю всем \\nчитателям: разбирайтесь, познавайте, интересуйтесь новым и не бойтесь труд -\\nностей. Удачи!\\nСергей Николенко, \\nавтор книги «Глубокое обучение. Погружение в мир нейронных сетей»,  \\nсотрудник лаборатории математической логики Санкт-Петербургского  \\nотделения Математического института РАН,  \\nдиректор по научным исследованиям (Chief Research Officer)  \\nплатформы Neuromation'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 11, 'page_label': '12'}, page_content='Отличное введение в машинное обучение от специалиста мирового уровня.\\nКаролис Урбонас (Karolis Urbonas),  \\nруководитель отдела анализа данных в Amazon\\nХотела бы я встретить такую книгу, когда обучалась статистике в аспирантуре \\nи пыталась освоить машинное обучение.\\nЧао Хан (Chao Han),  \\nвице-президент, руководитель исследований и разработок в Lucidworks\\nКнига Андрея, фантастическим образом устраняя все лишнее, идет на полной \\nскорости прямо к цели с самой первой страницы.\\nСуджит Варахеди (Sujeet Varakhedi),  \\nтехнический руководитель в eBay\\nПрекрасная книга для инженеров, желающих начать использовать машинное обу-\\nчение в своей повседневной работе и не затратить на это слишком много времени.\\nДипак Агарвал (Deepak Agarwal),  \\nвице-президент по развитию искусственного интеллекта в LinkedIn'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 12, 'page_label': '13'}, page_content='Предисловие \\nиз оригинального издания\\nВ последние двадцать лет мы наблюдаем взрывной рост объемов доступных данных \\nи, как следствие, интереса к статистическим приложениям и машинному обучению. \\nПоследствия оказались далекоидущими. Десять лет назад, когда я смог привлечь \\nполный класс студентов MBA к изучению моего нового факультативного курса по \\nстатистике, коллеги были удивлены, потому что наш факультет не мог добиться \\nтакого результата для большинства факультативов. Сегодня мы предлагаем курс \\nмагистратуры по бизнес-аналитике, который является крупнейшей специализиро-\\nванной магистерской программой в университете и по популярности конкурирует \\nс нашими программами MBA. Количество предлагаемых нами курсов значительно \\nвозросло, однако наши студенты все еще жалуются на нехватку мест. Наш опыт \\nне уникален, поскольку программы по науке о данных и машинному обучению \\nразвиваются с необычайной скоростью, так как спрос на специалистов в этой об-\\nласти непрерывно растет.\\nТакая популярность обусловлена простым, но неоспоримым фактом. Развитие \\nмашинного обучения привело к новым открытиям во многих областях, таких как \\nсоциальные науки, бизнес, биология и медицина, и это далеко не полный список. \\nВ результате возник огромный спрос на людей с определенным набором навыков. \\nТем не менее обучение студентов этим навыкам оказалось сложной задачей, потому \\nчто большая часть ранней литературы по этим методам была нацелена на людей, \\nзанимающихся академическими исследованиями, и сосредоточена на статистиче-\\nских и теоретических свойствах алгоритмов обучения или полученных моделей. \\nПочти полностью отсутствовали материалы, ориентированные на исследователей \\nи практиков, нуждавшихся в помощи при реализации определенного метода для \\nрешения практических задач. Таким людям важнее знать и понимать спектр мето-\\nдов, применимых к каждой задаче, их сильные и слабые стороны и лежащие в их \\nоснове предположения, а теоретические свойства или подробная информация об \\nалгоритмах подбора имеют для них второстепенное значение. Работая над книгой \\n«An Introduction to Statistical Learning with R» 1 (ISLR), мы преследовали цель \\n1 Джеймс Г., Уиттон Д., Хасти Т., Тибширани Р. Введение в статистическое обучение с при-\\nмерами на языке R. ДМК-Пресс, 2016. — Примеч. пер.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 13, 'page_label': '14'}, page_content='14   Предисловие из оригинального издания\\nсоздать источник информации для такой группы людей. Энтузиазм, с которым \\nбыла встречена эта книга, демонстрирует спрос, существующий в обществе.\\nКнига «Машинное обучение без лишних слов» следует аналогичной парадигме. \\nТак же как в ISLR, в ней отсутствуют теоретические выводы, и основное внима-\\nние уделяется описанию ключевых деталей реализации различных подходов. \\nЭто компактное руководство «как анализировать данные», и я убежден, что оно \\nстанет ценным источником информации для научных сотрудников и практиков. \\nКнига достаточно коротка, чтобы ее можно было прочитать за один присест. Тем \\nне менее, несмотря на небольшой объем, она охватывает все основные подходы \\nмашинного обучения, от классической линейной и логистической регрессии до со-\\nвременного метода опорных векторов, глубокого обучения, бустинга и случайных \\nлесов. При этом описание различных подходов не страдает от недостатка деталей, \\nи заинтересованный читатель сможет получить дополнительную информацию \\nо любом конкретном методе в «Википедии». Книга не предполагает наличия ма-\\nтематической или статистической подготовки высокого уровня или даже опыта \\nпрограммирования, поэтому доступна почти каждому, кто решит потратить время \\nна изучение этих методов. С другой стороны, эту книгу обязательно должны про-\\nчитать все начинающие обучение в этой области, и она послужит им полезным \\nсправочником в будущем. Наконец, книга иллюстрирует некоторые алгоритмы, \\nиспользуя код на Python, одном из самых популярных языков программирования \\nдля машинного обучения. Я настоятельно рекомендую книгу «Машинное обучение \\nбез лишних слов» как для начинающих, желающих узнать больше о машинном \\nобучении, так и для опытных практиков, стремящихся расширить свой кругозор.\\nГарет Джеймс (Gareth James),  \\nпрофессор в области теории и методов анализа данных в Южно-Калифорний-\\nском университете, соавтор (вместе с Уиттоном, Хасти и Тибширани) книги-\\nбестселлера «An Introduction to Statistical Learning, with Applications in R»'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 14, 'page_label': '15'}, page_content='Вступление\\nНачнем с простой истины: машины не учатся. Типичное машинное обучение за -\\nключается в поиске математической формулы, которая при применении к набору \\nвходных данных (называемых обучающими данными) дает желаемые результаты. \\nЭта математическая формула также генерирует правильные выходные данные для \\nбольшинства других входных данных (отличных от обучающих) при условии, что \\nэти входные данные поступают из того же или подобного статистического распре-\\nделения, из которого были получены обучающие данные.\\nПочему это не является обучением? Потому что стоит слегка исказить входные \\nданные, и результат, скорее всего, получится полностью неправильным. Обучение \\nу животных — это нечто иное. Если вы научились играть в видеоигру при прямой \\nориентации экрана, вы все равно сможете играть в  нее, даже если кто-то слегка \\nповернет экран. Алгоритм машинного обучения, обучавшийся при прямой ори -\\nентации экрана и не обученный распознаванию поворота, не сможет играть в игру \\nна повернутом экране.\\nНо почему тогда используется название «машинное обучение»? Причина, как это \\nчасто бывает, заключается в маркетинге: Артур Сэмюэл (Arthur Samuel), американ-\\nский пионер в области компьютерных игр и искусственного интеллекта, придумал \\nэтот термин в 1959 году, когда работал в IBM. Подобно тому как в 2010-х годах IBM \\nпыталась продвигать термин «когнитивные вычисления», чтобы выделиться среди \\nконкурентов, в 1960-х годах IBM использовала новый крутой термин «машинное \\nобучение», чтобы привлечь клиентов и талантливых сотрудников.\\nКак видите, подобно тому как искусственный интеллект не является интеллектом, \\nмашинное обучение тоже не является обучением. Тем не менее термин «машинное \\nобучение» получил широкое распространение и под ним часто подразумевается \\nтеория и практика создания машин, способных выполнять различные полезные \\nдействия без явного программирования. Слово «обучение» в данном случае ис-\\nпользуется лишь как аналогия с обучением в животном мире, а не буквально.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 15, 'page_label': '16'}, page_content='16    Вступление\\nКому адресована эта книга\\nЭта книга содержит только те сведения о машинном обучении, которые появились \\nпосле 1960-х годов и доказали свою практическую ценность. Новичок в машинном \\nобучении найдет в этой книге достаточно подробностей, чтобы обеспечить себе \\nтакой уровень понимания, который позволит начать задавать правильные вопросы.\\nПрактики с опытом могут использовать эту книгу как набор рекомендаций для \\nдальнейшего самосовершенствования. Книга также пригодится при мозговом \\nштурме в начале проекта, когда требуется ответить на вопрос, является ли данная \\nтехническая или бизнес-задача «машинно-обучаемой», и, если да, какие методы \\nспособны помочь решить ее.\\nКак пользоваться этой книгой\\nЕсли вы собираетесь приступить к изучению темы машинного обучения, жела -\\nтельно, чтобы вы прочитали эту книгу от начала и до конца. (Здесь всего чуть \\nбольше ста страниц, и вы без труда одолеете их.) Если вас заинтересует какая-то \\nконкретная тема из описываемых в книге и вы захотите узнать больше, в большин-\\nстве разделов вы найдете QR-код.\\nОтсканировав такой QR-код с помощью телефона, вы получите ссылку на страни-\\nцу в сопутствующем вики-справочнике книги на сайте theMLbook.com, где найдете \\nрекомендуемые материалы для чтения, видеоролики, вопросы и ответы, фрагменты \\nкода, учебные пособия и многое другое. Вики-справочник постоянно пополняется \\nпубликациями самого автора книги, а также добровольцев со всего мира, то есть \\nэта книга, как хорошее вино, со временем становится только лучше.\\nОтсканируйте QR-код слева, чтобы попасть в вики-справочник \\nдля книги. В некоторых разделах нет QR-кода, но для многих из \\nних тоже есть страницы в вики. Вы сможете найти их, выполнив \\nпоиск по названию раздела в поисковой системе вики. \\nТеперь устраивайтесь поудобнее. Приятного чтения!\\nАндрей Бурков\\nQR-код \\nс адресом \\nстатьи в вики'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 16, 'page_label': '17'}, page_content='От издательства   17\\nОт издательства\\nВаши замечания, предложения, вопросы отправляйте по адресу comp@piter.com \\n(издательство «Питер», компьютерная редакция). \\nМы будем рады узнать ваше мнение! \\nНа веб-сайте издательства www.piter.com вы найдете подробную информацию о на-\\nших книгах.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 17, 'page_label': '18'}, page_content='1 Введение\\n1.1. Что такое машинное обучение\\nМашинное обучение — это раздел информатики, посвященный созданию алгорит-\\nмов, опирающихся на набор данных о каком-либо явлении. Эти данные могут быть \\nполучены из естественной среды, созданы вручную или сгенерированы другим \\nалгоритмом. \\nМашинное обучение также можно определить как процесс решения практической \\nзадачи путем 1) формирования набора данных и 2) алгоритмического построения \\nстатистической модели на его основе. Предполагается, что эта статистическая мо-\\nдель будет каким-то образом использоваться для решения практической задачи.\\nЧтобы сэкономить на нажатиях клавиш, я буду использовать термины «обучение» \\nи «машинное обучение» как взаимозаменяемые.\\n1.2. Типы обучения\\nОбучение может быть с учителем, без учителя и с подкреплением.\\n1.2.1. Обучение с учителем\\nВ обучении с учителем набор данных организован как коллекция размеченных \\nобразцов \\n . Каждый элемент xi из N называется вектором признаков. \\nВектор признаков — это вектор, в котором каждое измерение j = 1, ..., D содержит \\nзначение, описывающее некоторую характеристику образца. Это значение называ-\\nется признаком и обозначается как x(j). Например, если каждый образец x в нашей'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 18, 'page_label': '19'}, page_content='1.2. Типы обучения   19\\nколлекции представляет человека, тогда первый признак, x(1), мог бы описывать его \\nрост в сантиметрах, второй признак, x(2), мог бы описывать его вес в килограммах, \\nx(3) — пол, и т. д. Для всех данных в наборе данных признак в позиции j в векторе \\nпризнаков всегда описывает одну и ту же характеристику. Это означает, что если \\n описывает вес некоторого образца xi в килограммах, тогда \\n  также будет \\nописывать вес в килограммах каждого образца xk, k = 1, ..., N. Метка yi может быть \\nэлементом конечного множества классов {1, 2, ..., C}, вещественным числом или \\nболее сложной структурой, такой как вектор, матрица, дерево или граф. В этой \\nкниге, если явно не оговаривается иное, под yi будет подразумеваться элемент \\nконечного множества классов или вещественное число1. Класс можно представить \\nкак категорию, которой принадлежит образец. Например, если роль данных играют \\nэлектронные письма и вы решаете задачу определения спама, тогда вы могли бы \\nопределить два класса: {спам, не_спам}.\\nЦель алгоритма обучения с учителем — на основе набора данных создать модель, \\nкоторая принимает вектор признаков x на входе и возвращает информацию, которая \\nпозволяет определить метку для этого вектора признаков. Например, модель, создан-\\nная с использованием набора данных людей, могла бы принимать вектор признаков, \\nописывающих человека, и возвращать вероятность, что этот человек болен раком.\\n1.2.2. Обучение без учителя\\nВ обучении без учителя набор данных представлен коллекцией неразмеченных \\nобразцов \\n . И снова, x — это вектор признаков, а цель алгоритма обучения \\nбез учителя — создать модель, которая принимает вектор признаков x на входе \\nи преобразует его в другой вектор или в значение, которое можно использовать для \\nрешения практической задачи. Например, в задачах кластеризации модель воз-\\nвращает идентификатор кластера для каждого вектора признаков в наборе данных. \\nВ задачах уменьшения размерности модель возвращает вектор признаков, который \\nимеет меньше элементов, чем входной вектор x. В задачах выявления аномалий \\nвозвращается действительное число, которое указывает, насколько x отличается \\nот «типичного» образца в наборе данных.\\n1.2.3. Обучение с частичным привлечением учителя\\nВ обучении с частичным привлечением учителя (semi-supervised learning) набор \\nданных содержит как размеченные, так и неразмеченные образцы. Обычно не -\\nразмеченных образцов намного больше, чем размеченных. Алгоритм обучения  \\n1 Вещественное число — это величина, которую можно представить как расстояние на \\nчисловой прямой. Примеры вещественных чисел: 0, –256.34, 1000, 1000.2.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 19, 'page_label': '20'}, page_content='20   Глава 1. Введение\\nс частичным привлечением учителя преследует ту же цель, что и алгоритм обу-\\nчения с учителем. В данном случае предполагается, что использование множества \\nнеразмеченных данных поможет алгоритму обучения найти (можно также сказать \\n«произвести» или «вычислить») лучшую модель.\\nПредположение о выигрыше от добавления большего количества неразмеченных \\nданных может показаться нелогичным. На первый взгляд кажется, что мы, на -\\nоборот, добавляем больше неопределенности. Однако добавляя неразмеченные \\nданные, вы вносите больше информации о задаче: б\\ue088ольшая выборка лучше отра-\\nжает распределение вероятностей в данных, откуда взяты размеченные образцы. \\nТеоретически, алгоритм обучения должен уметь воспользоваться этой дополни -\\nтельной информацией.\\n1.2.4. Обучение с подкреплением\\nОбучение с подкреплением — это раздел машинного обучения, где предполага -\\nется, что машина «живет» в определенном окружении и способна воспринимать \\nсостояние этого окружения как вектор характеристик. Машина может выполнять \\nнекоторые действия в каждом состоянии. Разные действия приносят разные возна\\xad\\nграждения, а также могут перевести машину в другое состояние окружения. Цель \\nалгоритма обучения с подкреплением — выучить линию поведения.\\nЛиния поведения — это стратегия (похожая на модель в обу-\\nчении с учителем), которая принимает вектор признаков, опи-\\nсывающий состояние, и возвращает оптимальное действие для \\nвыполнения в этом состоянии. Действие является оптималь -\\nным, если приводит к максимальному ожидаемому среднему \\nвознаграждению.\\nОбучение с подкреплением решает особый класс задач, когда решения принима-\\nются последовательно, а цель является долгосрочной, например игра в видеоигру, \\nроботизация производства, управление ресурсами или логистика. В этой книге \\nосновное внимание будет уделяться принятию единовременных решений, когда \\nисходные данные не зависят друг от друга, и решений, принятых в прошлом. Обу-\\nчение с подкреплением я оставлю за рамками этой книги.\\n1.3. Как работает обучение с учителем\\nВ этом разделе я кратко объясню, как работает обучение с учителем, чтобы дать \\nвам общую картину процесса, прежде чем углубиться в детали. В качестве примера'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 20, 'page_label': '21'}, page_content='1.3. Как работает обучение с учителем   21\\nя выбрал обучение с учителем, так как этот тип машинного обучения чаще других \\nиспользуется на практике.\\nПроцесс обучения с учителем начинается со сбора данных. Данные для этого вида \\nобучения — это коллекция пар (вход, выход). Входными данными может быть все \\nчто угодно, например электронные письма, изображения или замеры, полученные \\nот датчика. Выходными данными обычно являются действительные числа или \\nметки (например, «спам», «не_спам», «кошка», «собака», «мышь» и т. д.). В неко-\\nторых случаях выходные данные могут быть представлены векторами (например, \\nчетырьмя координатами углов прямоугольника вокруг человека на картинке), \\nпоследовательностями (например, [«прилагательное», «прилагательное», «су -\\nществительное»] для входа «большая красивая машина») или иметь какую-то \\nдругую структуру.\\nДопустим, вы решили использовать обучение с учителем для решения задачи \\nопределения спама. Вы собираете данные, например, 10 000 электронных писем, \\nкаждое из которых снабжается меткой «спам» или «не_спам» (вы можете добавить \\nэти метки вручную или отдать эту работу на аутсорсинг). Затем вы должны пре -\\nобразовать каждое электронное письмо в вектор признаков.\\nНа основе своего опыта специалист по анализу данных решает, как преобразовать \\nсущность реального мира, такую как электронное письмо, в вектор признаков. \\nЧасто для преобразования текста в вектор признаков используется метод, назы -\\nваемый мешком слов. Его суть заключается в том, чтобы взять словарь (допустим, \\nчто он содержит 20 000 слов, отсортированных по алфавиту) и условиться, что \\nв векторе признаков:\\n  первый признак равен 1, если электронное письмо содержит слово «а» (союз), \\nи 0 в другом случае;\\n  второй признак равен 1, если электронное письмо содержит слово «аарон» \\n(имя), и 0 в другом случае;\\n  ...;\\n  признак в позиции 20 000 равен 1, если электронное письмо содержит слово \\n«ящур» (болезнь), и 0 в другом случае.\\nВы повторяете описанную процедуру для каждого электронного письма в вашей \\nколлекции и получаете 10 000 векторов признаков (каждый вектор имеет размер-\\nность 20 000) и меток («спам»/«не_спам»).\\nТеперь у вас есть машиночитаемые входные данные, но выходные метки по-\\nпрежнему имеют вид простого текста. Некоторые алгоритмы обучения требуют \\nпреобразования меток в числа. Например, некоторые алгоритмы требуют исполь-'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 21, 'page_label': '22'}, page_content='22   Глава 1. Введение\\nзовать числа 0 (для представления метки «не_спам») и 1 (для представления метки \\n«спам»). Модель машинного обучения, которую я использую для иллюстрации \\nобучения с учителем, называется методом опорных векторов  (Support Vector \\nMachine, SVM) . Она требует, чтобы положительная метка (в данном случае \\n«спам») имела числовое значение +1 (один), а отрицательная метка («не_спам») \\nимела значение –1 (минус один).\\nТеперь у вас есть набор данных  и алгоритм обучения  и вы готовы применить \\nалгоритм обучения к набору данных, чтобы получить модель.\\nSVM рассматривает каждый вектор признаков как точку в многомерном про -\\nстранстве (в данном случае пространство имеет 20 000 измерений). Алгоритм по-\\nмещает все векторы признаков на воображаемый 20 000-мерный график и рисует \\nвоображаемую 19 999-мерную линию (гиперплоскость), которая отделяет данные \\nс положительными метками от данных с отрицательными метками. Граница, раз-\\nделяющая данные разных классов, в машинном обучении называется границей \\nпринятия решения.\\nУравнение гиперплоскости задается двумя параметрами: вещественным векто -\\nром w той же размерности, что и входной вектор признаков x, и действительным \\nчислом b, например:\\nwx – b = 0,\\nгде выражение wx означает w(1)x(1)+ w(2)x(2)+…+ w(D)x(D), а D — число измерений \\nв векторе признаков x.\\n(Сейчас некоторые уравнения могут показаться вам сложными, но в главе 2 мы \\nрассмотрим необходимые математические и статистические понятия. А пока про-\\nсто попробуйте понять происходящее в меру своих знаний. Многое прояснится, \\nкогда вы прочитаете следующую главу.)\\nТеперь прогнозируемую метку для некоторого входного вектора признаков x \\nможно выразить так:\\ny = sign(wx – b),\\nгде sign — это математический оператор, принимающий произвольное значение \\nи возвращающий +1, если входное значение является положительным числом, \\nи –1, если входное значение является отрицательным числом.\\nЦель алгоритма обучения, в данном случае SVM, используя набор данных, \\nнайти оптимальные значения w* и b* для параметров w и b. После того как'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 22, 'page_label': '23'}, page_content='1.3. Как работает обучение с учителем   23\\nалгоритм обучения найдет эти оптимальные значения, модель f(x) будет опре -\\nделяться как:\\nf(x) = sign(w*x – b*).\\nЧтобы с помощью модели SVM предсказать, является ли электронное письмо \\nспамом или нет, вы должны взять текст письма, преобразовать его в вектор при-\\nзнаков, затем умножить этот вектор на w*, вычесть b* и взять знак результата. Это \\nдаст нам прогноз (+1 означает «спам», а –1 означает «не_спам»).\\nНо как машина находит w* и b*? Она решает задачу оптимизации. Машины хорошо \\nсправляются с оптимизацией функций в условиях ограничений.\\nИтак, какие ограничения должны удовлетворяться здесь? Прежде всего, модель \\nдолжна правильно предсказывать метки имеющихся 10 000 данных. Напомню, что \\nкаждый образец i = 1, ..., 10 000 задается парой (xi, yi), где xi — вектор признаков \\ni-го образца, а yi — его метка, которая принимает значение –1 или +1. Ограничения \\nвыглядят следующим образом:\\nwxi – b ≥ +1, если yi = +1,\\nwxi – b ≤  –1, если yi = –1.\\nЖелательно также, чтобы гиперплоскость отделяла положительные данные от \\nотрицательных с максимальным зазором. Зазор — это расстояние между ближай-\\nшими образцами двух классов, отделяемых границей принятия решения. Большой \\nзазор способствует лучшему обобщению, то есть тому, насколько хорошо модель \\nбудет классифицировать новые данные. Для максимизации зазора нужно мини -\\nмизировать евклидову норму w, которая обозначается как || w || и определяется \\nвыражением \\n .\\nМашина должна решить задачу оптимизации, которая формулируется так:\\nМинимизировать  || w || с учетом y i(wxi – b) ≥ 1  для i = 1, ..., N. Выражение \\nyi(wxi – b) ≥ 1 — это всего лишь компактная запись двух ограничений выше.\\nРешение этой задачи оптимизации, обозначенной параметрами w* и b*, называ-\\nется статистической моделью, или просто моделью. Процесс построения модели \\nназывается обучением.\\nДля двумерных векторов задачу и решение можно представить визуально, как \\nпоказано на рис. 1.1. Синие и оранжевые точки представляют положительные и от-\\nрицательные образцы соответственно, а линия, заданная уравнением wx – b = 0, \\nпредставляет границу принятия решения.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 23, 'page_label': '24'}, page_content='24   Глава 1. Введение\\nx(2)\\nx(1)\\nwx — \\nb = 0\\nwx — \\nb = 1\\nwx\\n — \\nb = —1\\nb ||w|| \\n2 ||w|| \\nРис. 1.1. Пример модели SVM для двумерных векторов признаков\\nПочему минимизация нормы w дает в результате наибольший зазор между дву -\\nмя классами? Геометрически уравнения wx – b = 1 и wx – b = –1 определяют две \\nпараллельные гиперплоскости, как показано на рис. 1.1. Расстояние между этими \\nгиперплоскостями равно \\n , поэтому чем меньше норма || w ||, тем больше рас -\\nстояние между этими двумя гиперплоскостями.\\nТак работает метод опорных векторов (SVM). Эта конкретная версия алгоритма \\nстроит так называемую линейную модель. Она называется линейной, потому что гра-\\nница принятия решения — это прямая линия (или плоскость, или гиперплоскость). \\nМетод опорных векторов также может включать ядра, способные сделать границу \\nрешения произвольно нелинейной. В некоторых случаях невозможно полностью'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 24, 'page_label': '25'}, page_content='1.4. Почему модель способна работать с новыми данными   25\\nразделить две группы точек из-за шума в данных, ошибок разметки или аномалий \\n(данных, сильно отличающихся от «типичного» образца в наборе данных). Для \\nтаких случаев есть версия алгоритма SVM, способная включать гиперпараметр \\nштрафа1 за неправильную классификацию обучающих данных конкретных классов. \\nБолее подробно алгоритм SVM мы рассмотрим в главе 3.\\nСейчас вы должны усвоить следующее: любой алгоритм решения задачи клас -\\nсификации при построении модели явно или неявно создает границу решения. \\nГраница решения может быть прямой, изогнутой, иметь сложную форму или \\nобразовываться наложением некоторых геометрических фигур. Форма границы \\nрешения определяет точность модели (то есть долю образцов, метки которых \\nпредсказываются моделью правильно). Форма границы решения и то, как она \\nалгоритмически или математически вычисляется на основе обучающих данных, \\nотличают один алгоритм обучения от другого.\\nНа практике необходимо учитывать также две другие важные характеристики \\nалгоритма обучения: скорость построения модели и время получения прогноза. Во \\nмногих практических ситуациях предпочтение отдается более быстрым алгорит-\\nмам, которые строят менее точные модели. Кроме того, иногда предпочтительнее \\nиметь менее точную модель, но быстро вычисляющую прогнозы.\\n1.4. Почему модель способна работать \\nс новыми данными\\nПочему модель, полученная в результате машинного обучения, способна правильно \\nпредсказывать метки для новых, ранее не встречавшихся ей данных? Чтобы по -\\nнять это, посмотрите на график на рис. 1.1. Если два класса можно отделить друг \\nот друга границей решения, то, очевидно, данные, принадлежащие каждому классу, \\nрасположены в двух разных подпространствах, которые создает граница решения.\\nЕсли данные, использованные для обучения, были выбраны случайным образом, \\nнезависимо друг от друга и  с использованием одной и  той же процедуры, тогда \\nстатистически весьма вероятно, что новый отрицательный образец окажется на \\nграфике где-то не очень далеко от других отрицательных данных. То же касается \\nнового положительного образца: он, скорее всего, окажется где-то среди других \\nположительных данных. В таком случае наша граница решения с высокой вероят-\\n1 Гиперпараметр — это свойство алгоритма обучения, обычно (но не всегда) имеющее чис-\\nловое значение. Это значение влияет на работу алгоритма. Значения гиперпараметров не \\nопределяются самим алгоритмом из данных. Они должны задаваться аналитиком перед \\nзапуском алгоритма.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 25, 'page_label': '26'}, page_content='26   Глава 1. Введение\\nностью будет надежно отделять друг от друга новые положительные и отрицатель-\\nные данные. В других менее вероятных ситуациях наша модель будет совершать \\nошибки, но, поскольку такие ситуации менее вероятны, число ошибок, скорее \\nвсего, будет меньше числа правильных прогнозов.\\nОчевидно, что чем больше набор обучающих данных, тем менее \\nвероятно, что новые данные будут отличаться (и лежать на гра-\\nфике далеко) от данных, использованных для обучения.\\nДля минимизации вероятности ошибок прогнозирования на \\nновых образцах алгоритм SVM в поисках наибольшего зазора, \\nявным образом пытается провести границу решения так, чтобы она лежала как \\nможно дальше от данных обоих классов.\\nЧитателю, желающему узнать больше об обучаемости и понять связь между ошиб-\\nкой модели, размером обучающего набора, формой математического уравнения, \\nопределяющего модель, и временем построения модели, рекомендуется прочитать \\nо вероятностном приблизительно корректном обучении (Probably Approximately \\nCorrect, P AC). Теория вероятностно-приблизительного корректного обучения \\nпоможет проанализировать и понять, сможет ли и при каких условиях алгоритм \\nобучения получить приблизительно корректный классификатор.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 26, 'page_label': '27'}, page_content='2\\nОбозначения \\nи определения\\n2.1. Обозначения\\nНачнем с того, что повторим математические обозначения, которые мы все учили \\nв школе, но некоторые, вероятно, забыли их сразу после выпускного.\\n2.1.1. Структуры данных\\nСкаляр — это простое числовое значение, например, 15 или –3.25. Переменные \\nили константы, принимающие скалярные значения, обозначаются наклонным \\nшрифтом, например x или a.\\nВектор — это упорядоченный список скалярных значений, называемых атрибута-\\nми. Мы будем обозначать векторы жирным шрифтом, например, x или w. Векторы \\nможно изобразить в виде стрелок, указывающих в некоторых направлениях, а также \\nв виде точек в многомерном пространстве. Для примера на рис. 2.1 показаны три \\nдвумерных вектора, a = [2, 3], b = [–2, 5] и c = [1, 0]. Атрибуты вектора мы будем \\nобозначать наклонным шрифтом с индексом, например: w(j) или x(j). Индекс j обо-\\nзначает конкретное измерение вектора — позицию атрибута в списке. Например, \\nв векторе a, изображенном на рис. 2.1 в виде красной стрелки, a(1) = 2 и a(2) = 3.\\nОбозначение x(j) не следует путать с выражением степени, например x2 (x в квадра-\\nте) или x3 (x в кубе). Если нам понадобится возвести в степень, например в квадрат, \\nатрибут с индексом, мы запишем это так: \\n .\\nПеременная может иметь два или более индексов: \\n  или \\n . Например, обсуж-\\nдая нейронные сети, мы будем использовать запись \\n  для обозначения входного \\nпризнака j узла u в слое l.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 27, 'page_label': '28'}, page_content='28   Глава 2. Обозначения и определения\\nРис. 2.1. Три вектора, изображенные как стрелки и точки\\nМатрица — это прямоугольный массив чисел, расположенных в строках и столбцах. \\nНиже приводится пример матрицы с двумя строками и тремя столбцами:'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 28, 'page_label': '29'}, page_content='2.1. Обозначения   29\\nМатрицы будут обозначаться заглавными буквами и жирным шрифтом, напри -\\nмер: A или W.\\nМножество — это неупорядоченная коллекция уникальных элементов. Мы будем \\nобозначать множества заглавными буквами, например S. Множества чисел могут \\nбыть конечными (содержать фиксированное количество значений). В этом случае \\nмы будем обозначать их с использованием фигурных скобок, например {1, 3, 18, 23, \\n235} или {x1, x2, x3, x4, ..., xn}. Множество может быть бесконечным и содержать все \\nзначения, принадлежащие некоторому интервалу. Если множество включает все \\nзначения между a и b, в том числе a и b, мы будем обозначать его с использованием \\nквадратных скобок: [a, b]. Если множество не включает значения a и b, такое мно-\\nжество мы будем обозначать с использованием круглых скобок: (a, b). Например, \\nмножество [0, 1] включает в себя такие значения, как 0, 0.0001, 0.25, 0.784, 0.9995 \\nи 1.0. Специальное множество, обозначаемое как R, включает все числа от минус \\nбесконечности до плюс бесконечности.\\nЕсли элемент x принадлежит множеству S, мы выражаем это как x ϵ S. Мы можем \\nполучить новое множество S3 как пересечение двух множеств S1 и S2. Это вы -\\nражается как \\n . Например, \\n  дает в результате новое \\nмножество {1, 8}.\\nНовое множество S3 можно получить как объединение двух множеств S1 и S2. Мы \\nбудем выражать это так: \\n . Например, \\n  дает в резуль-\\nтате новое множество {1, 3, 4, 5, 8}.\\n2.1.2. Обозначения со знаком суммы\\nСуммирование элементов коллекции \\n или атрибутов век-\\nтора \\n обозначается так:\\n или так: \\n .\\nОператор \\n  обозначает «определен как».\\n2.1.3. Обозначения со знаком произведения\\nПо аналогии с суммированием существует обозначение, выражающее произведение. \\nОно обозначает произведение элементов коллекции или атрибутов вектора:'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 29, 'page_label': '30'}, page_content='30   Глава 2. Обозначения и определения\\nгде \\n  означает умножение a на b. Там, где это возможно, мы будем опускать опе-\\nратор умножения (·), упрощая запись произведения до ab, также обозначающего \\nумножение a на b.\\n2.1.4. Операции с множествами\\nОператор создания производного множества выглядит следующим образом: \\n. Это выражение означает, что создается новое множество \\n, в которое помещаются квадраты тех элементов x, принадлежащих S, значения \\nкоторых больше 3.\\nОператор мощности \\n  возвращает число элементов в множестве S.\\n2.1.5. Операции с векторами\\nСумма двух векторов x + z определяется как вектор\\n .\\nРазность двух векторов x – z определяется как вектор\\n.\\nПроизведение вектора на скаляр — это вектор. Например, \\n .\\nСкалярное произведение двух векторов — это скаляр. Например, \\n . \\nВ некоторых книгах скалярное произведение записывается как w ∙ x. Два вектора \\nдолжны иметь одинаковую размерность. Иначе результат скалярного произведе-\\nния не определен.\\nПроизведение матрицы W на вектор x дает в результате новый вектор. Допустим, \\nу нас есть матрица\\nКогда в операциях с матрицами участвуют векторы, по умолчанию вектор представ-\\nляется в виде матрицы с одним столбцом. Когда в выражении умножения вектор \\nнаходится справа от матрицы, он остается вектором-столбцом. Умножить матрицу'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 30, 'page_label': '31'}, page_content='2.1. Обозначения   31\\nна вектор можно, только если количество строк в векторе совпадает с количеством \\nстолбцов в матрице. Пусть у нас есть вектор \\n . Тогда результатом \\nпроизведения Wx будет двумерный вектор:\\nЕсли бы матрица имела, скажем, пять строк, в результате умножения получился \\nбы пятимерный вектор.\\nКогда в выражении умножения вектор находится слева от матрицы, его нужно \\nтранспонировать (повернуть) перед умножением. Транспонирование вектора x \\nобозначается как xТ и преобразует вектор-столбец в вектор-строку. Допустим,\\n.\\nУмножение вектора x на матрицу W обозначается как x\\n┬\\nW,\\n \\nКак видите, умножить вектор на матрицу можно только в том случае, если число \\nизмерений в векторе совпадает с числом строк в матрице.\\n2.1.6. Функции\\nФункция — это отношение, связывающее каждый элемент x из множества X (об\\xad\\nласти определения функции) с единственным элементом y из другого множества Y'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 31, 'page_label': '32'}, page_content='32   Глава 2. Обозначения и определения\\n(области значений функции). Функция обычно имеет имя. Если функция назы-\\nвается f, тогда отношение обозначается как y = f(x) (читается как «эф от икс»), \\nгде элемент x является аргументом, или входом, функции, а y — значением, или \\nвыходом, функции.\\nСимвол, представляющий аргумент, — это переменная функции (мы часто будем \\nговорить, что f — это функция от переменной x).\\nМы говорим, что f(x) имеет локальный минимум  при x = c, если f(x) ≥ f(c) для \\nкаждого значения x в некотором открытом интервале вокруг x = c. Интервал — \\nэто множество действительных чисел, такое, что любое число, которое находится \\nмежду двумя числами в множестве, также входит в это множество. Открытый \\nинтервал не включает конечные точки и обозначается круглыми скобками. \\n Например, (0, 1) означает «все числа больше 0 и меньше 1». Минимальное зна -\\nчение среди всех локальных минимумов называется глобальным минимумом  \\n(рис. 2.2).\\nлокальный миним ум\\nглобальный миним ум\\nx\\nf (x)\\n6\\n4\\n2\\n0\\n–2\\n–4\\n–6\\n0 0.2 0.4 0.6 0.8 1 1.2\\nРис. 2.2. Локальный и глобальный минимумы функции\\nВекторная функция, обозначаемая как y = f(x), — это функция, возвращающая \\nвектор y. Аргумент такой функции может быть вектором или скаляром.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 32, 'page_label': '33'}, page_content='2.1. Обозначения   33\\n2.1.7. Операторы max и arg max\\nПусть дано множество значений A = {a1, a2, …an}, тогда оператор \\n  вернет \\nнаибольшее значение f(a) из всех элементов в множестве A. С другой стороны, опе-\\nратор \\n  вернет элемент из множества A, который максимизирует f(а).\\nИногда, когда множество задано неявно или бесконечно, запись этих операторов \\nможно сократить до \\n  или \\n .\\nСуществуют также аналогичные операторы min и arg min.\\n2.1.8. Оператор присваивания\\nВыражение a ← f(x) означает, что переменная a получает новое значение: результат \\nf (x). Мы говорим, что переменной a присваивается новое значение. Аналогично, \\na ← [a1, a2] означает, что векторная переменная a получает значение двумерного \\nвектора [a1, a2].\\n2.1.9. Производная и градиент\\nПроизводная f ′ функции f — это функция или значение, которое описывает, как \\nбыстро f растет (или уменьшается). Если производная имеет постоянное значение, \\nнапример 5 или –3, значит, функция постоянно растет (или уменьшается) в лю-\\nбой точке x области определения. Если производная f ′ является функцией, тогда \\nфункция f может расти с разной скоростью в разных точках в области определения. \\nЕсли производная f ′ положительна в некоторой точке x, значит, функция f растет \\nв этой точке. Если производная от f отрицательна в некоторой точке x, значит, \\nфункция уменьшается в этой точке. Производная, равная нулю в точке x, означает, \\nчто функция f в этой точке не растет и не уменьшается (то есть это точка минимума \\nили максимума функции f).\\nПоиск производной называется дифференцированием дифференцированием.\\nПроизводные для основных функций известны. Например, для f(x) = x2 произ-\\nводная имеет вид f ′(x) = 2x; для  f(x) = 2x производная имеет вид f ′(x) = 2; для \\nf(x) = 2 производная имеет вид f ′(x) = 0 (производная любой функции f(x) = c, где \\nc — константа, равна нулю).\\nЕсли функция, которую нужно дифференцировать, не относится к числу ос -\\nновных, ее производную можно найти, используя правило дифференциро \\xad\\nвания сложной функции . Например, если F(x) = f(g(x)), где f и g — некото -\\nрые функции, тогда F ′(x) = f ′(g(x))g ′(x). Например, если F(x) = (5x +1)2, тогда'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 33, 'page_label': '34'}, page_content='34   Глава 2. Обозначения и определения\\ng(x) = 5x + 1 и f (g(x)) = (g(x))2. Применяя правило выше, находим F ′(x) = 2(5x + 1)\\ng ′(x) = 2(5x + 1)5 = 50x + 10.\\nГрадиент — это обобщение производной для функций нескольких аргументов (или \\nодного аргумента, представленного вектором или какой-либо другой сложной \\nструктурой). Градиент функции — это вектор частных производных. Поиск част-\\nной производной функции можно рассматривать как процесс поиска производной, \\nкогда изменяется только один из входов, а остальные имеют постоянные значения.\\nНапример, если функция определена как \\n , тогда \\nчастная производная функции f относительно x(1), обозначаемая как \\n , будет \\nопределяться формулой\\nгде а — производная функции ax(1); два нуля соответствуют производным от bx(2) \\nи c, потому что когда вычисляется производная по x(1), x(2) считается константой, \\nа производная любой константы равна нулю.\\nАналогично, частная производная функции f относительно x(2), \\n , будет опре-\\nделяться формулой\\nГрадиент функции f обозначается как ∇f и задается вектором \\n .\\nПравило дифференцирования сложной функции применимо и к частным произ-\\nводным, как я покажу в главе 4.\\n2.2. Случайная величина\\nСлучайная величина, которая обычно обозначается курсивной заглавной буквой, \\nнапример X, — это величина, возможные значения которой являются числовыми \\nрезультатами случайного явления. Примерами случайных явлений с числовым \\nрезультатом могут служить бросок монеты (0 для решки и  1 для орла), бросок \\nигрального кубика или рост первого незнакомца, встретившегося на улице. Су -\\nществует два типа случайных величин: дискретные и непрерывные.\\nДискретная случайная величина  принимает конечное или счетное множество \\nзначений, например: красный, желтый, синий или 1, 2, 3,  ...'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 34, 'page_label': '35'}, page_content='2.2. Случайная величина   35\\nРаспределение вероятностей  дискретной случайной величины описывается \\nсписком вероятностей, связанных с каждым из возможных значений. Этот список \\nвероятностей называется функцией распределения дискретной случайной вели\\xad\\nчины (probability mass function, pmf). Например: Pr(X = красный) = 0.3, Pr(X = жел-\\nтый) = 0.45, Pr(X = синий) = 0.25. Каждая вероятность в функции распределения \\nдискретной случайной величины — это значение, большее или равное 0. Сумма \\nвероятностей равна 1 (рис. 2.3a).\\nФункция распределения\\nдискретной случайной величины\\n           \\n(а)\\nПлощадь\\nФункция плотности\\nраспределения вероятностей\\n           \\n(б)\\nРис. 2.3. Функция распределения дискретной случайной величины (а) и функция \\nплотности распределения вероятностей (б)'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 35, 'page_label': '36'}, page_content='36   Глава 2. Обозначения и определения\\nНепрерывная случайная величина (continuous random variable, CRV) может прини-\\nмать бесконечное число возможных значений в некотором интервале. Примерами \\nмогут служить рост, вес и время. Поскольку число значений непрерывной случай-\\nной величины X бесконечно, вероятность Pr(X = c) для любого c равна 0. Поэтому \\nраспределение вероятностей CRV (непрерывное распределение вероятностей) \\nописывается не списком, а функцией плотности вероятности (probability density \\nfunction, pdf). Функция плотности вероятности — это функция с неотрицательной \\nобластью значений, а площадь под кривой этой функции равна 1 (рис. 2.3б).\\nПусть дискретная случайная величина X имеет k возможных значений \\n . \\nОжидание X, обозначаемое как E[X], определяется формулой\\n \\n   (2.1)\\nгде Pr(X = xi) — вероятность, что X имеет значение xi в соответствии с pmf. Ожида-\\nние случайной величины также называется средним, или ожидаемым, значением \\nи часто обозначается буквой μ. Ожидание является одной из наиболее важных \\nстатистических характеристик случайной величины.\\nЕще одной важной статистической характеристикой является стандартное от \\xad\\nклонение, которое определяется как\\nДисперсия, обозначаемая как σ2 или var(X), определяется формулой\\nДля дискретной случайной величины стандартное отклонение определяется как:\\n,\\nгде \\n .\\nОжидание непрерывной случайной величины X определяется формулой\\n \\n ,  (2.2)'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 36, 'page_label': '37'}, page_content='2.4. Правило Байеса   37\\nгде fX — это функция плотности вероятности (pdf) величины X, а \\n  — интеграл \\nот функции xfX.\\nИнтеграл является эквивалентом суммы всех значений функции, когда функция \\nимеет непрерывную область определения. Он равен площади под кривой функции. \\nФункция плотности вероятности обладает замечательным свойством: площадь под \\nее кривой всегда равна 1, то есть математически это означает, что \\n .\\nВ большинстве случаев fX неизвестна, но мы можем наблюдать некоторые значе-\\nния X. В машинном обучении мы называем эти значения образцами, а набор этих \\nданных — выборкой или набором данных.\\n2.3. Несмещенные оценки\\nТак как обычно fX неизвестна, но имеется выборка \\n , мы часто доволь-\\nствуемся не истинными значениями статистических характеристик распределения \\nвероятностей, такими как ожидание, а их несмещенными оценками.\\nМы говорим, что \\n  — это несмещенная оценка некоторой статистической \\nхарактеристики θ, вычисленной по выборке SX с неизвестным распределением \\nвероятностей, если \\n  обладает следующим свойством:\\n,\\nгде \\n  — статистическая характеристика выборки, полученная по выборке SX, а не \\nреальная статистическая характеристика, которую можно получить, только зная X; \\nожидание определяется по всем возможным выборкам из X. Это означает, что при \\nналичии неограниченного количества выборок, таких как SX, вычислив некоторую \\nнесмещенную оценку, такую как \\n , для каждой выборки и взяв среднее значение \\nдля всех этих \\n , вы получите значение реальной статистической характеристики μ, \\nкоторую вычислили бы по X.\\nМожно показать, что несмещенная оценка неизвестного ожидания E[X] (заданно-\\nго уравнением 2.1 или 2.2) равна \\n  (в статистике называется выборочное \\nсреднее).\\n2.4. Правило Байеса\\nУ словная вероятность Pr(X = x | Y = y) — это вероятность того, что случайная ве-\\nличина X будет иметь конкретное значение x при условии, что другая случайная'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 37, 'page_label': '38'}, page_content='38   Глава 2. Обозначения и определения\\nвеличина Y имеет конкретное значение y. Правило Байеса (также известное как \\nтеорема Байеса) гласит:\\n.\\n2.5. Оценка параметров\\nПравило Байеса удобно использовать, когда есть модель распределения X и эта \\nмодель \\n  является функцией, имеющей некоторые параметры в форме вектора θ. \\nПримером такой функции может служить функция Гаусса с двумя параметрами, \\nμ и σ, которая определяется как\\n,\\nгде \\n .\\nЭта функция имеет все свойства функции плотности распределения вероятно -\\nстей (pdf)1. Следовательно, ее можно использовать как модель неизвестного рас-\\nпределения X. Мы можем получить значения параметров в векторе θ из данных, \\nиспользуя правило Байеса:\\n.  (2.3)\\nгде \\n .\\nЕсли есть выборка S из X и множество возможных значений для θ конечно, мы \\nлегко сможем оценить \\n , итеративно применив правило Байеса к каж-\\nдому образцу \\n . Начальное значение \\n  можно выбрать таким, что \\n. Это предположение о вероятностях для различных \\n  называется \\nаприорной вероятностью.\\nСначала вычислим \\n  для всех возможных значений \\n . Затем, перед \\nобновлением \\n , на этот раз для \\n  с использованием уравне-\\n1 На самом деле уравнение 2.3 определяет pdf одного из наиболее часто используемых \\nна практике распределений вероятности, называемого гауссовым распределением, или \\nнормальным распределением, и обозначаемого как N (μ, σ2).'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 38, 'page_label': '39'}, page_content='2.7. Классификация и регрессия   39\\nния 2.3, заменим априорную вероятность \\n  в уравнении 2.3 новой оценкой \\n.\\nЛучшие значения параметров θ* в данном примере получаются с использованием \\nпринципа максимума апостериорной вероятности (maximum a posteriori, MAP):\\n \\n .  (2.4)\\nЕсли множество возможных значений для θ бесконечно, то уравнение 2.4 нужно \\nоптимизировать путем применения процедуры численной оптимизации, такой как \\nградиентный спуск, который мы рассмотрим в главе 4. Обычно оптимизируется \\nнатуральный логарифм выражения в правой части уравнения 2.4, потому что ло-\\nгарифм произведения превращается в сумму логарифмов, а компьютерам проще \\nработать с суммой, чем с произведением1.\\n2.6. Параметры и гиперпараметры\\nГиперпараметр — это свойство алгоритма обучения, обычно (но не всегда) имеющее \\nчисловое значение. Это значение влияет на работу алгоритма. Гиперпараметры не \\nвычисляются алгоритмом. Они должны задаваться аналитиком перед запуском \\nалгоритма. Как это сделать, я покажу в главе 5.\\nПараметры — это переменные, которые определяют модель, обучаемую алгорит -\\nмом обучения. Параметры напрямую изменяются алгоритмом обучения на основе \\nобучающих данных. Цель обучения — найти такие значения параметров, которые \\nделают модель оптимальной в определенном смысле.\\n2.7. Классификация и регрессия\\nКлассификация — это задача автоматического определения метки для неразме\\xad\\nченного образца. Определение спама — один из ярких примеров классификации.\\nВ машинном обучении задача классификации решается с помощью алгоритма обу\\xad\\nчения классификации, который на входе принимает набор размеченных данных \\n1 Умножение большого количества чисел может дать очень маленький или очень большой \\nрезультат. Это часто приводит к проблеме переполнения, когда компьютер оказывается \\nне в состоянии сохранить в памяти такое экстремально маленькое или экстремально \\nбольшое число.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 39, 'page_label': '40'}, page_content='40   Глава 2. Обозначения и определения\\nи создает модель, которая принимает неразмеченный образец и возвращает либо \\nего метку непосредственно, либо число, на основании которого аналитик сможет \\nопределить метку. Примером такого числа является вероятность.\\nВ задаче классификации метка является членом конечного множества клас\\xad\\nсов. Если размер множества классов равен двум («больной»/«здоровый», \\n«спам»/«не_спам»), мы называем такую классификацию бинарной классифика\\xad\\nцией (в некоторых источниках ее также называют биномиальной). Классификация \\nс несколькими классами (также называемая мультиномиальной, или многоклас\\xad\\nсовой) — это задача классификации с тремя или более классами1.\\nНекоторые алгоритмы обучения допускают наличие более двух классов, но есть \\nтакие, которые по своей природе являются алгоритмами бинарной классификации. \\nСуществуют стратегии, позволяющие преобразовать алгоритм обучения бинарной \\nклассификации в алгоритм многоклассовой классификации. Об одной из них \\nя расскажу в главе 7.\\nРегрессия — это задача прогнозирования метки с действительным значением \\n(часто называют также целевым значением) для образца без метки. Оценка сто -\\nимости дома на основе таких его характеристик, как площадь, количество спален, \\nрасположение и т. д., — вот один из примеров регрессии.\\nЗадача регрессии решается с помощью алгоритма обучения регрессии, который \\nпринимает на входе набор размеченных данных и создает модель, которая может \\nпо неразмеченному образцу предсказать его целевое значение.\\n2.8. Обучение на основе моделей \\nи на основе примеров\\nБольшинство алгоритмов обучения с учителем основаны на моделях. Мы уже ви-\\nдели один такой алгоритм: метод опорных векторов (SVM). Алгоритмы обучения \\nна основе моделей анализируют обучающие данные и создают модель, параметры \\nкоторой определяются в ходе анализа обучающих данных. В SVM мы видели два \\nпараметра: w* и b*. После создания модели обучающие данные можно отбросить.\\nАлгоритмы обучения на основе примеров используют весь набор данных в качестве \\nмодели. Одним из наиболее часто используемых на практике алгоритмов обучения \\nна основе примеров является метод k ближайших соседей (k\\xadNearest Neighbors, \\nkNN). В проблеме классификации, для того чтобы спрогнозировать метку для \\n1 При этом каждому образцу соответствует единственная метка.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 40, 'page_label': '41'}, page_content='2.9. Поверхностное и глубокое обучение   41\\nвходного образца, алгоритм kNN просматривает ближайшие окрестности этого \\nобразца в пространстве векторов признаков и возвращает метку, которая чаще \\nвсего встречается в этой окрестности.\\n2.9. Поверхностное и глубокое обучение\\nАлгоритм поверхностного обучения выводит параметры модели непосредственно \\nиз признаков обучающих данных. Большинство алгоритмов обучения с учителем \\nявляются поверхностными. Известными исключениями являются алгоритмы обу-\\nчения нейронных сетей, особенно те, что строят нейронные сети с несколькими \\nслоями между входом и выходом. Такие нейронные сети называются глубокими \\nнейронными сетями. В глубоком обучении нейронной сети (или просто глубоком \\nобучении), в отличие от поверхностного обучения, большинство параметров моде-\\nли выводится не из признаков обучающих данных непосредственно, а из значений, \\nвозвращаемых предыдущими слоями.\\nНе переживайте, если что-то пока остается неясным. Мы подробно рассмотрим \\nнейронные сети в главе 6.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 41, 'page_label': '42'}, page_content='3\\nФундаментальные \\nалгоритмы\\nВ этой главе я опишу пять самых известных алгоритмов, которые являются либо \\nочень эффективными сами по себе, либо используются как строительные блоки \\nв других эффективных алгоритмах обучения.\\n3.1. Линейная регрессия\\nЛинейная регрессия — это популярный алгоритм обучения регрессии, который \\nстроит модель, являющуюся линейной комбинацией признаков входного образца.\\n3.1.1. Задача\\nДано: коллекция размеченных данных \\n , где N — размер коллекции, \\nxi — D-мерный вектор признаков образца i = 1, ..., N, yi — действительное целевое \\nзначение1, и каждый признак \\n , j = 1, ..., D также является действительным числом.\\nТребуется: сконструировать модель fw, b (x), являющуюся линейной комбинацией \\nпризнаков образца x:\\n \\n ,  (3.1)\\nгде w — D-мерный вектор параметров, а b — действительное число. Запись \\n  \\nозначает, что модель f параметризуется двумя значениями: w и b.\\n1 Чтобы показать, что yi является действительным целевым значением, мы пишем yi ∈ R, \\nгде R обозначает множество всех действительных чисел, бесконечное множество чисел \\nот минус бесконечности до плюс бесконечности.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 42, 'page_label': '43'}, page_content='3.1. Линейная регрессия   43\\nМодель будет использоваться для предсказания неизвестного целевого зна -\\nчения y для данного x: y ← fw, b (x). Разные модели, параметризованные раз -\\nными  парами ( w, b), могут давать разные предсказания для одного и того же \\nобразца. Нужно найти оптимальные значения (w*, b*). Очевидно, что оптималь-\\nные значения параметров определяют модель, которая дает наиболее точные \\nпрогнозы.\\nОбратите внимание, что линейная модель в уравнении. 3.1 очень похожа на модель \\nSVM. Единственное отличие — отсутствие оператора sign. Модели действитель -\\nно очень похожи. Однако в SVM гиперплоскость играет роль границы принятия \\nрешения: она используется для отделения двух групп данных друг от друга. Как \\nследствие, она должна проходить как можно дальше от каждой группы.\\nВ линейной регрессии, напротив, гиперплоскость проводится так, чтобы оказаться \\nкак можно ближе ко всем обучающим образцам.\\nЧтобы понять, почему это последнее требование является обязательным, взгля -\\nните на рис. 3.1. Здесь изображена линия регрессии (красным цветом) для \\nодномерных данных (синие точки). Эту линию можно использовать для про -\\nгнозирования целевого значения цели yнов. нового образца без метки xнов.. Если \\nбы данные были представлены D-мерными векторами признаков ( D > 1), тогда \\nрешение отличалось бы от одномерного случая тем, что регрессионная модель \\nбыла бы не линией, а плоскостью (в случае двух измерений) или гиперплоско -\\nстью (в случае D > 2).\\nлинейная регрессия\\nобучающие данные\\nyнов.\\nxнов.\\nРис. 3.1. Линейная регрессия для одномерных данных'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 43, 'page_label': '44'}, page_content='44   Глава 3. Фундаментальные алгоритмы\\nТеперь должно быть понятно, почему так важно требование к расположению ги-\\nперплоскости регрессии как можно ближе к обучающим образцам: если бы красная \\nлиния на рис. 3.1 была далека от синих точек, прогноз yнов. имел бы меньше шансов \\nоказаться верным.\\n3.1.2. Решение\\nЧтобы удовлетворить это последнее требование, процедура оптимизации, ис -\\nпользуемая для поиска оптимальных значений w* и b*, должна минимизировать \\nследующее выражение:\\n \\n .  (3.2)\\nВыражение, которое требуется минимизировать или максимизировать, в матема-\\nтике называется целевой функцией, или просто целью. Выражение (fw, b (xi) – yi)2 \\nв целевой функции выше называется функцией потерь . Она определяет ве -\\nличину штрафа за неправильную классификацию образца i. Эта конкретная \\nфункция потерь называется квадратичной функцией потерь  (squared error \\nloss). Все алгоритмы обучения, основанные на моделях, используют функцию \\nпотерь, и в поисках лучшей модели мы пытаемся минимизировать цель, извест -\\nную как функция стоимости  (cost function). В  линейной регрессии функция \\nстоимости определяется как средняя потеря, также называемая эмпирическим \\nриском (empirical risk). Средняя потеря, или эмпирический риск, для модели  — \\nэто среднее всех штрафов, полученных при применении модели к обучающим \\nданным.\\nПочему в линейной регрессии используется квадратичная функция потерь? И мож-\\nно ли взять абсолютное значение разности между истинным целевым значением yi \\nи прогнозируемым значением f (xi) и использовать его в качестве штрафа? Можно. \\nБолее того, можно использовать любую четную степень вместо квадрата.\\nТеперь, возможно, вы начинаете понимать, сколько решений, на первый взгляд \\nпроизвольных, принимается при разработке алгоритма машинного обучения: \\nв данном примере мы решили использовать линейную комбинацию признаков \\nдля прогнозирования целевого значения. Однако для объединения значений при-\\nзнаков мы могли бы использовать квадрат или другой многочлен. Мы могли бы \\nтакже использовать другую функцию потерь, не лишенную смысла: абсолютная \\nразность между f (xi) и yi имеет смысл, куб разности — тоже; бинарная функция \\nпотерь (возвращающая 1, когда f (xi) и yi различны, и 0 — когда они одинаковы) \\nтоже имеет смысл, верно?'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 44, 'page_label': '45'}, page_content='3.1. Линейная регрессия   45\\nПриняв другое решение о форме модели, форме функции потерь и о выборе алго-\\nритма минимизации средней потери, чтобы найти лучшие значения параметров, мы \\nв итоге изобрели бы другой алгоритм машинного обучения. Кажется, все просто, \\nне правда ли? Но не спешите изобретать новый алгоритм обучения. Тот факт, что \\nон отличается от имеющихся, не означает, что он будет работать лучше.\\nНовые алгоритмы обучения изобретают по одной из двух основных причин:\\n1. Новый алгоритм решает конкретную практическую задачу лучше существу -\\nющих.\\n2. Новый алгоритм имеет более надежные теоретические гарантии качества про-\\nизводимой им модели.\\nОдним из практических обоснований выбора модели линейной формы является \\nее простота. Зачем использовать сложную модель, если можно использовать про-\\nстую? Другое обоснование: линейные модели в меньшей степени подвержены \\nэффекту переобучения. Переобучение (overfitting) — это свойство модели очень \\nхорошо предсказывать метки данных, использовавшихся для обучения, но часто \\nдопускать ошибки при применении к образцам, которые алгоритм обучения не \\nвидел прежде.\\nрегрессия с полиномом \\nстепени 10\\nобучающие данные\\nРис. 3.2. Переобучение\\nНа рис. 3.2 показан пример переобучения в регрессии. Для построения красной ли-\\nнии регрессии использовались те же данные, что и для линии регрессии на рис. 3.1. \\nРазница лишь в том, что на этот раз выполнялась полиномиальная регрессия с по-'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 45, 'page_label': '46'}, page_content='46   Глава 3. Фундаментальные алгоритмы\\nлиномом степени 101. Линия регрессии почти идеально предсказывает целевые \\nзначения для большинства обучающих данных, но, скорее всего, будет допускать \\nзначительные ошибки на новых данных, как показано на рис. 3.1 для xнов.. Мы еще \\nвернемся к проблеме переобучения в главе 5 и поговорим о том, как его избежать.\\nТеперь вы знаете одно из преимуществ линейной регрессии: она мало подвержена \\nпереобучению. А что можно сказать в отношении выбора квадратичной функции \\nпотерь? Почему мы решили, что потери нужно возводить в квадрат? В 1805 году \\nфранцузский математик Адриен-Мари Лежандр (Adrien-Marie Legendre), который \\nпервым опубликовал метод подсчета суммы квадратов для оценки качества моделей, \\nзаявил, что возведение ошибки в квадрат до суммирования — это удобно. Почему \\nон так сказал? Абсолютное значение неудобно, потому что не имеет непрерывной \\nпроизводной, что делает функцию негладкой. Негладкие функции создают ненуж-\\nные сложности, когда для поиска аналитических решений оптимизационных задач \\nиспользуются методы линейной алгебры. Аналитические решения для нахождения \\nоптимума функции — это простые алгебраические выражения, и они часто предпо-\\nчтительнее использования сложных численных методов оптимизации, таких как гра\\xad\\nдиентный спуск (используется для обучения нейронных сетей, кроме всего прочего).\\nОчевидно, что квадраты штрафов выгодны еще и потому, что преувеличивают раз-\\nность между истинным и прогнозируемым целевыми значениями, в соответствии \\nс величиной этой разности. Также можно использовать другие четные степени, \\nтакие как 4 или 6,, но работать с их производными сложнее.\\nНаконец, зачем нам нужна производная средней потери? Вычислив градиент функ-\\nции в уравнении 3.2, мы сможем затем установить этот градиент в ноль2 и найти \\nрешение системы уравнений, которое даст нам оптимальные значения w* и b*.\\n3.2. Логистическая регрессия\\nСразу должен сказать, что логистическая регрессия — это не регрессия, а алгоритм \\nобучения классификации. Название происходит из статистики и связано с тем, что \\nматематическая формулировка логистической регрессии аналогична линейной \\nрегрессии.\\n1 В полиномиальной регрессии степени n, f(x) имеет дополнительный параметр для ар -\\nгумента x, возведенного в каждую из степеней от 1 до 10, то есть f(x) =def w1x1 + w2x2 +  \\n+ … + wnxn + b″.\\n2 Чтобы найти минимум или максимум функции, мы устанавливаем градиент в ноль, по-\\nтому в точках экстремума функции значение градиента всегда равно нулю. В двумерном \\nслучае градиент экстремума — это горизонтальная линия.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 46, 'page_label': '47'}, page_content='3.2. Логистическая регрессия   47\\nЯ объясняю суть логистической регрессии на примере бинарной классификации. \\nОднако его можно естественным образом распространить на многоклассовую \\nклассификацию.\\n3.2.1. Задача\\nЦель логистической регрессии все та же: смоделировать yi как линейную функцию \\nот xi, однако для бинарных значений yi это не так просто. Линейная комбинация \\nпризнаков, такая как \\n , — это функция, простирающаяся от минус бесконеч-\\nности до плюс бесконечности, тогда как yi имеет только два возможных значения.\\nВо времена, когда не было компьютеров и все вычисления приходилось выполнять \\nвручную, ученые отдавали предпочтение моделям линейной классификации. В ту \\nпору они подметили, что если определить отрицательную метку как 0, а положи-\\nтельную метку как 1, достаточно найти простую непрерывную функцию с областью \\nзначений (0, 1). В этом случае, если значение, возвращаемое моделью для образца x, \\nближе к 0, ему присваивается отрицательная метка; иначе образец маркируется как \\nположительный. Одной из функций, обладающих таким свойством, является стан\\xad\\nдартная логистическая функция (также известная как логистический сигмоид):\\n,\\nгде e — основание натурального логарифма (также называется числом Эйлера ; \\nзначение ex в языках программирования также известно как функция exp(x)). Ее \\nграфик изображен на рис. 3.3.\\nВот как выглядит модель логистической регрессии:\\n \\n .  (3.3)\\nКак видите, здесь присутствует уже знакомый нам член wx + b из линейной ре -\\nгрессии.\\nВзглянув на график стандартной логистической функции, можно заметить, \\nнасколько хорошо она соответствует нашей цели классификации: если соот -\\nветствующим образом оптимизировать значения w и b, результат f(x) можно \\nинтерпретировать как вероятность, что yi будет иметь положительное значение. \\nНапример, если она выше или равна пороговому значению 0.5, мы бы сказали, что \\nкласс x положителен; иначе — отрицателен. На практике могут выбираться другие \\nпороговые значения, в зависимости от решаемой задачи. Мы вернемся к этой теме \\nв главе 5, когда будем говорить об оценке эффективности модели.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 47, 'page_label': '48'}, page_content='48   Глава 3. Фундаментальные алгоритмы\\nРис. 3.3. Стандартная логистическая функция\\nКак теперь найти оптимальные оценки w* и b*? В линейной регрессии мы минимизи-\\nровали эмпирический риск, который определялся как среднее квадратичной функции \\nпотерь, также известное как среднеквадратичная ошибка (mean squared error, MSE).\\n3.2.2. Решение\\nВ логистической регрессии, в отличие от линейной регрессии, максимизируется \\nправдоподобие  (вероятность) обучающего набора в соответствии с моделью. \\nВ статистике функция правдоподобия определяет, насколько правдоподобным \\nвыглядит наблюдение (образец) в соответствии с нашей моделью.\\nНапример, допустим, что в нашем обучающем наборе имеется размеченный об -\\nразец (xi, yi). Предположим также, что мы нашли (выбрали) некоторые конкрет -\\nные значения \\n  и \\n  для наших параметров. Если теперь применить модель \\n  \\nк xi, используя уравнение 3.3, мы получим некоторое значение 0 < p < 1. Если yi \\nявляется положительным классом, вероятность, что yi является положительным \\nклассом, согласно нашей модели, определяется как p. Аналогично, если yi является \\nотрицательным классом, вероятность, что он является отрицательным классом, \\nопределяется как 1 – p.\\nКритерий оптимизации в логистической регрессии называется максимальным \\nправдоподобием (maximum likelihood). Вместо того чтобы минимизировать сред-\\nнюю потерю, как в линейной регрессии, мы теперь максимизируем правдоподобие \\nобучающих данных в соответствии с моделью:'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 48, 'page_label': '49'}, page_content='3.3. Обучение дерева решений   49\\n \\n .  (3.4)\\nВыражение \\n  может показаться пугающим, но это всего лишь \\nпричудливый математический способ сказать: «f w, b (x), когда yi = 1, и (1 – f w, b (x)) \\nиначе». Действительно, если yi = 1, тогда \\n равно 1, потому что \\n(1 – yi) = 0, а как мы знаем, любое число в степени 0 равно 1. С другой стороны, \\nесли yi = 0, тогда \\n  равно 1 по той же причине.\\nВозможно, вы обратили внимание, что в целевой функции мы использовали опера-\\nтор произведения \\n  вместо оператора суммы \\n , который применялся в линейной \\nрегрессии. Это связано с тем, что вероятность наблюдения N меток в N образцах \\nявляется произведением вероятностей каждого наблюдения (при условии, что все \\nнаблюдения независимы друг от друга, что в нашем случае действительно так). \\nМожно провести параллель с  умножением вероятностей исходов в  серии неза-\\nвисимых экспериментов в теории вероятностей.\\nПоскольку в модели используется функция exp, на практике удобнее максимизи-\\nровать логарифм правдоподобия, а не правдоподобие. Логарифм правдоподобия \\nопределяется следующим образом:\\n.\\nПоскольку ln — строго возрастающая функция , ее максимизация равносильна \\nмаксимизации ее аргумента, а решение этой новой задачи оптимизации равно -\\nсильно решению исходной задачи.\\nВ отличие от линейной регрессии, задача оптимизации выше не имеет аналитиче-\\nского решения. Поэтому в таких случаях обычно используется процедура числен-\\nной оптимизации — градиентный спуск. Но об этом мы поговорим в следующей \\nглаве.\\n3.3. Обучение дерева решений\\nДерево решений — это ациклический граф, который можно использовать для \\nпринятия решений. В каждом ветвящемся узле графа исследуется j-й признак из \\nвектора признаков. Если значение признака ниже определенного порога, выби -\\nрается левая ветвь; иначе — правая. По достижении листового узла принимается \\nрешение о классе, к которому относится образец.\\nКак следует из заголовка раздела, дерево решений можно получить из данных.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 49, 'page_label': '50'}, page_content='50   Глава 3. Фундаментальные алгоритмы\\n3.3.1. Задача\\nКак и прежде, дано: коллекция размеченных данных; метки принадлежат множе-\\nству {0, 1}. Нужно построить дерево решений, которое позволило бы предсказать \\nкласс по заданному вектору признаков.\\n3.3.2. Решение\\nСуществуют различные формулировки алгоритма обучения дерева решений. \\nВ этой книге мы рассмотрим только один, который называется ID3.\\nКритерием оптимизации в данном случае является среднее логарифмическое \\nправдоподобие:\\n \\n ,  (3.5)\\nгде fID3 — дерево решений.\\nПока все выглядит похожим на логистическую регрессию. Однако, в отличие от \\nалгоритма обучения логистической регрессии, который строит параметрическую \\nмодель \\n  путем поиска оптимального решения критерия оптимизации, алго -\\nритм ID3 оптимизирует его приблизительно, конструируя непараметрическую \\nмодель \\n .\\nАлгоритм обучения ID3 работает следующим образом. Пусть S обозначает мно-\\nжество размеченных данных. В начале дерево решений имеет только начальный \\nузел, который содержит все данные: \\n . Начнем с постоянной модели \\n, которая определяется как\\n \\n .  (3.6)\\nВышеупомянутая модель \\n  будет возвращать один и тот же прогноз для \\nлюбого входа x. Соответствующее дерево решений, построенное на основе нашего \\nфиктивного набора данных из 12 размеченных данных, показано на рис. 3.4a.\\nЗатем мы ищем все признаки j = 1, ..., D и все пороги t и разбиваем множество S \\nна два подмножества: \\n  и \\n . \\nДва новых подмножества образуют два новых листовых узла, и мы оцениваем для'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 50, 'page_label': '51'}, page_content='3.3. Обучение дерева решений   51\\nвсех возможных пар (j, t), насколько хорошим получилось расщепление на части \\nS– и S+. Наконец, выбираем наилучшие значения ( j, t), разбиваем S на S– и S+, \\nформируем два новых листовых узла и продолжаем рекурсивно разбивать на \\nS– и S+ (или завершаем работу, если ни одно разбиение не дает модели, которая \\nпозволяет получить лучший прогноз, чем текущая). Дерево решений после одного \\nрасщепления показано на рис. 3.4б.\\nS={(x1, y1), (x2, y2), (x3, y3),\\n(x4, y4), (x5, y5), (x6, y6),\\n(x7, y7), (x8, y8), (x9, y9),\\n(x10, y10), (x11, y11), (x12, y12)}\\nx\\nPr(y = 1|x) = (y1+y2+y3+y4+y5 \\n+y6+y7+y8+y9+y10+y11+y12)/12\\nPr(y = 1|x)\\n(a)\\nx\\nPr(y = 1|x) = (y1+y2+y4 \\n+y6+y7+y8+y9)/7\\nPr(y = 1|x)\\nx(3) < 18.3?\\nS- = {(x1, y1), (x2, y2),\\n(x4, y4), (x6, y6), (x7, y7),\\n(x8, y8), (x9, y9)} \\nPr(y = 1|x) =\\n(y3+y5+y10+y11+y12)/5\\nPr(y = 1|x)\\nS+ = {(x3, y3), (x5, y5), (x10, y10),\\n(x11, y11), (x12, y12)} \\nДа Нет\\n(б)\\n+ +\\n=\\nРис. 3.4. Иллюстрация алгоритма построения дерева решений. Множество S содержит \\n12 размеченных данных. (a) Вначале дерево решений содержит только начальный узел; он \\nдает один и тот же прогноз для любого входа. (б) Дерево решений после первого расщеп-\\nления; оно проверяет, является ли признак 3 меньше 18.3, и, в зависимости от результата, \\nпрогноз выполняется одним из двух листовых узлов\\nТеперь у вас наверняка возник вопрос, что означают слова «оценить, насколько \\nхорошим получилось расщепление». В ID3 качество расщепления оценивается \\nс использованием критерия, называемого энтропией. Энтропия — это мера не -\\nопределенности случайной величины. Она достигает своего максимума, когда все \\nзначения случайной величины равновероятны. Энтропия достигает своего мини-\\nмума, когда случайная величина может иметь только одно значение. Энтропия \\nмножества данных S определяется как\\n.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 51, 'page_label': '52'}, page_content='52   Глава 3. Фундаментальные алгоритмы\\nКогда мы разбиваем множество данных по некоторому признаку j и порогу t, эн-\\nтропия разбиения \\n  определяется как простая взвешенная сумма двух \\nэнтропий:\\n \\n .  (3.7)\\nИтак, в ID3, на каждом шаге, в каждом листовом узле мы находим расщепление, \\nминимизирующее энтропию, заданную уравнением 3.7, или останавливаемся на \\nэтом листовом узле.\\nАлгоритм останавливается на листовом узле в любой из следующих ситуаций:\\n  Все примеры в листовом узле правильно классифицируются моделью (урав -\\nнение 3.6).\\n  Невозможно найти атрибут для расщепления.\\n  Расщепление уменьшает энтропию ниже некоторого значения ε (которое нуж-\\nно определить экспериментально1).\\n  Дерево достигает некоторой максимальной глубины d (также должна опреде-\\nляться экспериментально).\\nПоскольку в ID3 решение о расщеплении набора данных в каждой итерации явля-\\nется локальным (не зависит от будущих расщеплений), алгоритм не гарантирует \\nоптимального решения. Модель можно улучшить, использовав в процессе поиска \\nоптимального дерева решений такие методы, как возврат (backtracking), хотя и за \\nсчет увеличения времени построения модели.\\nНаиболее широко используемая версия алгоритма обучения дерева решений на -\\nзывается C4.5. Она имеет несколько дополнительных особенностей по сравнению \\nс ID3:\\n  принимает непрерывные и дискретные признаки;\\n  поддерживает возможность обработки неполных данных;\\n  решает проблему переобучения с использованием восходящего метода, из -\\nвестного как «подрезка» (отсечение ветвей).\\nПодрезка заключается в том, чтобы выполнить обратный обход только что создан-\\nного дерева и удалить ветви, которые не вносят существенного вклада в уменьше-\\nние ошибки, заменив их листовыми узлами.\\n1 Я покажу, как это сделать, в главе 5, в разделе, посвященном настройке гиперпараметров.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 52, 'page_label': '53'}, page_content='3.4. Метод опорных векторов   53\\nКогда мы разбиваем множество данных по некоторому признаку j и порогу t, эн-\\nтропия разбиения  определяется как простая взвешенная сумма двух \\nэнтропий:\\n .  (3.7)\\nИтак, в ID3, на каждом шаге, в каждом листовом узле мы находим расщепление, \\nминимизирующее энтропию, заданную уравнением 3.7, или останавливаемся на \\nэтом листовом узле.\\nАлгоритм останавливается на листовом узле в любой из следующих ситуаций:\\n  Все примеры в листовом узле правильно классифицируются моделью (урав -\\nнение 3.6).\\n  Невозможно найти атрибут для расщепления.\\n  Расщепление уменьшает энтропию ниже некоторого значения ε (которое нуж-\\nно определить экспериментально1).\\n  Дерево достигает некоторой максимальной глубины d (также должна опреде-\\nляться экспериментально).\\nПоскольку в ID3 решение о расщеплении набора данных в каждой итерации явля-\\nется локальным (не зависит от будущих расщеплений), алгоритм не гарантирует \\nоптимального решения. Модель можно улучшить, использовав в процессе поиска \\nоптимального дерева решений такие методы, как возврат (backtracking), хотя и за \\nсчет увеличения времени построения модели.\\nНаиболее широко используемая версия алгоритма обучения дерева решений на -\\nзывается C4.5. Она имеет несколько дополнительных особенностей по сравнению \\nс ID3:\\n  принимает непрерывные и дискретные признаки;\\n  поддерживает возможность обработки неполных данных;\\n  решает проблему переобучения с использованием восходящего метода, из -\\nвестного как «подрезка» (отсечение ветвей).\\nПодрезка заключается в том, чтобы выполнить обратный обход только что создан-\\nного дерева и удалить ветви, которые не вносят существенного вклада в уменьше-\\nние ошибки, заменив их листовыми узлами.\\n1 Я покажу, как это сделать, в главе 5, в разделе, посвященном настройке гиперпараметров.\\nСмысл критерия расщепления на основе энтропии очевиден: эн -\\nтропия достигает минимальной величины 0, когда все данные в S \\nимеют одинаковую метку; с другой стороны, энтропия достигает \\nмаксимальной величины 1, когда ровно половина примеров в S \\nимеет метку 1, что делает такой лист бесполезным для классифи-\\nкации. Единственный оставшийся вопрос — как этот алгоритм \\nприблизительно максимизирует средний логарифм правдоподобия. Я предлагаю \\nчитателям выяснить это самостоятельно.\\n3.4. Метод опорных векторов\\nЯ уже представлял метод опорных векторов (SVM) во введении, поэтому здесь \\nвосполню лишь несколько пробелов. Вот два важных вопроса, которые мы должны \\nзадать:\\n1. Как быть, если исходные данные настолько искажены помехами, что невоз -\\nможно найти гиперплоскость, четко разделяющую положительные и отрица-\\nтельные данные?\\n2. Что если данные нельзя разделить с помощью плоскости, но можно с помощью \\nполинома более высокого порядка?\\nОбе эти ситуации изображены на рис. 3.5. Слева показан случай, когда данные \\nнельзя разделить прямой линией из-за шума (аномальных выбросов или непра -\\nвильно размеченных данных). Справа границей решения является окружность, \\nа не прямая линия.\\nНапомню, что, используя метод опорных векторов, мы должны удовлетворить \\nследующие ограничения:\\n wxi – b ≥ + 1, если yi  = +1,  \\n wxi – b ≤ –1, если yi  = –1.  \\n(3.8)\\nТакже мы должны минимизировать || w||, чтобы гиперплоскость была одинаково \\nудалена от ближайших данных каждого класса. Минимизация || w|| эквивалентна \\nминимизации \\n , и использование этого члена позволит нам в дальнейшем \\nвыполнять оптимизацию квадратичного программирования. Соответственно, за-\\nдача оптимизации в SVM выглядит следующим образом:\\n \\n .  (3.9)'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 53, 'page_label': '54'}, page_content='54   Глава 3. Фундаментальные алгоритмы\\nРис. 3.5. Случаи, неразделимые линейно. Сверху: присутствует шум.  \\nСнизу: естественная нелинейность\\n3.4.1. Работа с шумом\\nЧтобы распространить SVM на случаи, когда данные невозможно разделить \\nлинейно, введем кусочно\\xadлинейную функцию потерь  (hinge loss function): \\nmax (0,1 – yi (wxi – b)).\\nКусочно-линейная функция потерь равна нулю, если выполнены условия 3.8, то \\nесть если wxi лежит с правильной стороны от границы решения. Для данных, ле-\\nжащих с неправильной стороны, значение функции пропорционально расстоянию \\nот границы решения.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 54, 'page_label': '55'}, page_content='3.4. Метод опорных векторов   55\\nЗатем минимизируем следующую функцию стоимости:\\n,\\nгде гиперпараметр C определяет компромисс между увеличением размера грани-\\nцы решения и гарантией местонахождения каждого xi с правильной стороны от \\nграницы решения. Значение C обычно выбирается экспериментально, как и ги-\\nперпараметры ϵ и d в ID3.\\nАлгоритм SVM, оптимизирующий кусочно-линейную функцию потерь, называ -\\nют алгоритмом SVM с мягким зазором (soft-margin SVM), тогда как алгоритм \\nв оригинальной формулировке называют алгоритмом SVM с жестким зазором \\n(hard-margin SVM).\\nКак нетрудно заметить, при достаточно высоких значениях C второй член в функ-\\nции стоимости становится пренебрежимо малым, поэтому алгоритм SVM будет \\nпытаться найти наибольший зазор, полностью игнорируя ошибочную классифи-\\nкацию. По мере уменьшения значения C ошибки классификации становятся более \\nдорогостоящими, поэтому алгоритм SVM будет пытаться делать меньше ошибок, \\nжертвуя размером зазора. Как уже говорилось, больший зазор дает лучшее обоб-\\nщение. Следовательно, C регулирует компромисс между хорошей классификацией \\nобучающих данных (минимальный эмпирический риск) и хорошей классифика-\\nцией данных в будущем (обобщение).\\n3.4.2. Работа с естественной нелинейностью\\nSVM можно адаптировать для работы с наборами данных, которые нельзя раз -\\nделить гиперплоскостью в исходном пространстве. Действительно, если удастся \\nпреобразовать исходное пространство в пространство более высокой размерности, \\nможно надеяться, что данные станут линейно разделимыми в этом преобразован-\\nном пространстве. Использование функции для неявного преобразования исход-\\nного пространства в пространство более высокой размерности в ходе оптимизации \\nфункции стоимости в SVM называется ядерным трюком (kernel trick).\\nНа рис. 3.6 показан эффект применения ядерного трюка. Как видите, двумерные \\nданные, не разделимые линейно, можно преобразовать в линейно разделимые \\nтрехмерные данные, используя специальное отображение \\n , где \\n — вектор с более высокой размерностью, чем x. Например, к двумерным \\nданным, изображенным на рис. 3.5 (справа), можно применить отображение, \\nпроеци рующее двумерные данные x = [q, p] в трехмерное пространство (рис. 3.6), \\nко торое выглядит т ак: \\n , где \\n  — это возведение в ква-'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 55, 'page_label': '56'}, page_content='56   Глава 3. Фундаментальные алгоритмы\\nдрат. После преобразования данные становятся линейно разделимыми в новом \\nпространстве.\\nРис. 3.6. Данные, представленные на рис. 3.5 (снизу), становятся линейно разделимыми \\nпосле преобразования в трехмерное пространство\\nОднако заранее неизвестно, какое отображение подойдет для наших данных. \\nЕсли преобразовывать все входные данные в векторы с более высокой размер -\\nностью и применять к ним SVM, опробуя все возможные функции отображения, \\nвычисления могут стать очень неэффективными и мы никогда не решим задачу \\nклассификации.\\nК счастью, ученые выяснили, как использовать функции ядр\\ue088а (или просто \\ue088ядра) \\nдля эффективной работы в многомерных пространствах без явного преобразова-\\nния. Чтобы понять, как работают ядра, прежде нужно посмотреть, как алгоритм \\nоптимизации для SVM находит оптимальные значения для w и b.\\nДля решения задачи оптимизации в уравнении 3.9 традиционно используется ме\\xad\\nтод множителей Лагранжа. Вместо оригинальной задачи из уравнения 3.9 проще \\nрешить эквивалентную задачу, сформулированную так:\\nгде αi называются множителями Лагранжа. В такой формулировке задача \\nоптимизации превращается в выпуклую задачу квадратичной оптимизации, \\nкоторая эффективно решается применением алгоритмов квадратичного про -\\nграммирования.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 56, 'page_label': '57'}, page_content='3.5. Метод k ближайших соседей   57\\nОбратите внимание, что в формулировке выше присутствует член xi xk, это един-\\nственное место, где используются векторы признаков. Чтобы преобразовать ис -\\nходное векторное пространство в пространство с большим числом измерений, \\nнужно преобразовать xi в ϕ(xi) и xk в ϕ(xk), а затем перемножить ϕ(xi) и ϕ(xk). Эти \\nвычисления могут оказаться очень дорогостоящими.\\nС другой стороны, нас интересует только результат скалярного произведения xixk, \\nкоторый, как мы знаем, является действительным числом. Нам все равно, как будет \\nполучено это число, лишь бы оно было верным. Используя функцию ядра, можно \\nизбавиться от дорогостоящего преобразования исходных векторов признаков \\nв векторы с более высокой размерностью и избежать необходимости вычислять \\nих скалярное произведение. Мы заменим эти вычисления простой операцией с ис-\\nходными векторами признаков, которая даст тот же результат. Например, вместо \\nпреобразования \\n  в \\n  и \\n  в \\n  и последу-\\nющего вычисления скалярного произведения \\n  и \\n , \\nчтобы получить \\n , можно найти скалярное произведение \\n и \\n , чтобы получить \\n , а затем возвести в квадрат, чтобы \\nполучить тот же результат \\n .\\nЭто был пример функции ядра, и мы использовали квадратичное ядро \\n. Существует несколько функций ядра, из которых наиболее \\nшироко используется ядро RBF:\\n,\\nгде \\n  — квадрат евклидова расстояния между двумя векторами признаков. \\nЕвклидово расстояние определяется следующим уравнением:\\nМожно показать, что пространство признаков ядра RBF (Radial Basis Function — \\nрадиальная базисная функция) имеет бесконечное число измерений. Изменяя \\nгиперпараметр σ, аналитик может выбирать между гладкой или изогнутой границей \\nрешения в исходном пространстве.\\n3.5. Метод k ближайших соседей\\nМетод k ближайших соседей (k-Nearest Neighbors, kNN) — это непараметрический \\nалгоритм обучения. В отличие от других алгоритмов обучения, позволяющих от-'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 57, 'page_label': '58'}, page_content='58   Глава 3. Фундаментальные алгоритмы\\nбрасывать обучающие данные после построения модели, метод kNN сохраняет все \\nобучающие примеры в памяти. Когда появляется новый, ранее не встречавшийся \\nобразец x, алгоритм kNN находит k обучающих данных, наиболее близких к x, \\nи возвращает наиболее часто встречающуюся метку в случае классификации или \\nсреднее значение метки в случае регрессии.\\nБлизость двух данных определяется функцией расстояния. Например, на практике \\nчасто используется евклидово расстояние, показанное выше. Также нередко ис -\\nпользуется еще одна функция расстояния — отрицательное косинусное сходство. \\nКосинусное сходство, которое определяется как\\nявляется мерой сходства направлений двух векторов. Если угол между двумя век-\\nторами равен 0 градусов, значит, они указывают в одном направлении и косинусное \\nсходство равно 1. Если векторы ортогональны, косинусное сходство равно 0. Для \\nвекторов, указывающих в противоположных направлениях, косинусное сходство \\nравно –1. Чтобы использовать косинусное сходство в качестве меры расстояния, \\nего значение нужно умножить на –1. В числе других популярных мер расстояния \\nможно назвать расстояние Чебышева, расстояние Махаланобиса и расстояние \\nХемминга. Выбор меры, а также значения для k должен сделать аналитик перед \\nзапуском алгоритма. То есть все это — гиперпараметры. Меру расстояния также \\nможно вывести из данных. Мы поговорим об этом в главе 10.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 58, 'page_label': '59'}, page_content='4\\nАнатомия алгоритмов \\nобучения\\n4.1. Строительные блоки \\nалгоритмов обучения\\nЧитая предыдущую главу, вы могли заметить, что все рассмотренные там методы \\nсостоят из трех частей:\\n1. Функция потерь.\\n2. Критерий оптимизации, основанный на функции потерь (например, функция \\nстоимости).\\n3. Процедура оптимизации, использующая обучающие данные для поиска реше-\\nния критерия оптимизации.\\nЭти строительные блоки присутствуют во всех методах обучения. В предыдущей \\nглаве вы видели, что одни методы предполагают явную оптимизацию определен-\\nного критерия (линейная и логистическая регрессия, SVM). Другие, включая об-\\nучение дерева решений и kNN, оптимизируют критерий неявно. Обу чение дерева \\nрешений и kNN являются одними из самых старых методов машинного обучения \\nи были изобретены экспериментально на основе интуитивных представлений, \\nбез наличия конкретных глобальных критериев оптимизации, которые (как это \\nчасто случалось в истории науки) были разработаны позже, чтобы объяснить, как \\nработают эти методы.\\nВ современной литературе по машинному обучению часто можно встретить по -\\nнятия градиентный спуск или стохастический градиентный спуск. Это два наи-\\nболее часто используемых метода оптимизации, которые применяются в случаях \\nиспользования дифференцируемого критерия оптимизации.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 59, 'page_label': '60'}, page_content='60   Глава 4. Анатомия алгоритмов обучения\\nГрадиентный спуск — это метод итеративной оптимизации для поиска минимума \\nфункции. Чтобы найти локальный минимум функции с использованием градиент-\\nного спуска, нужно выбрать некоторую случайную точку и шагать в направлении \\nотрицательных значений градиента (или аппроксимации градиента) функции \\nв текущей точке.\\nГрадиентный спуск можно использовать для поиска оптимальных параметров \\nлинейной и логистической регрессии, SVM, а также нейронных сетей, которые \\nмы рассмотрим позже. Для многих моделей, таких как логистическая регрессия \\nи SVM, критерий оптимизации является выпуклым. Выпуклые функции имеют \\nтолько один минимум, который является глобальным. Критерии оптимизации \\nдля нейронных сетей не являются выпуклыми, но на практике часто достаточно \\nнайти хотя бы локальный минимум.\\nДавайте посмотрим, как работает градиентный спуск.\\n4.2. Градиентный спуск\\nВ этом разделе я покажу, как градиентный спуск находит решение задачи линейной \\nрегрессии1. Свое описание я проиллюстрирую с помощью кода на Python, а также \\nграфиков, показывающих, как решение улучшается после нескольких итераций \\nградиентного спуска. В примере я использую набор данных с единственным при-\\nзнаком. Однако критерий оптимизации будет иметь два параметра: w и b. Распро-\\nстранение примера на многомерные обучающие данные делается просто: нужно \\nиспользовать переменные w(1), w(2) и b в случае с двумерными данными, w(1), w(2), \\nw(3) и b в случае с трехмерными данными и т. д.\\nЧтобы придать примеру практический характер, я  использую реальный набор \\nданных (его можно найти в вики для книги) со следующими столбцами: ежегод-\\nные расходы различных компаний на рекламу по радио и их ежегодные объемы \\nпродаж в пересчете на проданные штуки. Нам нужно построить регрессионную \\nмодель, которую можно использовать для прогнозирования продаж в зависимо-\\nсти от расходов на рекламу. Каждая строка в наборе данных представляет одну \\nконкретную компанию.\\nВ наборе содержатся данные по 200 компаниям, соответственно, у нас имеется \\n200 обучающих данных в форме (xi, yi) = (Затратыi, Продажиi). На рис. 4.1 по-\\nказана двумерная диаграмма со всеми образцами.\\n1 Как известно, линейная регрессия имеет аналитическое решение. То есть для решения за-\\nдач этого конкретного типа градиентный спуск не требуется. Однако линейная регрессия \\nявляется идеальным примером для объяснения градиентного спуска.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 60, 'page_label': '61'}, page_content='4.2. Градиентный спуск   61\\nОб ъем продаж, в штуках\\nЗатраты, млн долл.\\nОб ъем продаж как функция от затрат на рекламу по радио\\nРис. 4.1. Исходные данные. Ось Y соответствует объему продаж в штуках  \\n(который мы должны предсказать), ось X соответствует признаку:  \\nзатратам на рекламу по радио в млн долл.\\nКомпания Затраты, M$ Продажи, в штуках\\n1 37.8 22.1\\n2 39.3 10.4\\n3 45.9 9.3\\n4 41.3 18.5\\n... ... ...\\nНапомню, что модель линейной регрессии выглядит следующим образом: \\nf(x) = wx + b. Мы не знаем оптимальных значений w и b и должны определить их \\nиз данных. Для этого мы найдем такие значения w и b, которые минимизируют \\nсреднеквадратичную ошибку:\\nГрадиентный спуск начинается с вычисления частной производной для каждого \\nпараметра:'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 61, 'page_label': '62'}, page_content='62   Глава 4. Анатомия алгоритмов обучения\\n \\n   (4.1)\\nЧтобы найти частную производную члена (yi – (wx + b))2 относительно w, я при-\\nменил правило дифференцирования сложной функции. Здесь мы имеем составную \\nфункцию f = f2 (f1), где  f1 = yi – (wx + b) и  f2  = f1\\n2. Чтобы найти частную производ-\\nную f относительно w, нужно сначала найти частную производную f относительно \\nf2, которая равна 2(yi – (wx + b)) (из теории вычислений мы знаем, что производная \\n), а затем умножить ее на частную производную yi – (wx + b) относи-\\nтельно w, равную – x. То есть в целом получаем \\n . \\nАналогично вычисляется частная производная l относительно b, \\n .\\nГрадиентный спуск выполняется этапами, или эпохами. В каждой эпохе произво-\\nдится уточнение каждого параметра с использованием всего обучающего набора. \\nВ начале, в первую эпоху, мы инициализируем1 w ← 0 и b ← 0. Частные производ-\\nные, \\n  и \\n , заданные уравнениями 4.1, равны соответственно \\n  и \\n. В каждую эпоху с использованием частных производных производится \\nуточнение w и b. Скорость обучения α контролирует размер уточнения:\\n \\n   (4.2)\\nМы вычитаем частные производные из значений параметров (а не прибавляем), \\nпотому что производные являются индикаторами роста функции. Если производ-\\nная положительна в некоторой точке2, значит, функция возрастает в этой точке. \\n1 В сложных моделях, таких как нейронные сети, имеющих тысячи параметров, инициа -\\nлизация параметров может существенно повлиять на решение, найденное градиентным \\nспуском. Существуют разные методы инициализации (случайными значениями, нулями, \\nнебольшими значениями, близкими к нулю, и т. д.), и этот важный выбор должен сделать \\nаналитик.\\n2 Точка задается текущими значениями параметров.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 62, 'page_label': '63'}, page_content='4.2. Градиентный спуск   63\\nПоскольку мы минимизируем целевую функцию, для положительного значения \\nпроизводной мы должны скорректировать параметр в противоположном направ-\\nлении (сместить влево на оси координат). Для отрицательного значения производ-\\nной (функция убывает) мы должны сместить параметр вправо, чтобы еще больше \\nуменьшить значение функции. Вычитание отрицательного значения из параметра \\nсмещает его вправо.\\nВ следующую эпоху мы повторно вычисляем производные, используя уравне -\\nние 4.1 с измененными значениями w и b; процесс продолжается до схождения. \\nОбычно требуется пройти много эпох, пока не обнаружится, что значения w и b \\nмало меняются после каждой эпохи; после этого процесс останавливается.\\nТрудно представить инженера по машинному обучению, который не использует \\nязык программирования Python. Поэтому, если вы ждали удобного момента для \\nизучения Python, он настал. Ниже я покажу, как запрограммировать градиентный \\nспуск на Python.\\nНиже показана функция, корректирующая параметры w и b в ходе одной эпохи:\\n 1 def update_w_and_b(spendings, sales, w, b, alpha):\\n 2     dl_dw = 0.0\\n 3     dl_db = 0.0\\n 4     N = len(spendings)\\n 5\\n 6     for i in range(N):\\n 7         dl_dw += -2*spendings[i]*(sales[i] - (w*spendings[i] + b))\\n 8         dl_db += -2*(sales[i] - (w*spendings[i] + b))\\n 9\\n10     # скорректировать w и b\\n11     w = w - (1/float(N))*dl_dw*alpha\\n12     b = b - (1/float(N))*dl_db*alpha\\n13\\n14     return w, b\\nДалее показана функция, которая в цикле выполняет множество эпох:\\n15 def train(spendings, sales, w, b, alpha, epochs):\\n16     for e in range(epochs):\\n17         w, b = update_w_and_b(spendings, sales, w, b, alpha)\\n18\\n19         # вывести информацию о продвижении вперед\\n20         if e % 400 == 0:\\n21             print(\"epoch:\", e, \"loss: \", avg_loss(spendings, sales, w, b))\\n22\\n23     return w, b'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 63, 'page_label': '64'}, page_content='64   Глава 4. Анатомия алгоритмов обучения\\n       \\nЭпоха 0                                                                                 Эпоха 400\\n       \\nЭпоха 800                                                                             Эпоха 1200\\n         \\nЭпоха 1600                                                                 Эпоха 3000\\nРис. 4.2. Эволюция линии регрессии с течением эпох градиентного спуска'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 64, 'page_label': '65'}, page_content='4.2. Градиентный спуск   65\\nФункция avg_loss, используемая в листинге выше, вычисляет среднеквадратичную \\nошибку. Вот как она определяется:\\n25 def avg_loss(spendings, sales, w, b):\\n26     N = len(spendings)\\n27     total_error = 0.0\\n28     for i in range(N):\\n29         total_error += (sales[i] - (w*spendings[i] + b))**2\\n30     return total_error / float(N)\\nЕсли вызвать функцию train  с параметрами alpha  = 0.001, w = 0.0, b = 0.0 \\nи epochs = 15000, мы увидим следующие результаты (показана лишь часть из них):\\nepoch: 0 loss: 92.32078294903626\\nepoch: 400 loss: 33.79131790081576\\nepoch: 800 loss: 27.9918542960729\\nepoch: 1200 loss: 24.33481690722147\\nepoch: 1600 loss: 22.028754937538633\\n...\\nepoch: 2800 loss: 19.07940244306619\\nКак видите, средняя потеря уменьшается по мере прохождения функции train \\nчерез эпохи. На рис. 4.2 показано, как эволюционировала линия регрессии с те-\\nчением эпох.\\nНаконец, после получения оптимальных значений параметров w и b нам недостает \\nтолько функции, выполняющей предсказание:\\n31 def predict(x, w, b):\\n32     return w*x + b\\nПопробуйте выполнить следующий код:\\n33 w, b = train(x, y, 0.0, 0.0, 0.001, 15000)\\n34 x_new = 23.0\\n35 y_new = predict(x_new, w, b)\\n36 print(y_new)\\nОн должен вывести 13.97.\\nГрадиентный спуск чувствителен к выбору скорости обучения α. Кроме того, он \\nмедленно сходится на больших наборах данных. К счастью, было предложено не-\\nсколько существенных улучшений этого алгоритма.\\nМини\\xadпакетный стохастический градиентный спуск (Minibatch Stochastic Gradient \\nDescent, minibatch SGD) — это версия алгоритма, ускоряющая вычисления за счет \\nаппроксимации градиента с использованием небольших пакетов (подмножеств) \\nобучающих данных. Сам алгоритм SGD тоже включает различные «усовершенство-'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 65, 'page_label': '66'}, page_content='66   Глава 4. Анатомия алгоритмов обучения\\nвания». Метод адаптивного градиента (adagrad) — это версия SGD, которая масшта-\\nбирует α для каждого параметра в соответствии с историей градиентов. В результате \\nα уменьшается при очень больших градиентах и наоборот. Метод моментов — это \\nметод, позволяющий ускорить SGD за счет ориентации градиентного спуска в соот-\\nветствующем направлении и уменьшения колебаний. В обучении нейронных сетей \\nтакже часто используются такие варианты SGD, как RMSprop и Adam.\\nОбратите внимание, что градиентный спуск и его варианты не являются алго -\\nритмами машинного обучения. Они решают задачи минимизации, в которых \\nминимизируемая функция имеет градиент (в большинстве точек в своей области \\nопределения).\\n4.3. Как работают инженеры, занимающиеся \\nмашинным обучением\\nЕсли вы не научный сотрудник и не работаете в крупной компании с большим \\nбюджетом, выделяемым на научные исследования и разработки, вам едва ли при-\\nдется самим заниматься реализацией алгоритмов машинного обучения. Вам не \\nпридется заниматься реализацией градиентного спуска или любого другого метода \\nоптимизации. Вы, скорее всего, будете использовать библиотеки, большинство из \\nкоторых распространяется с открытым исходным кодом. Библиотека — это кол-\\nлекция алгоритмов и вспомогательных инструментов, отличающаяся надежностью \\nи эффективностью. На практике чаще всего используется библиотека машинного \\nобучения с открытым исходным кодом — scikit-learn. Она написана на Python и C. \\nВот как можно реализовать линейную регрессию с использованием scikit-learn:\\n 1 def train(x, y):\\n 2     from sklearn.linear_model import LinearRegression\\n 3     model = LinearRegression().fit(x,y)\\n 4     return model\\n 5\\n 6 model = train(x,y)\\n 7\\n 8 x_new = 23.0\\n 9 y_new = model.predict(x_new)\\n10 print(y_new)\\nВ результате вы получите тот же результат 13.97. Легко, да? При желании вы мо-\\nжете заменить LinearRegression другим алгоритмом обучения регрессии, ничего \\nне меняя в остальном коде. Все просто. То же можно сказать о классификации. Вы \\nлегко сможете заменить алгоритм LogisticRegression алгоритмом SVC (именно \\nтак называется реализация метода опорных векторов в библиотеке scikit-learn),'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 66, 'page_label': '67'}, page_content='4.4. Особенности алгоритмов обучения   67\\nDecisionTreeClassifier, NearestNeighbors и многими другими алгоритмами клас-\\nсификации, реализованными в scikit-learn.\\n4.4. Особенности алгоритмов обучения\\nЗдесь я отмечу некоторые практические особенности, отличающие один алгоритм \\nобучения от другого. Вы уже знаете, что разные алгоритмы обучения могут иметь \\nразные гиперпараметры (C в SVM, ϵ и d в ID3). Алгоритмы оптимизации, такие \\nкак градиентный спуск, тоже могут иметь гиперпараметры, например α.\\nНекоторые алгоритмы, такие как обучение дерева решений, могут принимать ка-\\nчественные признаки. Например, если в наборе данных имеется признак «цвет», \\nпринимающий такие значения, как «красный», «желтый» или «зеленый», вы мо-\\nжете оставить его как есть. Но SVM, логистическая и линейная регрессия, а также \\nkNN (с метриками косинусного сходства или евклидова расстояния) ожидают, \\nчто все признаки будут иметь числовые значения. Все алгоритмы, реализованные \\nв scikit-learn, работают только с числовыми признаками. В следующей главе я по-\\nкажу, как преобразовать качественные признаки в числовые.\\nНекоторые алгоритмы, такие как SVM, позволяют аналитикам добавлять весовые \\nкоэффициенты для каждого класса. Эти весовые коэффициенты влияют на опре-\\nделение границы решения. Если какой-либо класс имеет большой вес, алгоритм \\nобучения постарается не допускать ошибок в классификации обучающих данных, \\nпринадлежащих этому классу (обычно за счет ошибок в других данных). Это может \\nбыть важно, если представители какого-то класса находятся в меньшинстве в обу-\\nчающих данных и вам нужно избежать, насколько это возможно, неправильной \\nих классификации.\\nНекоторые модели классификации, такие как SVM и kNN, выводят для заданного \\nвектора признаков только класс. Другие, такие как логистическая регрессия или \\nдеревья решений, также могут возвращать оценку от 0 до 1, которую можно ин -\\nтерпретировать как степень уверенности модели в прогнозе или вероятность, что \\nвходной образец принадлежит определенному классу1.\\nНекоторые алгоритмы классификации (например, обучения дерева решений, \\nлогистической регрессии или SVM) строят модель, используя сразу весь набор \\nданных. При появлении дополнительных размеченных данных вам придется \\nпересобрать модель заново. Другие алгоритмы (такие как наивный байесов -\\n1 При необходимости оценку для прогнозов SVM и kNN можно сгенерировать искусственно, \\nиспользовав несложные методы.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 67, 'page_label': '68'}, page_content='68   Глава 4. Анатомия алгоритмов обучения\\nский классификатор, многослойный персептрон, SGDClassifier/SGDRegressor, \\nPassiveAggressiveClassifier/PassiveAggressiveRegressor в scikit-learn) могут \\nобучаться итеративно, принимая обучающие данные пакетами. При появлении \\nновых обучающих данных вы можете обновить модель, использовав только новые \\nданные.\\nНаконец, некоторые алгоритмы, такие как обучение дерева решений, SVM и kNN, \\nмогут использоваться как для классификации, так и для регрессии, в то время как \\nдругие способны решать только задачи одного вида: либо классификацию, либо \\nрегрессию, но не обе.\\nОбычно каждая библиотека сопровождается документацией, где объясняется, ка-\\nкую задачу решает каждый алгоритм, какие входные значения допустимы и что воз-\\nвращает модель. Документация также содержит информацию о гиперпараметрах.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 68, 'page_label': '69'}, page_content='5 Практические основы\\nДо сих пор я лишь мимоходом упомянул некоторые проблемы, которые аналитик \\nдолжен учитывать, работая над задачей машинного обучения: проектирование при-\\nзнаков, переобучение и настройка гиперпараметров. В этой главе мы поговорим об \\nэтих и других проблемах, которые необходимо разрешить, прежде чем вы сможете \\nввести инструкцию model = LogisticRegression().fit(x, y).\\n5.1. Проектирование признаков\\nКогда менеджер по продукту говорит вам: «Нужно предсказать, останется ли у нас \\nконкретный клиент. Вот вам журналы, фиксирующие взаимодействия клиента \\nс нашим продуктом за пять лет», — вы не сможете просто взять эти данные, пере-\\nдать их библиотеке и получить прогноз. Вы должны сначала сконструировать \\nнабор данных.\\nКак рассказывалось в первой главе, набор данных — это коллекция размеченных \\nобразцов \\n . Каждый элемент xi из N называется вектором признаков. \\nВектор признаков — это вектор, в котором каждое измерение j = 1, ..., D содержит \\nзначение, которое как-то описывает образец. Это значение называется признаком \\nи обозначается как x(j).\\nПроблема преобразования исходной информации в набор данных называется \\nпроектированием признаков . В большинстве случаев проектирование призна -\\nков — трудоемкий процесс, требующий от аналитика творческого подхода и, пред-\\nпочтительно, знания предметной области.\\nНапример, для преобразования журналов, фиксирующих взаимодействия пользо-\\nвателя с компьютерной системой, можно создать признаки, содержащие различную \\nстатистическую информацию о пользователе, извлеченную из журналов. К при -'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 69, 'page_label': '70'}, page_content='70   Глава 5. Практические основы\\nмеру, один признак мог бы содержать цену подписки; другие признаки — частоту \\nсоединений в день, неделю и год. Еще один признак мог бы содержать среднюю \\nпродолжительность сеанса в секундах или среднее время ответа на один запрос \\nи т. д. Все, что доступно для измерения, можно использовать как признак. Задача \\nаналитика — создать информативные  признаки, которые позволят алгоритму \\nобучения построить модель, хорошо предсказывающую метки в обучающих дан-\\nных. Высокоинформативные признаки также называют признаками с  большой \\nпрогнозирующей способностью. Например, средняя продолжительность сеанса \\nпользователя имеет высокую прогнозирующую способность для предсказания — \\nбудет ли пользователь продолжать использовать приложение в будущем.\\nМы говорим, что модель имеет малое смещение, если она дает хорошие результаты на \\nобучающих данных. То есть модель делает немногочисленные ошибки, когда приме-\\nняется для прогнозирования меток данных, использованных для построения модели.\\n5.1.1. Унитарное кодирование\\nНекоторые алгоритмы обучения работают только с векторами числовых признаков. \\nЕсли какой-то признак в наборе данных является качественным, например «цвет» \\nили «день недели», его можно преобразовать в несколько бинарных признаков.\\nЕсли образец имеет качественный признак «цвет» с тремя возможными значени-\\nями: «красный», «желтый», «зеленый», его можно преобразовать в вектор с тремя \\nчисловыми значениями с помощью унитарного кодирования (известного также \\nкак кодирование с одним активным состоянием, one-hot encoding):\\n красный = [1, 0, 0]  \\n желтый = [0, 1, 0]  \\n зеленый = [0, 0, 1].  \\n(5.1)\\nТакой подход увеличивает размерность векторов признаков. Не следует пытать -\\nся уменьшить размерность, преобразовав значение «красный» в 1, «желтый» в 2 \\nи «зеленый» в 3, потому что это будет означать наличие упорядоченности в этой \\nкатегории и важность этого конкретного порядка для принятия решений. Если \\nпорядок значений признака неважен, использование упорядоченных чисел в ка-\\nчестве значений может запутать алгоритм обучения1, потому что алгоритм будет \\n1 Когда порядок значений некоторого качественного признака действительно имеет значе-\\nние, тогда можно заменить эти значения порядковыми числами, оставив единственный \\nпризнак. Например, если признак представляет качество статьи и имеет значения {плохо, \\nудовлетворительно, хорошо, отлично}, тогда можно заменить эти качественные значения \\nчислами, например {1, 2, 3, 4}.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 70, 'page_label': '71'}, page_content='5.1. Проектирование признаков   71\\nпытаться найти упорядоченность там, где ее нет, что потенциально может привести \\nк переобучению.\\n5.1.2. Биннинг\\nПротивоположная ситуация, реже встречающаяся на практике, — когда имеется чис-\\nловой признак, но его хотелось бы преобразовать в качественный. Биннинг (binning, \\nв литературе также встречается bucketing или просто дискретизация) — это про-\\nцесс преобразования признака с непрерывным диапазоном значений в несколько \\nбинарных признаков, которые иногда называют корзинами (или категориями), \\nобычно с разбивкой по диапазонам. Например, вместо представления возраста, \\nкак единственного действительного признака, аналитик мог бы разбить возраст на \\nдискретные диапазоны: все возрасты от 0 до 5 лет могут быть объединены в одну \\nкатегорию, от 6 до 10 лет — во вторую категорию, от 11 до 15 лет — в третью, и т. д.\\nНапример, пусть признак j = 4 представляет возраст. Применяя биннинг, признак \\nможно заменить соответствующими категориями. Допустим, мы добавили три \\nновые категории, «age_bin1», «age_bin2» и «age_bin3», с индексами j = 123, j = 124 \\nи j = 125 соответственно. Теперь, если для некоторого образца xi признак \\n , \\nтогда мы можем установить признак \\n ; если \\n  — установить признак \\n и т. д.\\nВ некоторых случаях хорошо продуманная дискретизация может помочь алгоритму \\nобучиться на меньшем количестве данных, потому что, используя такой подход, \\nмы «подсказываем» алгоритму обучения, что если значение признака попадает \\nв определенный диапазон, точное значение этого признака не имеет значения.\\n5.1.3. Нормализация\\nНормализация — это процесс преобразования фактического диапазона значений \\nчислового признака в стандартный диапазон значений, обычно в интервале [–1, 1] \\nили [0, 1].\\nНапример, предположим, что естественные значения некоторого признака изме-\\nняются в диапазоне от 350 до 1450. Вычитая 350 из каждого значения признака \\nи деля результат на 1100, можно нормализовать эти значения, преобразовав их \\nв диапазон [0, 1].\\nВ общем случае формула нормализации выглядит так:'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 71, 'page_label': '72'}, page_content='72   Глава 5. Практические основы\\nгде min(j) и max(j) — минимальное и максимальное значения признака j в наборе \\nданных соответственно.\\nЗачем нужна нормализация? Нормализация данных не является строгим тре -\\nбованием. Однако на практике она может способствовать увеличению скорости \\nобучения. Вспомните пример градиентного спуска из предыдущей главы. Пред -\\nставьте, что у вас есть двумерный вектор признаков. Корректируя параметры w(1) \\nи w(2), вы используете частные производные среднеквадратичной ошибки отно -\\nсительно w(1) и w(2). Если x(1) находится в диапазоне [0, 1000], а x(2) — в диапазоне \\n[0, 0.0001], то при корректировке будет преобладать производная по признаку \\nс большим значением.\\nКроме того, часто полезно гарантировать относительно небольшой диапазон и при-\\nмерно одинаковые изменения входных данных, чтобы избежать проблем, которые \\nвозникают у компьютеров при работе с очень маленькими или очень большими \\nчислами (так называемое числовое переполнение).\\n5.1.4. Стандартизация\\nСтандартизация (или нормализация z\\xadоценки) — это процедура, в ходе которой \\nзначения признаков масштабируются таким образом, что приобретают свойства \\nстандартного нормального распределения с μ = 0 и σ = 1, где μ — среднее значение \\nпризнака (усредняется по всем образцам в наборе данных), а σ — стандартное от-\\nклонение от среднего. \\nСтандартные оценки (или z-оценки) признаков вычисляются следующим образом:\\nВозникает вопрос, когда следует использовать нормализацию, а когда стандарти-\\nзацию. На этот вопрос нет однозначного ответа. Обычно, если набор данных не \\nслишком большой и есть время, можно попробовать оба варианта и посмотреть, \\nкакой лучше подходит для решаемой задачи.\\nЕсли нет времени на эксперименты, используйте следующие эмпирические пра -\\nвила:\\n  в алгоритмах обучения без учителя на практике чаще выгоднее использовать \\nстандартизацию, а не нормализацию;\\n  стандартизация также предпочтительнее для признаков, распределение зна -\\nчений которых близко к нормальному распределению (то есть если график \\nраспределения имеет колоколообразную форму);'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 72, 'page_label': '73'}, page_content='5.1. Проектирование признаков   73\\n  и снова стандартизация предпочтительнее для признаков, которые иногда мо-\\nгут иметь экстремально большие или экстремально малые (аномальные) зна -\\nчения; предпочтительность стандартизации объясняется тем, что нормализа -\\nция «втискивает» нормальные значения в очень узкий диапазон;\\n  во всех остальных случаях предпочтительнее нормализация.\\nМасштабирование признаков обычно хорошо сказывается на большинстве алго -\\nритмов обучения. Однако современные реализации алгоритмов, которые можно \\nнайти в популярных библиотеках, вполне устойчивы к признакам с разными диа-\\nпазонами значений.\\n5.1.5. Работа с отсутствующими значениями признаков\\nИногда аналитик получает данные в виде набора с уже определенными признаками. \\nВ некоторых образцах значения отдельных признаков могут отсутствовать. Это \\nчасто случается, когда набор данных создавался вручную, и человек, работавший \\nс ним, забывал заполнять некоторые значения или вообще не измерял их.\\nВот несколько типичных способов работы с отсутствующими значениями при -\\nзнаков:\\n  удалить данные с отсутствующими значениями признаков из набора дан -\\nных (этот способ можно использовать, если набор данных достаточно велик \\nи можно пожертвовать несколькими обучающими образцами);\\n  использовать алгоритм обучения, умеющий работать с отсутствующими зна-\\nчениями (зависит от библиотеки и конкретной реализации алгоритма);\\n  использовать вычислительные методы восстановления данных.\\n5.1.6. Методы восстановления данных\\nОдин из методов восстановления данных заключается в замене отсутствующего \\nзначения признака средним значением, вычисленным по всему набору данных:\\nДругой метод заключается в замене отсутствующего значения значением, выхо -\\nдящим за пределы диапазона нормальных значений. Например, если нормальные \\nзначения находятся в диапазоне [0, 1], отсутствующее значение можно установить \\nравным 2 или –1. Идея состоит в том, чтобы позволить алгоритму обучения само-\\nму решить, как лучше поступить, если значение признака значительно отличается'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 73, 'page_label': '74'}, page_content='74   Глава 5. Практические основы\\nот типичных значений. Как вариант, отсутствующее значение можно заменить \\nзначением середины диапазона. Например, если значения признака находятся \\nв диапазоне [–1, 1], отсутствующее значение можно установить равным 0. В дан-\\nном случае идея заключается в том, что значение середины диапазона не окажет \\nзначительного влияния на прогноз.\\nБолее продвинутый метод — решить задачу регрессии, использовав отсутствую -\\nщее значение в качестве целевой переменной. Используя все остальные признаки \\n, можно сформировать вектор признаков \\n , \\nустановить \\n , где j — признак с отсутствующим значением. Затем построить \\nрегрессионную модель для прогнозирования \\n  по \\n . Разумеется, для построения \\nобучающих данных \\n  должны использоваться только те данные из исходного \\nнабора данных, в которых присутствует значение признака j.\\nНаконец, если имеется достаточно большой набор данных и значения отсутствуют \\nлишь в нескольких признаках, можно увеличить размерность векторов признаков, \\nдобавив бинарный признак для каждого признака с отсутствующими значениями. \\nНапример, пусть в D-мерном наборе данных признак j = 12 имеет отсутствующие \\nзначения. Для каждого вектора признаков x тогда можно добавить признак j = D + 1 \\nсо значением 1, если значение 12-го признака присутствует в x, и 0 в противном \\nслучае. Тогда недостающее значение можно заменить нулем или любым другим \\nчислом по вашему выбору.\\nНа этапе прогнозирования, если образец имеет отсутствующее значение, следует \\nиспользовать тот же метод восстановления данных, который применялся к обуча-\\nющим данным, чтобы заполнить недостающие значения признаков.\\nЗаранее нельзя сказать, какой метод восстановления данных окажется лучшим \\nв конкретной ситуации. Попробуйте применить несколько методов, постройте \\nнесколько моделей и выберите ту, которая показывает лучшие результаты.\\n5.2. Выбор алгоритма обучения\\nВыбор алгоритма машинного обучения иногда может оказаться сложной задачей. \\nПри наличии времени можно попробовать их все. Но обычно на решение задачи \\nотводится ограниченное время. Попробуйте задать себе несколько вопросов, пре-\\nжде чем приступить к работе над задачей. В зависимости от ответов вы сможете \\nсузить круг алгоритмов и опробовать их на своих данных.\\n  Объяснимость.\\nНужно ли объяснять вашу модель нетехническим специалистам? Большинство \\nточных алгоритмов обучения — это так называемые «черные ящики». Они'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 74, 'page_label': '75'}, page_content='5.2. Выбор алгоритма обучения   75\\nобу чают модели, допускающие очень мало ошибок, но иногда очень трудно \\nпонять и еще сложнее объяснить, почему модель сделала тот или иной прогноз. \\nПримерами таких моделей являются нейронные сети и ансамблевые модели.\\nС другой стороны, алгоритмы обучения kNN, линейной регрессии или дерева \\nрешений создают модели, которые дают пусть не всегда самые точные, зато \\nлегко объяснимые результаты.\\n  Возможность сохранения набора данных в оперативной памяти.\\nМожно ли набор данных целиком загрузить в оперативную память сервера или \\nперсонального компьютера? Если да, тогда появляется возможность выбора из \\nширокого спектра алгоритмов. В противном случае предпочтение следует от-\\nдавать инкрементальным алгоритмам обучения, способным совершенствовать \\nмодель постепенно, по мере добавления новых данных.\\n  Число признаков и данных.\\nСколько обучающих данных присутствует в  наборе данных? Сколько при -\\nзнаков имеет каждый образец? Некоторые алгоритмы, включая нейронные \\nсети и градиентный бустинг (мы рассмотрим их позже), могут обрабатывать \\nогромное количество данных с миллионами признаков. Другие, такие как SVM, \\nмогут быть очень ограниченными в этом отношении.\\n  Качественные и количественные признаки.\\nСостоят ли данные только из качественных или только из числовых признаков \\nлибо имеют признаки обоих видов? В зависимости от ответа некоторые алго-\\nритмы могут быть неспособны обработать набор данных непосредственно, и вам \\nпридется преобразовать качественные признаки в числовые.\\n  Нелинейность данных.\\nЯвляются ли данные линейно разделимыми или их можно моделировать с по-\\nмощью линейной модели? Если да, тогда хорошим выбором могут оказаться \\nSVM с линейным ядром, логистическая или линейная регрессия. Иначе более \\nпредпочтительными могут оказаться глубокие нейронные сети или ансамблевые \\nалгоритмы, рассматриваемые в главах 6 и 7.\\n  Скорость обучения.\\nСколько времени можно отпустить алгоритму обучения для построения моде-\\nли? Как известно, нейронные сети обучаются очень долго. Простые алгоритмы, \\nтакие как логистическая и линейная регрессия или деревья решений, действуют \\nнамного быстрее. Специализированные библиотеки содержат очень эффектив-\\nные реализации некоторых алгоритмов; возможно, вы предпочтете поискать'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 75, 'page_label': '76'}, page_content='76   Глава 5. Практические основы\\nв интернете, чтобы найти такие библиотеки. Некоторые алгоритмы, такие как \\nслучайные леса, при выполнении на многоядерных процессорах могут произ-\\nводить вычисления параллельно, поэтому при наличии десятков ядер способны \\nстроить модели намного быстрее.\\n  Скорость прогнозирования.\\nКак быстро обученная модель должна генерировать прогнозы? Будет ли модель \\nиспользоваться в окружении, где требуется очень высокая пропускная способ-\\nность? Одни алгоритмы, такие как SVM, линейная и логистическая регрессия \\nи нейронные сети (некоторых типов), чрезвычайно быстро генерируют прогноз. \\nДругие, такие как kNN, ансамблевые алгоритмы и очень глубокие или рекур-\\nрентные нейронные сети, работают медленнее1.\\nЧтобы не надеяться на удачу в выборе лучшего алгоритма для ваших данных, мож-\\nно воспользоваться популярным способом: протестировать несколько алгоритмов \\nна контрольном наборе. Мы поговорим об этом далее. В качестве альтернативы \\nпри использовании библиотеки scikit-learn можно попробовать схему выбора \\nалгоритма, показанную на рис. 5.1.\\n5.3. Три набора\\nДо сих пор я использовал выражения «набор данных» и «обучающий набор» \\nвзаимозаменяемо. Однако на практике аналитики работают с тремя наборами \\nразмеченных данных:\\n1. Обучающий набор.\\n2. Контрольный набор.\\n3. Тестовый набор.\\nПосле получения набора размеченных данных первое, что следует сделать, — пере-\\nмешать данные и разбить их на три выборки: обучающую, контрольную и тестовую. \\nОбучающая выборка обычно самая большая; она используется для построения \\nмодели. Выборки для проверки и тестирования имеют примерно одинаковые \\nразмеры и намного меньше обучающей выборки. Алгоритм обучения не должен \\nиспользовать данные из этих двух выборок для построения модели. Вот почему \\nэти две выборки часто называют отложенными выборками (holdout sets).\\n1 Скорость прогнозирования kNN и ансамблевых методов, реализованных в современных \\nбиблиотеках, достаточно высока, поэтому не бойтесь использовать эти алгоритмы в своей \\nпрактике.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 76, 'page_label': '77'}, page_content='Памятка по выбору \\nалгоритма в scikit-lear n\\nКлассификация\\nРегрессия\\nСниж ение\\nразмерности\\nКластеризация\\nАнсамблевые\\nклассификаторы\\nЯдерная\\nаппроксимация\\nЯдерная\\nаппроксимация\\nНЕ ПОД ХО ДИТ\\nНЕ ПОД ХО ДИТ\\nНЕ ПОД ХО ДИТ\\nНЕ ПОД ХО ДИТ\\nНЕ ПОД ХО ДИТ\\nНЕ ПОД ХО ДИТ\\nНЕ ПО ДХ ОД ИТ\\nНаивный\\nБайес\\nКлассификатор\\nпо k б лижайшим\\nсоседям\\nТекстовые данные\\nДА\\nДА\\nДА\\nДА\\nДА\\nДА\\nДА\\nДА\\nДА\\nДА\\nДА\\nДАДА\\nНЕТ\\nНЕТ\\nНЕТ\\nНЕТ\\nНЕТ\\nНЕТ\\nНЕТ\\nНЕТ\\nНЕТ\\nНЕТ\\nНЕТ\\nНЕТ\\nНЕТ\\nЛинейный\\nМОВ\\n<100К данных\\nСобрать\\nбольше\\nданных\\nНА ЧАЛО\\n>50 данных\\nПредсказание\\nкатегории\\nЕсть размеченные\\nданные\\nПредсказание\\nколичественного\\nзначения\\nТолько\\nдля обзора\\nПрогнозирование\\nструктуры\\nНеудача\\nСпектральная\\nкластеризация Ме тод k\\nсреднихGMM\\nVBGMM\\n<10 данных\\n<10 данных\\n<10 данных\\n<100 данны х\\nМини-пак етный\\nметод k сре дних Сдвиг среднего\\nЧисло категорий\\nизвестно\\nРегрессор СГС\\nЛассо\\nЭластичная сеть\\nАнсамблевые регрессоры\\nГребневая регрессия\\nНекоторые признаки\\nважнее других\\nРандомизиро-\\nванный МГ К\\nСпектральное\\nвложение\\nSVR(kernel=’liner ’)\\nSVR(kernel=’rbf ’)\\nLLE\\nIsomap\\nКлассифика-\\nтор СГ С\\nМОВ\\nРис. 5.1. Диаграмма выбора машинного алгоритма из имеющихся  \\nв библиотеке scikit-learn'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 77, 'page_label': '78'}, page_content='78   Глава 5. Практические основы\\nНе существует оптимальной пропорции деления исходного набора данных на \\nтри выборки. В прошлом широко применялось эмпирическое правило, согласно \\nкоторому 70 % исходных данных использовались для обучения, 15 % для проверки \\nи 15 % для тестирования. Однако в эпоху больших данных наборы часто включают \\nмиллионы образцов. В таких случаях разумнее оставить 95 % для обучения и по \\n2.5 % выделить для контроля/тестирования.\\nВозможно, вам интересно, почему нужно использовать три выборки, а не одну. \\nОтвет прост: нежелательно, чтобы модель давала хорошие прогнозы только для \\nданных, которые алгоритм видел в процессе обучения. Тривиальный алгоритм, \\nпросто запоминающий все обучающие данные, а затем использующий память, \\nчтобы «предсказать» их метки, не будет ошибаться, предсказывая метки обучаю-\\nщих данных, но такой алгоритм бесполезен на практике. В действительности нам \\nнужно, чтобы модель давала достаточно точные прогнозы для данных, которые \\nалгоритм обучения не видел: нам нужна высокая эффективность на отложенной  \\nвыборке.\\nЗачем же нужны две контрольные выборки, а не одна? Контрольная выборка ис-\\nпользуется для: 1) выбора алгоритма обучения и 2) поиска оптимальных значений \\nгиперпараметров. Тестовая выборка используется для оценки модели перед пере-\\nдачей ее клиенту или запуском в продакшн.\\n5.4. Недообучение и переобучение\\nВыше я упомянул понятие смещения. Я говорил, что модель имеет малое смещение, \\nесли дает хорошие результаты на обучающих данных. Если модель допускает много \\nошибок на обучающих данных, мы говорим, что модель имеет большое смещение \\nили что модель недообучена. Недообученность — это неспособность модели более \\nили менее точно предсказывать метки данных, на которых она обучалась. Причин \\nнедообучения может быть несколько, наиболее важными из них являются:\\n  модель слишком проста для данных (например, линейные модели часто стра-\\nдают недообученностью);\\n  спроектированные вами признаки недостаточно информативны.\\nПервую причину легко показать на примере одномерной регрессии: набор дан -\\nных может напоминать изогнутую линию, а модель описывает прямую линию. \\nВторую причину можно проиллюстрировать так: допустим, требуется пред -\\nсказать наличие у пациента рака; в вашем распоряжении есть такие признаки, \\nкак рост, кровяное давление и  частота сердечных сокращений. Очевидно, что \\nэти три признака не являются хорошими прогностическими признаками рака,'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 78, 'page_label': '79'}, page_content='5.4. Недообучение и переобучение   79\\nпоэтому модель, использующая их, не сможет выявить значимые связи между \\nэтими признаками и метками.\\nЧтобы решить проблему недообучения, можно попробовать использовать более \\nсложную модель или спроектировать признаки с более высокой прогнозирующей \\nспособностью.\\nПереобучение — другая проблема, которой может страдать модель. Переобученная \\nмодель слишком хорошо предсказывает обучающие данные, но плохо — данные из \\nобеих контрольных выборок или хотя бы из одной из них. Я уже приводил пример \\nпереобучения в главе 3. Причин переобучения может быть несколько, наиболее \\nважными из них являются:\\n  модель слишком сложна для данных (например, очень высокое дерево реше -\\nний или очень глубокая или широкая нейронная сеть часто бывают переобу-\\nчены);\\n  слишком много признаков, но мало обучающих данных.\\nВ литературе можно встретить другое название проблемы переобучения: про -\\nблема высокой дисперсии. Этот термин происходит из статистики. Дисперсия — \\nэто ошибка модели, вызванная ее чувствительностью к небольшим колебаниям \\nв обучающем наборе. Если обучающие данные отобрать чуть иначе, в результате \\nможет получиться совершенно другая модель. Вот почему переобученная модель \\nпоказывает плохие результаты на тестовых данных: тестовые и обучающие данные \\nвыбираются из исходного набора данных независимо друг от друга.\\nДаже самую простую линейную модель можно переобучить. Обычно такое проис-\\nходит, когда данные многомерны, а количество обучающих данных относительно \\nневелико. Фактически, когда векторы признаков слишком многомерны, линейный \\nалгоритм обучения может построить модель, которая присваивает ненулевые зна-\\nчения большинству элементов w(j) в векторе параметров w, пытаясь учесть очень \\nсложные взаимосвязи между всеми доступными признаками, чтобы предсказать \\nметки обучающих данных максимально точно.\\nТакая сложная модель, скорее всего, будет плохо предсказывать метки контрольных \\nданных. Это связано с тем, что, пытаясь точно предсказать метки всех обучающих \\nданных, модель также изучит специфические особенности обучающего набора: \\nшум в значениях признаков обучающих данных, несовершенство выборки из-за \\nмалого размера набора данных и другие артефакты, не свойственные решаемой \\nзадаче, но присутствующие в обучающем наборе.\\nНа рис. 5.2 изображен набор одномерных данных, для которого созданы недообу-\\nченная, хорошо обученная и переобученная регрессионные модели.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 79, 'page_label': '80'}, page_content='80   Глава 5. Практические основы\\nстепень 1 (недообучение)\\nтрениров очные образцы\\n        \\nстепень 2 (обучение)\\nтрениров очные образцы\\nНедообучение                                                       Хорошее обучение\\nстепень 15 (переобучение)\\nтрениров очные образцы\\nПереобучение\\nРис. 5.2. Примеры недообучения (линейная модель), хорошего обучения  \\n(квадратичная модель) и переобучения (полином степени 15)\\nВот некоторые методы борьбы с переобучением:\\n1. Попробовать более простую модель (линейную регрессию вместо полиноми -\\nальной, метод опорных векторов (SVM) с линейным ядром вместо радиальных \\nбазисных функций (RBF), нейронную сеть с меньшим числом слоев/узлов).\\n2. Уменьшить размерность данных в наборе данных (например, с помощью одного \\nиз методов уменьшения размерности, рассматриваемых в главе 9).\\n3. Добавить больше обучающих данных, если возможно.\\n4. Применить регуляризацию к модели.\\nРегуляризация — один из самых широко используемых приемов в борьбе с пере-\\nобучением.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 80, 'page_label': '81'}, page_content='5.5. Регуляризация   81\\n5.5. Регуляризация\\nРегуляризация — это собирательный термин, охватывающий методы, позволяю-\\nщие алгоритмам обучения строить менее сложные модели. На практике это часто \\nприводит к небольшому увеличению смещения, но значительно уменьшает дис -\\nперсию. Эта проблема известна в литературе как дилемма смещения\\xadдисперсии.\\nНа практике наиболее широко используются L1\\xad и L2\\xadрегуляризация. Идея до-\\nвольно проста. Чтобы создать регуляризованную модель, нужно модифицировать \\nцелевую функцию, добавив штрафной член, значение которого увеличивается \\nс ростом сложности модели.\\nЯ покажу регуляризацию на примере линейной регрессии. Но тот же принцип \\nс успехом можно применить к широкому спектру моделей.\\nНапомню, как выглядит целевая функция регрессии:\\n \\n   (5.2)\\nL1-регуляризованная целевая функция имеет вид\\n \\n   (5.3)\\nгде \\n , а C является гиперпараметром, определяющим важность регу-\\nляризации. Если установить C равным нулю, модель превратится в стандартную \\nнерегуляризованную модель линейной регрессии. С другой стороны, если при -\\nсвоить гиперпараметру C большое положительное значение, алгоритм обучения \\nпостарается присвоить большинству элементов w(j) очень маленькие значения \\nили ноль, чтобы минимизировать целевую функцию. В результате модель сильно \\nупростится, что может привести к недообучению. Ваша роль как аналитика состоит \\nв том, чтобы найти такое значение гиперпараметра C, которое не слишком увели-\\nчивает смещение и уменьшает дисперсию до приемлемого уровня. В следующем \\nразделе я покажу, как это сделать.\\nL2-регуляризованная целевая функция имеет вид\\n \\n   (5.4)\\nС практической точки зрения L1-регуляризация создает разреженную модель — \\nмодель, большинство параметров которой (в случае линейной модели — боль-'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 81, 'page_label': '82'}, page_content='82   Глава 5. Практические основы\\nшинство значений w(j)) равно нулю, при условии что гиперпараметр C достаточно \\nвелик. Таким образом, L1 производит отбор признаков , решая, какие признаки \\nважны для прогнозирования, а какие нет. Это может пригодиться, когда требуется \\nупростить объяснение модели. Однако если единственная цель — увеличение \\nкачества прогнозирования на контрольных данных, то обычно лучшие резуль -\\nтаты дает L2. \\nМетоды регуляризации L1 и L2 также объединяются в так называемую модель \\nрегуляризации эластичных сетей , в которой L1- и L2-регуляризация являются \\nчастными случаями. В литературе также можно встретить название гребневая \\nрегуляризация (ridge regularization), подразумевающее L2-регуляризацию, и лассо \\n(lasso), соответствующее L1-регуляризации.\\nМетоды регуляризации L1 и L2 широко используются с линейными моделями, \\nа также часто применяются к нейронным сетям и моделям многих других типов, \\nкоторые напрямую минимизируют целевую функцию.\\nПри создании нейронных сетей также нередко используются два других метода \\nрегуляризации: прореживание (dropout) и пакетная нормализация. Существуют \\nтакже нематематические методы, имеющие эффект регуляризации: расширение \\nданных (data augmentation) и ранняя остановка. Мы поговорим об этих методах \\nв главе 8.\\n5.6. Оценка эффективности модели\\nПосле того как алгоритм построит модель на основе обучающих данных, как мы \\nможем узнать, насколько хорошей получилась эта модель? Для оценки модели \\nиспользуется тестовый набор данных.\\nТестовый набор содержит данные, которые алгоритм обучения не видел прежде, \\nпоэтому, если модель покажет хорошие результаты при прогнозировании меток \\nданных из тестового набора, можно сказать, что модель имеет хорошую обобщаю-\\nщую способность, или просто хороша.\\nСтрого говоря, для оценки эффективности моделей специалисты по машинному \\nобучению используют разные формальные метрики и инструменты. В случае ре-\\nгрессии модель оценивается довольно просто. Хорошо обученная модель регрессии \\nдает прогнозные значения, близкие к наблюдаемым. В отсутствие информативных \\nпризнаков обычно используется модель средних  (mean model), которая всегда \\nпрогнозирует средние значения меток в обучающих данных. Соответственно, \\nоцениваемая регрессионная модель должна быть лучше модели средних. Если это'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 82, 'page_label': '83'}, page_content='5.6. Оценка эффективности модели   83\\nтак, тогда на следующем шаге сравнивается эффективность модели на обучающих \\nи тестовых данных.\\nДля этого вычисляется среднеквадратичная ошибка1 (Mean Squared Error, MSE) \\nотдельно для обучающих и тестовых данных. Если среднеквадратичная ошибка \\nмодели на тестовых данных существенно выше среднеквадратичной ошибки на \\nобучающих данных, это явный признак переобучения. Проблему могут решить \\nрегуляризация или более тщательный подбор гиперпараметров. Смысл слов «суще-\\nственно выше» зависит от решаемой задачи и определяется аналитиком совместно \\nс лицом, принимающим решение, заказавшим модель.\\nВ случае с классификацией все немного сложнее. Вот метрики и инструменты, \\nнаиболее широко используемые для оценки моделей классификации:\\n  матрица ошибок;\\n  правильность;\\n  правильность с учетом цены (cost-sensitive accuracy);\\n  точность/полнота;\\n  площадь под кривой рабочей характеристики приемника (Receiver Operating \\nCharacteristic, ROC).\\nДля простоты иллюстрации я использую задачу бинарной классификации. А там, \\nгде это необходимо, я покажу, как распространить решение на случай многоклас-\\nсовой классификации.\\n5.6.1. Матрица ошибок\\nМатрица ошибок  — это таблица, описывающая успешность классификации \\nданных, принадлежащих разным классам. Одна ось матрицы ошибок — метка, \\nпредсказанная моделью, а другая ось — фактическая метка. В задаче бинарной \\nклассификации есть два класса. Допустим, модель делает выбор из двух классов: \\n«спам» и «не_спам»:\\nспам (предсказание) не_спам (предсказание)\\nспам (факт) 23 (TP) 1 (FN)\\nне_спам (факт) 12 (FP) 556 (TN)\\n1 Или функция средней потери любого другого типа, имеющего смысл.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 83, 'page_label': '84'}, page_content='84   Глава 5. Практические основы\\nПриведенная выше матрица ошибок показывает, что из 24 данных «спам» мо -\\nдель правильно классифицировала 23. В этом случае мы говорим, что у нас есть \\n23 истинно положительных (true positives, TP) результата, или TP = 23. Модель \\nнеправильно классифицировала 1 образец как не_спам. То есть мы имеем 1 лож\\xad\\nноотрицательный  (false negative, FN) результат, или FN = 1. Аналогично, из \\n568 данных, фактически не являющихся спамом, 556 были классифицированы \\nправильно. То есть мы имеем 556 истинно отрицательных  (true negatives, TN), \\nили TN = 556. Наконец, 12 данных, фактически не являющихся спамом, были \\nклассифицированы неверно, а значит, мы имеем 12 ложноположительных (false \\npositives, FP), или FP = 12.\\nМатрица ошибок для случая многоклассовой классификации имеет число строк \\nи столбцов по числу разных классов. Она может помочь вам определить тенденции \\nв распределении ошибок. Например, матрица ошибок может показать, что модель, \\nобученная распознаванию видов животных, имеет тенденцию ошибочно распоз -\\nнавать «пантеру» как «кошку» или «крысу» как «мышь». В таком случае можно \\nпопробовать добавить больше размеченных данных этих видов животных, чтобы \\nпомочь алгоритму обучения «увидеть» разницу между ними. Также можно попро-\\nбовать добавить дополнительные признаки, которые алгоритм обучения сможет ис-\\nпользовать для построения модели, способной лучше различать эти виды животных.\\nМатрица ошибок используется для вычисления двух других метрик: точность \\nи полнота.\\n5.6.2. Точность/полнота\\nДля оценки эффективности модели часто используются две метрики — точность \\nи полнота. Точность — это отношение истинно положительных прогнозов к обще-\\nму количеству положительных прогнозов:\\nПолнота — это отношение истинно положительных прогнозов к общему количе-\\nству положительных данных:\\nЧтобы понять значимость и важность точности и полноты для оценки модели, ча-\\nсто полезно рассматривать задачу прогнозирования как задачу поиска документов \\nв базе данных с помощью запросов. Точность — это доля релевантных документов'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 84, 'page_label': '85'}, page_content='5.6. Оценка эффективности модели   85\\nв списке, возвращаемом запросом. Полнота — это доля релевантных документов, \\nвозвращаемых поисковым механизмом, в  общем количестве релевантных доку -\\nментов, которые могли бы быть возвращены.\\nВ случае с задачей классификации спама нам нужна высокая точность (желательно \\nисключить ошибочную классификацию допустимого сообщения как спам), и мы \\nготовы поступиться полнотой (то есть мы допускаем, что некоторые сообщения, \\nявляющиеся спамом, окажутся в папке для входящих сообщений).\\nНа практике почти всегда приходится выбирать между высокой точностью или \\nвысокой полнотой. Добиться высоких значений обеих метрик одновременно \\nобычно невозможно. Мы можем повысить тот или другой показатель разными \\nспособами:\\n  назначая более высокие весовые коэффициенты образцам (к примеру, алго -\\nритм SVM принимает на вход весовые коэффициенты для классов);\\n  настраивая гиперпараметры для получения более высокого значения точно -\\nсти или полноты на контрольном наборе;\\n  изменяя порог принятия решения для алгоритмов, возвращающих вероятно -\\nсти классов; например, при использовании логистической регрессии или де -\\nрева решений, для того чтобы повысить точность (за счет снижения полноты), \\nможно считать прогноз положительным, только если вероятность, возвраща -\\nемая моделью, выше 0.9.\\nДаже притом, что точность и полнота определены для случая бинарной класси -\\nфикации, эти оценки всегда можно распространить на модель многоклассовой \\nклассификации. Для этого сначала нужно выбрать класс для оценивания. И затем \\nсчитать все данные, принадлежащие выбранному классу, положительными, а все \\nостальные данные — отрицательными.\\n5.6.3. Правильность\\nПравильность определяется количеством правильно классифицированных дан -\\nных, деленным на общее количество классифицированных примеров. В терминах \\nматрицы ошибок она определяется как\\n \\n  (5.5)\\nОценка правильности может пригодиться, когда одинаково важны ошибки в про-\\nгнозировании всех классов. Это не относится к задаче классификации спам/'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 85, 'page_label': '86'}, page_content='86   Глава 5. Практические основы\\nне_спам. Например, вы терпимее будете относиться к ложноотрицательным ре-\\nзультатам, чем к ложноположительным. Ложноположительный результат в класси-\\nфикации спама — это когда ваш друг отправил вам электронное письмо, но модель \\nраспознала его как спам и спрятала от вас. С другой стороны, ложноотрицательный \\nрезультат — намного меньшая проблема: если ваша модель не распознает неболь-\\nшой процент спама, это не будет иметь большого значения.\\nПлощадь\\nПлощадьПлощадь\\nПлощадь\\nДо ля истинно полож ительных\\n результатов\\nДо ля истинно полож ительных\\n результатов\\nДо ля истинно полож ительных\\n результатов\\nДо ля истинно полож ительных\\n результатов\\nДо ля ложнопол ож ительных\\nрезультатов\\nДо ля ложнопол ож ительных\\nрезультатов\\nДо ля ложнопол ож ительных\\nрезультатов\\nДо ля ложнопол ож ительных\\nрезультатов\\n11\\n11\\n11\\n11 00\\n00\\nРис. 5.3. Площадь под кривой рабочей характеристики (окрашена в серый цвет)'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 86, 'page_label': '87'}, page_content='5.6. Оценка эффективности модели   87\\n5.6.4. Правильность с учетом цены\\nВ случаях, когда разные классы имеют разную важность, может пригодиться \\nметрика правильность с учетом цены (cost-sensitive accuracy). Чтобы получить \\nоценку правильности с учетом цены, нужно присвоить цену (положительное \\nчисло) обоим типам ошибок: FP и FN. Затем вычислить значения TP , TN, FP , FN, \\nкак обычно, умножить значения FP и FN на соответствующие цены и определить \\nправильность с помощью уравнения 5.5.\\n5.6.5. Площадь под ROC-кривой (AUC)\\nROC-кривая (термин receiver operating characteristic — рабочая характеристика \\nприемника — происходит из радиолокации) — это широко используемый метод \\nоценки эффективности классификационных моделей. Чтобы создать общую \\nкартину эффективности классификации, ROC-кривые используют комбинацию \\nдоли истинно положительных результатов (определяется в точности как полнота) \\nи доли ложноположительных результатов (доля отрицательных данных, класси-\\nфицированных неправильно).\\nДоли истинно положительных (True Positive Rate, TPR) и ложноположительных \\n(False Positive Rate, FPR) результатов определяются как\\nROC-кривые можно использовать только для оценки классификаторов, которые \\nвозвращают некоторую оценку достоверности (или вероятность) прогноза. На -\\nпример, с использованием ROC-кривых можно оценить логистическую регрессию, \\nнейронные сети и деревья решений (включая ансамблевые модели, основанные \\nна деревьях решений).\\nЧтобы начертить ROC-кривую, сначала нужно дискретизировать диапазон оценок \\nдостоверности. Если для данной модели диапазон равен [0, 1], его можно дискре-\\nтизировать следующим образом: [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]. Затем \\nкаждое дискретное значение используется в качестве порога при прогнозировании, \\nс использованием модели, меток данных в наборе данных. Например, чтобы вы -\\nчислить TPR и FPR для порога 0.7, нужно применить модель к каждому образцу, \\nполучить оценку достоверности, и, если оценка выше или равна 0.7, для этого об-\\nразца выбирается положительный класс; иначе — отрицательный.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 87, 'page_label': '88'}, page_content='88   Глава 5. Практические основы\\nВзгляните на рис. 5.3. Легко заметить, что для порога 0 все прогнозы будут \\nположительными, поэтому обе метрики, TPR и FPR, будут равны 1 (верхний \\nправый угол). С другой стороны, для порога 1 положительные прогнозы невоз -\\nможны, поэтому оценки TPR и FPR будут равны 0, что соответствует левому \\nнижнему углу.\\nЧем больше площадь под ROC-кривой (area under ROC curve, AUC), тем эффек-\\nтивнее классификатор. Классификатор с AUC выше 0.5 лучше классификатора, \\nдействующего методом случайного выбора. Если AUC ниже 0.5, значит, с моделью \\nчто-то не так. Идеальный классификатор будет иметь AUC, равную 1. Обычно, \\nимея хорошую модель, можно получить эффективный классификатор, выбирая \\nзначение порога, который дает значение TPR, близкое к 1, и удерживает значение \\nFPR около 0.\\nROC-кривые пользуются большой популярностью, потому что относительно \\nпросты для понимания, способны охватывать несколько аспектов классификации \\n(с учетом ложных положительных и отрицательных результатов) и позволяют ви-\\nзуально и с минимальными усилиями сравнивать эффективность разных моделей.\\n5.7. Настройка гиперпараметров\\nКогда я знакомил вас с обучающими алгоритмами, то говорил, что вы, как аналитик, \\nдолжны выбирать правильные значения для гиперпараметров алгоритма, таких \\nкак ϵ и d для ID3, C для SVM или α для градиентного спуска. Но что понимается \\nпод «правильными значениями»? Какое значение является правильным и как его \\nнайти? В данном разделе я отвечаю на эти важные вопросы.\\nКак вы уже знаете, гиперпараметры не оптимизируются самим алгоритмом обуче-\\nния. Аналитик должен «настроить» гиперпараметры экспериментально, подобрав \\nлучшую комбинацию значений, по одному для каждого гиперпараметра.\\nОдин из типичных способов сделать это, если имеется достаточный объем данных, \\nчтобы выделить приличный контрольный набор (в котором каждый класс пред -\\nставлен как минимум парой десятков данных), а количество гиперпараметров и их \\nдиапазон не слишком велики, — использовать поиск по сетке.\\nПоиск по сетке — самый простой метод настройки гиперпараметров. Допустим, вы \\nобучаете SVM и у вас есть два гиперпараметра: параметр штрафа C (положительное \\nдействительное число) и ядро («linear» или «rbf»).\\nЕсли вы впервые работаете с конкретным набором данных, вы не знаете возможный \\nдиапазон значений для C. На практике часто применяется простой трюк — ис-'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 88, 'page_label': '89'}, page_content='5.7. Настройка гиперпараметров   89\\nпользуется логарифмическая шкала. Например, вы можете попробовать следую-\\nщие значения для C: [0.001, 0.01, 0.1, 1, 10, 100, 1000]. В этом случае у вас есть 14 \\nкомбинаций гиперпараметров: [(0.001, «linear»), (0.01, «linear»), (0,1, «linear»), \\n(1, «linear»), (10, «linear» »), (100, «linear»), (1000, «linear»), (0.001, «rbf»), (0.01, \\n«rbf»), (0.1, «rbf»), (1, «rbf»), (10, «rbf»), (100, «rbf»), (1000, «rbf»)].\\nДалее вы обучаете 14 моделей на обучающем наборе, по одной для каждой ком -\\nбинации гиперпараметров. Затем оцениваете эффективность каждой модели на \\nконтрольных данных, используя одну из метрик, о которых мы говорили в пре-\\nдыдущем разделе (или какую-то другую метрику, важную для вас). И наконец, \\nсохраняете модель, обладающую лучшей эффективностью в соответствии с вы-\\nбранной метрикой.\\nОпределив лучшую пару гиперпараметров, вы можете попробовать другие значе-\\nния, близкие к лучшим. Иногда это позволяет получить еще более эффективную \\nмодель.\\nВ заключение вы оцениваете выбранную модель с использованием тестового на-\\nбора.\\nОчевидно, что проверка всех комбинаций гиперпараметров, особенно если их не-\\nсколько, может занять много времени, особенно для больших наборов данных. \\nСуществуют более эффективные методы, такие как случайный поиск и байесов\\xad\\nская оптимизация гиперпараметров.\\nСлучайный поиск отличается от поиска по сетке тем, что от \\nвас не требуется создавать дискретный набор значений для \\nкаждого гиперпараметра; вместо этого вы произвольно опреде-\\nляете статистическое распределение каждого гиперпараметра, \\nиз которого случайным образом выбираются значения для \\nопробования, и задаете общее количество комбинаций, которые \\nнужно опробовать.\\nБайесовские методы отличаются от случайного поиска или поиска по сетке тем, что \\nвыбор следующих значений для оценки они производят на основе результатов про-\\nшлых испытаний. Идея состоит в том, чтобы ограничить количество дорогостоящих \\nоптимизаций целевой функции, выбирая следующие значения гиперпараметра на \\nоснове тех, которые давали хороший результат в прошлом.\\nСуществуют также методы на основе градиента, методы эволюционной оптимиза\\xad\\nции и другие методы алгоритмической настройки гиперпараметров. Большинство \\nсовременных библиотек машинного обучения реализуют один или несколько таких \\nметодов. Существуют также специализированные библиотеки настроек гиперпа-'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 89, 'page_label': '90'}, page_content='90   Глава 5. Практические основы\\nраметров, которые могут помочь в настройке гиперпараметров для практически \\nлюбого алгоритма обучения, включая созданные вами.\\n5.7.1. Перекрестная проверка\\nКогда нет возможности выделить приличного размера контрольный набор для \\nнастройки гиперпараметров, часто используется метод перекрестной проверки. \\nЕсли обучающих данных немного, затруднительно выделить два дополнительных \\nнабора данных, контрольный и тестовый. Вы наверняка предпочтете использовать \\nбольше данных для обучения модели. В таком случае вы можете разбить данные \\nтолько на два набора: обучающий и тестовый, а затем использовать прием пере -\\nкрестной проверки на обучающем наборе, чтобы сымитировать контрольный набор.\\nПерекрестная проверка выполняется следующим образом. Сначала фиксируются \\nзначения гиперпараметров для оценки. Затем обучающий набор разбивается на \\nнесколько выборок одинакового размера. Каждая выборка называется блоком. \\nНа практике обычно используется перекрестная проверка с пятью блоками. Для \\nперекрестной проверки с пятью блоками нужно случайным образом разбить обу-\\nчающие данные на пять блоков: {F1, F2, ..., F5}. Каждый Fk, k = 1, ..., 5 содержит 20 % \\nобучающих данных. Затем обучается пять отдельных моделей, как описывается \\nдалее. Для обучения первой модели, f1, используются все данные из блоков F2, F3, F4 \\nи F5, а данные из F1 играют роль контрольного набора. Для обучения второй модели, \\nf2, используются данные из блоков F1, F3, F4 и F5, а данные из F2 используются для \\nпроверки. Аналогично строятся остальные модели и для каждого контрольного \\nнабора, от F1 до F5, вычисляются значения метрики. Затем пять значений метрики \\nусредняются, чтобы получить окончательное значение.\\nДля поиска оптимальных значений гиперпараметров перекрестную проверку \\nможно совместить с поиском по сетке. Определив искомые значения, можно ис -\\nпользовать весь обучающий набор для построения модели с лучшими значениями \\nгиперпараметров, найденными путем перекрестной проверки. В завершение про-\\nизводится оценка модели с использованием тестового набора.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 90, 'page_label': '91'}, page_content='6\\nНейронные сети \\nи глубокое обучение\\nНачнем с того, что вы уже знаете, что такое нейронная сеть, и знаете, как ее по -\\nстроить. Да, это логистическая регрессия! Фактически, модель логистической \\nрегрессии, или, скорее, ее обобщение для многоклассовой классификации, назы -\\nваемое моделью регрессии softmax, является стандартным узлом в нейронной сети.\\n6.1. Нейронные сети\\nПонимая, как работает линейная регрессия, логистическая регрессия и градиент-\\nный спуск, вы легко освоите нейронные сети.\\nНейронная сеть (neural network, NN), так же как модель регрессии или SVM, — это \\nвсего лишь математическая функция:\\ny = fNN(x).\\nФункция fNN имеет особую форму: это вложенная функция (вроде матрешки). \\nВы, наверное, уже слышали о слоях в нейронных сетях. Итак, для трехслойной \\nнейронной сети, возвращающей скаляр, fNN выглядит так:\\ny = fNN(x) = f3(f2(f1(x))).\\nf1 и f2 в уравнении выше — это векторные функции, которые определяются как\\n \\n   (6.1)\\nгде l — это индекс слоя и может охватывать от 1 до любого количества слоев. Функ-\\nция gl называется функцией активации. Это фиксированная, обычно нелинейная'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 91, 'page_label': '92'}, page_content='92   Глава 6. Нейронные сети и глубокое обучение\\nфункция, выбранная аналитиком до начала обучения. Параметры Wl (матрица) \\nи bl (вектор) определяются для каждого слоя в ходе обучения, с использованием \\nуже знакомого вам градиентного спуска для оптимизации, в зависимости от ре-\\nшаемой задачи, конкретной функции стоимости (такой как среднеквадратичная \\nошибка — MSE). Сравните уравнение 6.1 с уравнением логистической регрессии, \\nзаменив gl сигмоидной функцией, и вы не увидите никакой разницы. Функция f3 \\nявляется скалярной функцией для задачи регрессии, но также может быть вектор-\\nной функцией, в зависимости от конкретной задачи.\\nВозможно, вам интересно, почему вместо вектора wl используется матрица Wl. \\nПричина в  том, что  gl — векторная функция. Каждая строка wl,u (u означает \\n«unit» — узел) в матрице Wl является вектором той же размерности, что и z. Пусть \\nal,u = wl,uz + bl,u. На выходе fl (z) возвращает вектор \\n , \\nгде gl — некоторая скалярная функция1, а sizel — количество узлов в слое l. Чтобы \\nсделать обсуждение более конкретным, рассмотрим одну из архитектур нейрон -\\nных сетей, называемую многослойным перцептроном и часто упоминаемую как \\nклассическая нейронная сеть.\\n6.1.1. Пример многослойного перцептрона\\nДалее мы подробно рассмотрим одну конкретную конфигурацию нейронных сетей, \\nназываемую нейронными сетями прямого распространения (Feedforward Neural \\nNetwork, FFNN), и еще более конкретно — архитектуру, называемую многослойным \\nперцептроном (Multilayer Perceptron, MLP). В качестве иллюстрации рассмотрим \\nMLP с тремя слоями. Наша сеть принимает на вход двумерный вектор признаков \\nи выводит число. Эта FFNN может быть моделью регрессии или классификации, \\nв зависимости от функции активации, используемой в третьем выходном слое.\\nНаш многослойный перцептрон изображен на рис. 6.1. Графически нейронную \\nсеть можно представить в виде комбинации связанных узлов, логически органи-\\nзованных в один или несколько слоев. Каждый узел представлен кружком или \\nпрямоугольником. Входящая стрелка представляет вход узла и указывает, откуда \\nпоступают данные на этот вход. Исходящая стрелка представляет выход узла.\\nВыход каждого узла является результатом математической операции, выполня -\\nемой внутри прямоугольника. Узлы, обозначенные кружками, ничего не делают \\nс входными данными; они просто пересылают их на свой выход.\\nВот что происходит в каждом узле, обозначенном прямоугольником. Сначала все \\nвходы узла объединяются, и из них формируется входной вектор. Затем узел при-\\n1 Скалярная функция возвращает скаляр — простое число, а не вектор.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 92, 'page_label': '93'}, page_content='6.1. Нейронные сети   93\\nменяет линейное преобразование к входному вектору, точно так же, как это делает \\nмодель линейной регрессии со своим вектором входных признаков. И в заключе-\\nние применяет функцию активации g к результату линейного преобразования, \\nполучая выходное значение — действительное число. В классической нейронной \\nсети прямого распространения (FFNN) выходное значение узла в некотором слое \\nстановится входным значением для всех узлов в следующем слое.\\nНа рис. 6.1 функция активации gl имеет один индекс: l — индекс слоя, которому \\nпринадлежит узел. Обычно все узлы в одном слое уровня используют одну и ту же \\nфункцию активации, но это не обязательно. Каждый слой может иметь различное \\nколичество узлов. Каждый узел имеет свои параметры wl,u и bl,u, где u — индекс узла, \\nа l — индекс слоя. Вектор yl–1 в каждом узле определяется как \\n. \\nВектор x в первом слое определяется как \\n.\\nКак можно заметить на рис. 6.1, в многослойном перцептроне все выходы одного \\nслоя подключены к каждому входу последующего слоя. Такая архитектура назы-\\nвается полносвязанной. Нейронная сеть также может содержать полносвязанные \\nслои, то есть слои, чьи узлы получают на входе выходные данные от каждого из \\nузлов в предыдущем слое.\\n6.1.2. Архитектура нейронных сетей прямого \\nраспространения\\nДля решения задач регрессии или классификации, которые рассматривались в пре-\\nдыдущих главах, достаточно, чтобы последний (самый правый) слой нейронной \\nсети содержал единственный узел. Если функция активации glast последнего узла \\nявляется линейной, тогда нейронная сеть является регрессионной моделью. Если \\nglast является логистической функцией, тогда нейронная сеть является моделью \\nбинарной классификации.\\nАналитик данных может выбрать для gl,u любую дифференцируемую математи -\\nческую функцию 1. Последнее свойство существенно для градиентного спуска, \\nиспользуемого для поиска значений параметров wl,u и bl,u для всех l и u. Основная \\n1 Функция должна быть дифференцируемой по всей области значений или в большинстве \\nточек в этой области. Например, ReLU не дифференцируется в точке 0.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 93, 'page_label': '94'}, page_content='x(1)\\nx(2)\\ny1(1) ← g 1(w1,1x + b1,1)\\nx(1)\\nx(2)\\ny1(2) ← g1(w1,2x + b1,2)\\ny1(3) ← g1(w1,3x + b1,3)\\ny1(4) ← g1(w1,4x + b1,4)\\ny2(1) ← g2(w2,1y1 + b2,1)\\ny2(2) ← g2(w2,2y1 + b2,2)\\ny2(3) ← g2(w2,3y1 + b2,3)\\ny2(4) ← g2(w2,4y1 + b2,4)\\ny ← g3(w3,1y2 + b3,1) y\\nслой 3 (f3) слой 2 (f2) слой 1 (f1) \\ny1(1)\\ny1(4)\\ny2(4)\\ny2(3)\\ny2(2)\\ny2(1)\\nРис. 6.1. Многослойный перцептрон с двумерным входом, двумя слоями по четыре узла в каждом и выходным слоем \\nс единственным узлом'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 94, 'page_label': '95'}, page_content='6.2. Глубокое обучение   95\\nцель нелинейных компонентов в функции fNN состоит в том, чтобы позволить ней-\\nронной сети аппроксимировать нелинейные функции. В отсутствие нелинейных \\nкомпонентов fNN была бы линейной, независимо от количества слоев. Причина \\nв том, что Wl z + bl является линейной функцией, а линейная функция от линейной \\nфункции также является линейной.\\nВ роли функций активации часто используется уже известная вам логистическая \\nфункция, а также TanH и ReLU. Первая — это функция гиперболического тангенса, \\nнапоминающая логистическую функцию, но имеющая область определения в диа-\\nпазоне от –1 до 1 (не включая их). Последняя представляет собой спрямленную \\nлинейную единичную функцию, которая равна нулю, когда на входе получает \\nотрицательное значение z, и само значение z в противном случае:\\nКак я уже говорил выше, Wl в выражении Wlz + bl — это матрица, а bl — вектор. \\nЭтим оно отличается от линейной регрессии wz + b. Каждой строке u в матрице Wl \\nсоответствует вектор параметров wl,u. Размерность вектора wl,u равна количеству \\nузлов в слое l — 1. Операция Wlz дает вектор \\n . Тогда \\nсумма al + bl дает sizel-размерный вектор cl. Наконец, функция gl (cl) создает и воз-\\nвращает вектор \\n .\\n6.2. Глубокое обучение\\nПод глубоким обучением подразумевается обучение нейронных сетей, имеющих \\nбольше двух невыходных слоев. В прошлом обучение таких сетей усложнялось все \\nбольше с ростом количества слоев. В числе самых больших проблем назывались \\nвзрывной рост градиента  и затухание градиента , поскольку для определения \\nпараметров сети использовался градиентный спуск.\\nЕсли проблема взрывного роста градиента решалась относительно просто, с при-\\nменением таких простых методов, как ограничение градиента  и L1- или L2-\\nрегуляризация, то проблема затухания градиента оставалась неразрешимой \\nв течение десятилетий.\\nЧто такое затухание градиента и чем обусловлена эта проблема? Для обновления \\nзначений параметров в нейронных сетях обычно используется алгоритм, называе-'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 95, 'page_label': '96'}, page_content='96   Глава 6. Нейронные сети и глубокое обучение\\nмый обратным распространением. Обратное распространение — это эффективный \\nалгоритм вычисления градиентов в нейронных сетях с использованием правила \\nдифференцирования сложных функций. В главе 4 мы уже видели, как это правило \\nиспользуется для вычисления частных производных составной функции. В каждой \\nитерации обучения, в процессе градиентного спуска, параметры нейронной сети \\nобновляются пропорционально частной производной функции стоимости для \\nтекущего параметра. Проблема в том, что иногда градиент оказывается исчезаю-\\nще малым, что фактически мешает изменению значений некоторых параметров. \\nВ худшем случае это может полностью остановить обучение нейронной сети.\\nТрадиционные функции активации, такие как функция гиперболического тангенса, \\nо которой я упоминал выше, имеют градиенты в диапазоне (0, 1), при этом гради-\\nенты вычисляются на этапе обратного распространения по правилу дифференци-\\nрования сложных функций. В результате для вычисления градиентов предыдущих \\nслоев (расположенных левее) в n-слойной сети производится перемножение n этих \\nнебольших чисел, из-за чего градиент экспоненциально уменьшается с увеличени-\\nем n. Это приводит к тому, что более ранние слои обучаются намного медленнее, \\nесли вообще обучаются.\\nОднако современные реализации алгоритмов обучения нейронных сетей позво -\\nляют эффективно обучать очень глубокие нейронные сети (до нескольких сотен \\nслоев). Это объясняется внедрением целого комплекса усовершенствований, вклю-\\nчая ReLU, LSTM (и другие вентильные узлы; мы рассмотрим их ниже), а также \\nтаких методов, как соединения с пропуском слоя (skip connections), используемые \\nв остаточных нейронных сетях (residual neural networks), а также усовершенство-\\nванные версии алгоритма градиентного спуска.\\nИтак, поскольку проблемы затухания и взрывного роста градиента в настоящее \\nвремя практически решены (или их влияние сведено к минимуму), под термином \\n«глубокое обучение» подразумевается обучение нейронных сетей с использова-\\nнием современного алгоритмического и математического инструментария, неза-\\nвисимо от глубины нейронной сети. На практике многие бизнес-задачи можно \\nрешить с помощью нейронных сетей, имеющих 2–3 слоя между входным и выход-\\nным слоями. Слои, не являющиеся ни входными, ни выходными, часто называют \\nскрытыми слоями.\\n6.2.1. Сверточная нейронная сеть\\nВозможно, вы заметили, что количество параметров, которые может иметь MLP \\n(многослойный перцептрон), быстро растет по мере увеличения сети. В частности, \\nпри добавлении одного слоя в сеть добавляется (sizel–1 +1) ⋅ sizel параметров (ма-\\nтрица Wl плюс вектор bl). То есть если в существующую нейронную сеть добавить'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 96, 'page_label': '97'}, page_content='6.2. Глубокое обучение   97\\nеще один слой с 1000 узлов, в модель добавится более миллиона дополнительных \\nпараметров. Оптимизация таких больших моделей является очень сложной вы -\\nчислительной задачей.\\nКогда в роли обучающих данных используются изображения, входные данные \\nполучаются слишком многомерными 1. Если вы решите построить модель клас -\\nсификации изображений с использованием MLP , проблема оптимизации почти \\nнаверняка станет неразрешимой.\\nСверточная нейронная сеть (Convolutional Neural Network, CNN) — это особый \\nвид FFNN, который значительно сокращает количество параметров в глубокой \\nнейронной сети с большим количеством узлов практически без потери качества \\nмодели. Сверточные нейронные сети нашли применение в обработке изображений \\nи текста, где они побили многие ранее установленные рекорды.\\nТак как сверточные нейронные сети были изобретены для обработки изображений, \\nя объясню, как они работают, на примере классификации изображений.\\nВозможно, вы замечали, что пикселы, расположенные в изображениях близко \\nдруг от друга, обычно представляют информацию одного и  того же типа: небо, \\nвода, листья, мех, кирпичи и т. д. Исключением из правила являются края: части \\nизображения, где два разных объекта «касаются» друг друга.\\nЕсли обучить нейронную сеть распознаванию областей с одной и той же информа-\\nцией, а также краев, эти знания позволят нейронной сети распознавать объекты, \\nпредставленные на изображении. Например, если нейронная сеть обнаружит \\nнесколько областей кожи с краями, имеющими овальную форму, с цветом кожи \\nвнутри и голубым цветом снаружи, то, скорее всего, это лицо на фоне неба. Если \\nцелью является обнаружение людей на изображениях, нейронная сеть, скорее \\nвсего, преуспеет в этом.\\nУчитывая, что наиболее важная информация занимает на изображении ограничен-\\nную площадь, мы можем разделить изображение на квадратные фрагменты, исполь-\\nзуя метод скользящего окна2. Затем обучить несколько небольших регрессионных \\nмоделей одновременно, передавая каждой квадратный фрагмент. Цель каждой \\nнебольшой регрессионной модели — научиться обнаруживать определенный ша-\\nблон во фрагменте на входе. Например, одна небольшая модель может научиться \\nопределять небо; другая — траву, третья — края зданий и т. д.\\n1 Каждый пиксел в изображении — это отдельный признак. Изображение размером 100 на \\n100 пикселов имеет 10 000 признаков.\\n2 Представьте, что рассматриваете банкноту в микроскоп. Чтобы рассмотреть всю банкноту, \\nнужно постепенно перемещать ее слева направо и сверху вниз. В каждый момент времени \\nвы видите только часть банкноты. Этот подход называется методом скользящего окна.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 97, 'page_label': '98'}, page_content='98   Глава 6. Нейронные сети и глубокое обучение\\nНебольшие регрессионные модели в CNN напоминают модель на рис. 6.1, но имеют \\nтолько по одному слою. Чтобы обнаружить какой-либо шаблон, модель регрессии \\nдолжна определить параметры матрицы F (от слова «filter» — фильтр) размером \\np × p, где p — размер фрагмента. Для простоты предположим, что входное изо -\\nбражение черно-белое, число 1 представляет черные, а число 0 — белые пикселы. \\nПредположим также, что фрагменты имеют размер 3 на 3 пиксела ( p = 3). Неко-\\nторый фрагмент может выглядеть как следующая матрица P (от слова «patch» — \\nфрагмент):\\nФрагмент выше представляет шаблон с изображением креста. Небольшая ре -\\nгрессионная модель, которая будет обнаруживать такие шаблоны (и только их), \\nдолжна обучить матрицу F размером 3 на 3, в которой параметры в позициях, со-\\nответствующих единицам во входном фрагменте, будут положительными числами, \\nа параметры в позициях, соответствующих нулям, будут иметь значения, близкие \\nк нулю. Если вычислить свертку матриц P и F, полученное значение будет тем \\nбольше, чем больше F похожа на P. Для иллюстрации свертки двух матриц пред-\\nположим, что F выглядит следующим образом:\\nОператор свертки conv определен только для матриц, имеющих одинаковое ко -\\nличество строк и столбцов. Для наших матриц P и F свертка вычисляется, как \\nпоказано на рис. 6.2.\\n0 1 0\\n111\\n00 1\\n0 2 3\\n241\\n00 3\\n0\\n11\\n0\\n1\\n1\\n01\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n3\\n21\\n00\\n0 2\\n4\\n3\\n00 11 00\\n11 11 11\\n00 0011\\nconv\\nPF\\noverlay\\n00 22 33\\n22 44 11\\n00 0033\\n0 . 0 0\\n11\\n0\\n000 1\\n1\\n01\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\nsum\\n1 . 2111 ... 0 . 3000 ...\\n1 . 2111 ... 1 . 4111 ... 1 . 1111 ...\\n0 . 0000 ... 1 . 3111 ... 0 . 0000 ...\\n3\\n21\\n00\\n02\\n4\\n3\\nсуммиро-\\nвание\\nPF\\nнало-\\nжение\\nсвертка 12\\nРис. 6.2. Свертка двух матриц'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 98, 'page_label': '99'}, page_content='6.2. Глубокое обучение   99\\nЕсли на вход подать фрагмент P, имеющий другой шаблон, например изображение \\nбуквы L,\\nтогда свертка с F даст в результате меньшее значение: 5. То есть чем больше фрагмент \\n«похож» на фильтр, тем выше значение операции свертки. Для удобства имеется \\nтакже параметр смещения b, связанный с каждым фильтром F, который добавляется \\nк результату свертки перед применением нелинейности (функция активации).\\nОдин слой в CNN состоит из нескольких сверточных фильтров (каждый со своим \\nсобственным параметром смещения), в точности как один слой в классической \\nFFNN состоит из нескольких узлов. Каждый фильтр в первом (самом левом) слое \\nскользит — свертывает — по входному изображению слева направо, сверху вниз, \\nи в каждой итерации вычисляет значение свертки.\\nЭтот процесс изображен на рис. 6.3, где показаны шесть шагов перемещения одного \\nфильтра, выполняющего свертку изображения.\\nМатрица фильтра (по одной для каждого фильтра в  каждом слое) и значения \\nсмещения являются обучаемыми параметрами, которые оптимизируются с  ис-\\nпользованием градиентного спуска с обратным распространением.\\nНелинейность применяется к сумме свертки и  смещения. Как правило, во всех \\nскрытых слоях используется функция активации ReLU. Функция активации \\nв выходном слое зависит от решаемой задачи.\\nПоскольку в каждом слое l может иметься sizel фильтров, выходной слой l будет \\nсостоять из sizel матриц, по одной для каждого фильтра.\\nЕсли CNN имеет один сверточный слой, следующий за другим сверточным слоем, \\nто последующий слой l + 1 будет обрабатывать выходные данные предыдущего \\nслоя l, как коллекцию sizel матриц изображения. Такая коллекция называется \\nтомом. Размер коллекции называется глубиной тома. Каждый фильтр в слое l + 1 \\nвыполняет свертку всего тома. Свертка фрагмента тома — это просто сумма сверток \\nсоответствующих фрагментов отдельных матриц, из которых состоит том.\\nНа рис. 6.4 показан пример свертки фрагмента тома с глубиной 3. Значение свертки, \\n–3, было получено в результате вычисления выражения: \\n(–2 · 3 + 3 · 1 + 5 · 4 + (–1) · 1) + (–2 · 2 + 3 · (–1) + 5 · (–3) + (–1) · 1) + (–2 · 1 +  \\n+ 3 · (–1) + 5 · 2 + (–1) · (–1)) + (–2).'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 99, 'page_label': '100'}, page_content='1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\nИзображение\\nФильтр \\n4 \\nВыход перед\\nприменением \\nнелинейности \\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\n4 –1 \\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\n4 –1 7 \\nСвертка 1\\nСвертка 2\\nСвертка 3\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\n4 \\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\n4 –1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\n4 –1 7 \\n–1 7 \\n7 \\n2 Свертка 4\\n2 7 \\n2 7 0 \\nСвертка 5\\nСвертка 6\\n1\\nСмещение\\n1\\n1\\n1\\n1\\n1\\nРис. 6.3. Фильтр, свертывающий изображение'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 100, 'page_label': '101'}, page_content='6.2. Глубокое обучение   101\\nФильтр Смещение\\nВых од перед применением\\nнелинейности\\nТом\\n–\\n–\\n––\\n––\\n–––\\n–\\n–\\n––\\n–\\n––\\n–\\nРис. 6.4. Свертка тома состоит из трех матриц\\nВ системах распознавания изображений сверточные нейронные сети часто получа-\\nют на входе тома, потому что изображения обычно представлены тремя каналами: \\nR, G и B, каждый из которых представляет монохромное изображение.\\nСвертки имеют два важных свойства — шаг и дополнение. Шаг — это величина \\nодного шага смещения окна. На рис. 6.3 шаг равен 1, то есть фильтр смещается \\nвправо и вниз на одну ячейку за раз. На рис. 6.5 показан пример свертки с шагом 2. \\nКак видите, чем больше шаг, тем меньше выходная матрица.\\nДополнение позволяет получить увеличенную выходную матри-\\nцу; это ширина рамки с дополнительными ячейками, которые \\nдобавляются вокруг изображения (или тома) перед сверткой \\nс помощью фильтра. Обычно дополнительные ячейки, формиру-\\nющие дополнение, содержат нули. На рис. 6.3 дополнение равно \\n0, поэтому дополнительные ячейки не добавляются в изображе-\\nние. На рис. 6.6 задан шаг, равный 2, и дополнение, равное 1, поэтому вокруг изо-\\nбражения добавляется рамка шириной в 1 ячейку. Как видите, выходная матрица \\nувеличилась с увеличением дополнения1.\\n1 Для экономии места на рис. 6.6 показаны только первые две из девяти сверток.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 101, 'page_label': '102'}, page_content='1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\nИзображение\\nФильтр\\n4 \\nВыход перед\\nприменением\\nнелинейности\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 -2 \\n4 7 \\nСвертка 1\\nСвертка 2\\n1\\nСмещение\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\n4 \\nСвертка 3\\n1\\n7 \\n0 \\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\n4 \\nСвертка 4\\n1\\n7 \\n0 –1 \\nРис. 6.5. Свертка с шагом 2'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 102, 'page_label': '103'}, page_content='6.2. Глубокое обучение   103\\n0\\n0\\n0\\n0\\n0 0 0 0 0\\n0 0 0 0 0 0\\n0\\n0\\n0\\n0\\n0\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\nИзображение с дополнением 1\\nФильтр  \\n–1 \\nВыход перед\\nприменением\\nнелинейности\\n \\nСвертка 1\\n1\\nСмещение\\n0\\n0\\n0\\n0\\n0 0 0 0 0\\n0 0 0 0 0 0\\n0\\n0\\n0\\n0\\n0\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\n–1 \\nСвертка 2\\n1\\n1\\nРис. 6.6. Свертка с шагом 2 и дополнением 1\\nНа рис. 6.7 показан пример изображения с дополнением 2. Дополнение может \\nпригодиться при использовании более крупных фильтров, позволяя им лучше \\n«сканировать» границы изображения.\\nЭтот раздел был бы неполным без описания приема подвыборки (pooling, в русско-\\nязычной литературе также встречаются термины «субдискретизация» и «пулинг»), \\nочень часто используемого в CNN. Подвыборка действует во многом подобно \\nсвертке, потому что фильтр применяется методом скользящего окна. Однако вместо \\nприменения обучаемого фильтра к входной матрице или т \\ue088ому слой подвыборки \\nприменяет фиксированный оператор, обычно max (возвращающий максимальное \\nзначение) или average (возвращающий среднее значение). Подобно свертке, опера-\\nция подвыборки имеет гиперпараметры: размер фильтра и шаг. Пример подвыборки \\nс оператором max с размером фильтра 2 и шагом 2 показан на рис. 6.8.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 103, 'page_label': '104'}, page_content='104   Глава 6. Нейронные сети и глубокое обучение\\nРис. 6.7. Изображение с дополнением 2\\n3\\n5\\n–3\\n5\\n5\\n6\\n4\\n2\\n9 \\n–1 \\n1 \\n7 4 \\n2 \\n1 8 \\nИзображение\\n8 \\nВыход  \\n8 6 \\nПодвыборка 1\\nПодвыборка 2\\n8 \\nПодвыборка 3\\n6 \\n5 \\n8 \\nПодвыборка 4\\n6 \\n5 9 \\n3\\n5\\n–3\\n5\\n5\\n6\\n4\\n2\\n9 \\n–1 \\n1 \\n7 4 \\n2 \\n1 8 \\n3\\n5\\n–3\\n5\\n5\\n6\\n4\\n2\\n9 \\n–1 \\n1 \\n7 4 \\n2 \\n1 8 \\n3\\n5\\n–3\\n5\\n5\\n6\\n4\\n2\\n9 \\n–1 \\n1 \\n7 4 \\n2 \\n1 8 \\nРис. 6.8. Подвыборка с размером фильтра 2 и шагом 2\\nКак правило, слой подвыборки следует за сверточным слоем и получает на входе \\nвыходные данные свертки. Когда подвыборка применяется к т\\ue088ому, каждая матрица \\nв этом томе обрабатывается независимо от других. То есть в результате применения \\nподвыборки к т\\ue088ому получается том с той же глубиной.\\nКак видите, операция подвыборки имеет только гиперпараметры и не имеет обу-\\nчаемых параметров. На практике обычно используются фильтры с размером 2'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 104, 'page_label': '105'}, page_content='6.2. Глубокое обучение   105\\nили 3 и с шагом 2. Подвыборка с определением максимального значения более \\nпопулярна, чем с определением среднего, и часто дает лучшие результаты.\\nОбычно подвыборка способствует повышению точности модели, а также повышает \\nскорость обучения за счет уменьшения количества вычислений требуемых для \\nприменения свертки. (Как показано на рис. 6.8, при размере фильтра 2 и шаге 2 \\nразмерность тома на входе следующего слоя уменьшается вдвое.) \\n6.2.2. Рекуррентная нейронная сеть\\nРекуррентные нейронные сети (Recurrent Neural Network, RNN) используются \\nдля маркировки, классификации или генерации последовательностей. Последо -\\nвательность — это матрица, каждая строка которой является вектором признаков \\nи в которой порядок строк имеет значение. Под маркировкой последовательности \\nподразумевается предсказание класса для каждого вектора признаков в последова-\\nтельности. Под классификацией последовательности — предсказание класса для \\nвсей последовательности. Сгенерировать последовательность означает вывести \\nдругую последовательность (возможно, другой длины), некоторым образом свя -\\nзанную с входной последовательностью.\\nРекуррентные нейронные сети часто используются для обработки текста, потому \\nчто предложения и тексты являются естественными последовательностями слов \\nи знаков препинания или последовательностями символов. По той же причине \\nрекуррентные нейронные сети также используются в обработке речи.\\nРекуррентная нейронная сеть не является сетью прямого распространения: она со-\\nдержит циклы. Идея состоит в том, что каждый узел u рекуррентного слоя l имеет ве-\\nщественное состояние hl,u. Состояние можно рассматривать как память узла. В RNN \\nкаждый узел u в каждом слое l имеет два входа: вектор состояний из предыдущего \\nслоя l — 1 и вектор состояний из этого же слоя l, но из предыдущего временного шага.\\nДля иллюстрации рассмотрим первый и второй рекуррентные слои в сети RNN. \\nПервый (самый левый) слой получает на входе вектор признаков. Второй слой \\nполучает на входе выходные данные из первого слоя.\\nЭта ситуация схематически изображена на рис. 6.9. Как я уже говорил, каждый \\nобучающий образец представлен матрицей, в которой каждая строка является \\nвектором признаков. Для простоты будем рассматривать эту матрицу как после -\\nдовательность векторов \\n , где lengthx — длина \\nвходной последовательности. Если входной образец X является текстовым пред-\\nложением, тогда вектор признаков xt для каждого t = 1, ..., lengthx представляет \\nслово в позиции t в предложении.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 105, 'page_label': '106'}, page_content='xt ← [x (1),t,x(2),t]\\nx(2),t\\nht-1\\n1,1\\nht-1\\nl,2\\nht\\n1,1\\nht1,1 ← g 1(w1,1xt + u1,1ht-11 + b1,1)\\nyt\\n1 ← g 2(V1ht\\n1 + c1)\\nx(1),t\\nx(2),t\\nht-11,1\\nht-1\\n1,2\\nht\\n1,2\\nht1,2 ← g 1(w1,2xt + u1,2ht-1\\n1 + b1,2)\\nx(1),t\\nxt ← [ x(1),t,x(2),t]\\nслой 1\\nht1 ← [h t1,1,ht1,2]\\nht-1\\n2,1\\nht-1\\n2,2\\nht\\n2,1\\nht2,1 ←  g1(w2,1h1t + u2,1ht-12 + b2,1)\\nht-12,1\\nht-1\\n2,2\\nht\\n2,2\\nслой 2\\nht1 ← [h t1,1,ht1,2]\\nyt2 ←  g2(V2ht2 + c2)\\nht2 ←[h t2,1,ht2,2]\\nyt1 yt2\\nht\\n1 ← [h t\\n1,1,ht1,2]\\nht\\n2,2 ← g 1(w2,2ht\\n1 + u2,2ht-12 + b2,2)\\nРис. 6.9. Первые два слоя в рекуррентной нейронной сети.  \\nНа вход подается двумерный вектор признаков; каждый слой имеет два узла'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 106, 'page_label': '107'}, page_content='6.2. Глубокое обучение   107\\nКак показано на рис. 6.9, в RNN векторы признаков из входного образца после -\\nдовательно «читаются» нейронной сетью в порядке временных шагов. Индекс t \\nобозначает временной шаг. Чтобы обновить состояние \\n  на каждом временном \\nшаге t в каждом узле u каждого слоя l, сначала вычисляется линейная комбинация \\nвходного вектора признаков с вектором состояния \\n  этого же слоя из предыдущего \\nвременного шага t — 1. Линейная комбинация двух векторов вычисляется с исполь-\\nзованием двух векторов параметров wl,u, ul,u и параметра bl,u. Значение\\n  получается \\nприменением функции активации g1 к результату линейной комбинации. Обычно \\nв роли функции g1 выступает tanh. Выход \\n  обычно является вектором, который \\nвычисляется сразу для всего слоя l. Чтобы получить \\n , используется функция ак-\\nтивации g2, которая на входе принимает вектор и возвращает другой вектор той же \\nразмерности. Функция g2 применяется к линейной комбинации вектора значений \\nсостояния \\n , вычисленных с использованием матрицы парамет ров Vl и вектора \\nпараметров cl. В классификации на роль g2 обычно выбирается функция softmax:\\nФункция softmax — это обобщение сигмоидной функции на многомерные выходы. \\nОна имеет свойство \\n  и \\n  для всех j.\\nРазмерность Vl выбирается аналитиком таким образом, чтобы произведение \\nматрицы Vl на вектор \\n  давало вектор той же размерности, что и вектор cl. Этот \\nвыбор зависит от размерности выходной метки y в данных обучения. (До сих пор \\nмы рассматривали только одномерные метки, но в следующих главах мы увидим, \\nчто метки могут быть многомерными.)\\nЗначения wl,u, ul,u, bl,u, Vl,u и cl,u определяются по обучающим данным с использова-\\nнием градиентного спуска с обратным распространением. Для обучения моделей \\nRNN используется специальная версия обратного распространения, называемая \\nобратным распространением во времени.\\nОбе функции, tanh и softmax, страдают проблемой затухания градиента. Даже если \\nнаша сеть RNN имеет только один или два рекуррентных слоя, из-за последова -\\nтельного характера входных данных обратное распространение «развертывает» \\nсеть с течением времени. С точки зрения вычисления градиента это означает, что \\nчем длиннее входная последовательность, тем глубже получается развернутая сеть.\\nДругая проблема, характерная для RNN, заключается в обработке долгосрочных \\nзависимостей. По мере увеличения длины входной последовательности векторы \\nпризнаков, находящиеся в начале последовательности, постепенно «забываются», \\nпотому что состояние всех узлов, которые играют роль памяти сети, в значительной'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 107, 'page_label': '108'}, page_content='108   Глава 6. Нейронные сети и глубокое обучение\\nмере зависит от векторов признаков, прочитанных последними. Следовательно, \\nпри обработке текста или речи причинно-следственная связь между удаленными \\nсловами в длинном предложении может быть потеряна. Наиболее эффективными \\nрекуррентными моделями нейронных сетей, используемыми на практике, являются \\nвентильные RNN. К ним относятся сети с долгой краткосрочной памятью (Long \\nShort-Term Memory, LSTM) и сети с вентильными рекуррентными узлами (Gated \\nRecurrent Unit, GRU).\\nБлагодаря использованию вентильных узлов сети RNN получают способность хра-\\nнить информацию в своих узлах для будущего использования почти так же, как хра-\\nнятся биты в памяти компьютера. Разница лишь в том, что операции чтения, записи \\nи стирания информации, хранящейся в каждом узле, контролируются функциями \\nактивации, которые принимают значения в диапазоне (0, 1). Обученная нейронная \\nсеть может «прочитать» входную последовательность векторов признаков и  на \\nнекотором раннем временном шаге t решить сохранить конкретную информацию \\nо векторах признаков. Эта информация о более ранних векторах признаков может \\nпозже использоваться моделью для обработки векторов признаков в конце вход-\\nной последовательности. Например, если текст на входе начинается со слова она, \\nмодель RNN для обработки текстов может решить запомнить род местоимения, \\nчтобы правильно интерпретировать слово ее, следующее далее в предложении.\\nРешение о том, какую информацию хранить и когда разрешать чтение, запись \\nи удаление, принимают узлы. Эти решения принимаются на основе данных и ре-\\nализуются через идею вентилей (gates). Есть несколько архитектур управляемых \\nузлов. Простая, но эффективная называется минимальным вентильным узлом  \\nи состоит из ячейки памяти и вентиля забывания.\\nДавайте посмотрим, как действует узел GRU с математической точки зрения, \\nвзяв в качестве примера первый слой RNN (тот, который принимает входную по-\\nследовательность векторов признаков). Минимальный вентильный узел u в слое l \\nимеет два входа: вектор значений ячеек памяти из всех узлов в том же слое из \\nпредыдущего временного шага \\n  и вектор признаков xt. Он использует эти два \\nвектора следующим образом (все операции, представленные ниже, выполняются \\nузлом последовательно, друг за другом):'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 108, 'page_label': '109'}, page_content='6.2. Глубокое обучение   109\\nгде g1 — функция активации tanh, g2 называется управляющей функцией и реали-\\nзуется как сигмоидная функция, принимающая значения в диапазоне (0, 1). Если \\nвентиль Γl,u близок к 0, тогда ячейка памяти сохраняет значение, полученное на \\nпредыдущем временном шаге \\n . Если вентиль Γl,u близок к 1, значение ячейки \\nпамяти затирается новым значением \\n  (см. третью сверху операцию). Как \\nи в стандартных сетях RNN, в роли g3 обычно используется функция softmax.\\nУправляемый узел принимает входные данные и хранит их \\nв течение некоторого времени. Это эквивалентно применению \\nк входу функции тождества (f (x) = x). Поскольку производная \\nфункции тождества является константой, когда сеть с управ-\\nляемыми узлами обучается с обратным распространением во \\nвремени, градиент не затухает.\\nК другим важным расширениям RNN относятся: двунаправленные RNN, RNN \\nс механизмом внимания и модели RNN преобразования последовательностей \\nв последовательности  (sequence-to-sequence). Последние, например, часто ис -\\nпользуются для реализации нейронных моделей машинного перевода и других \\nмоделей преобразования текста в текст. Обобщением RNN является рекурсивная \\nнейронная сеть.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 109, 'page_label': '110'}, page_content='7 Проблемы и решения\\n7.1. Ядерная регрессия\\nРанее мы говорили о линейной регрессии, но что если исходные данные имеют \\nформу, отличную от прямой линии? В таких случаях может помочь полиноми -\\nальная регрессия. Допустим, у нас есть одномерные данные \\n . Мы мог-\\nли бы попытаться найти квадратичную линию y = w1xi + w2xi\\n2 + b, описывающую \\nнаши данные. Определив функцию стоимости как среднеквадратичную ошибку \\n(MSE), можно выполнить градиентный спуск и найти значения параметров w1, w2 \\nи b, минимизирующие эту функцию. В одно- или двумерном пространстве легко \\nувидеть, соответствует ли функция данным. Но если входные данные представ -\\nлены D-мерным вектором признаков с D > 3, тогда найти правильный полином \\nбудет сложно.\\nЯдерная регрессия (kernel regression) является непараметрическим методом. Это \\nозначает отсутствие параметров, которые должны определяться в процессе обуче-\\nния. Модель основана на самих данных (как kNN). В простейшем случае ядерная \\nрегрессия подбирает такую модель:\\n \\n .  (7.1)\\nФункция k(·) называется ядром (kernel). Ядро играет роль функции подобия: \\nзначения коэффициентов wi тем выше, чем ближе значение x к xi, и наоборот. Ядро'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 110, 'page_label': '111'}, page_content='7.1. Ядерная регрессия   111\\nможет принимать разные формы. На практике наиболее часто используется ядро \\nГаусса:\\nЗначение b является гиперпараметром, который настраивается с использованием \\nконтрольного набора (путем применения модели, построенной с определенным \\nзначением b, к образцам в контрольном наборе и вычисления среднеквадратичной \\nошибки). На рис. 7.1 показано, как b влияет на форму линии регрессии.\\nтренировочные образцы\\nb\\n     \\nтренировочные образцы\\nb\\n Оптимальная модель Несколько переобученная модель\\nтренировочные образцы\\nb\\nСильно переобученная модель\\nРис. 7.1. Пример линий ядерной регрессии с ядром Гаусса для трех значений b\\nВ случае, когда входные данные являются многомерными векторами признаков, \\nчлены xi – x и xl – x в уравнении 7.1 следует заменить евклидовым расстоянием \\n|| xi –x || и || xl –x || соответственно.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 111, 'page_label': '112'}, page_content='112   Глава 7. Проблемы и решения\\n7.2. Многоклассовая классификация\\nМногие задачи классификации можно определить с использованием двух классов, \\nно некоторые определены с использованием большего количества классов, что \\nтребует адаптации алгоритмов машинного обучения.\\nВ многоклассовой классификации метка может быть одним из C классов: \\n. Многие алгоритмы машинного обучения являются бинарными, на-\\nпример SVM. Некоторые алгоритмы можно модифицировать для решения задач \\nс множеством классов. ID3 и другие алгоритмы обучения деревьев решений можно \\nизменить, как показано ниже:\\nдля всех \\n , где S — листовой узел, в котором происходит прогнозиро-\\nвание.\\nЛогистическую регрессию можно естественным образом распространить на задачи \\nмногоклассового обучения, заменив сигмоидную функцию функцией softmax , \\nкоторую мы уже видели в главе 6.\\nАлгоритм kNN тоже легко распространить на случай многоклассовой классифи -\\nкации: отыскав k ближайших данных для входа x, нужно вернуть класс, которому \\nпринадлежит больше всего данных среди k.\\nАлгоритм SVM не получится естественным образом распространить на задачи \\nмногоклассовой классификации. Другие алгоритмы работают намного эффективнее, \\nкогда определены для двух классов. Что делать, если требуется решить задачу много-\\nклассовой классификации, но алгоритм обучения поддерживает только бинарную \\nклассификацию? В таких случаях часто используется стратегия, которая называется \\n«один против всех». Идея состоит в том, чтобы преобразовать задачу многоклас-\\nсовой классификации в C задач бинарной классификации и построить C бинарных \\nклассификаторов. Например, если есть три класса \\n , нужно создать копии \\nисходных наборов данных и модифицировать их. В первой копии заменить на 0 все \\nметки, не равные 1. Во второй копии заменить на 0 все метки, не равные 2. В третьей \\nкопии заменить на 0 все метки, не равные 3. После этого останется только решить три \\nзадачи бинарной классификации и обучить модели различать метки 1 и 0, 2 и 0 и 3 и 0.\\nПосле получения трех моделей для классификации нового входного вектора x, они \\nприменяются к входным данным и дают три прогноза. После этого остается только \\nвыбрать прогноз принадлежности к ненулевому классу, который является наиболее \\nдостоверным. Как вы помните, модель логистической регрессии возвращает  не \\nметку, а оценку (от 0 до 1), которую можно интерпретировать как вероятность, что'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 112, 'page_label': '113'}, page_content='7.3. Одноклассовая классификация   113\\nметка является положительной. Этот показатель можно также интерпретировать \\nкак достоверность прогноза. В SVM аналогом достоверности является расстояние \\nd от входа x до границы решения:\\nЧем больше расстояние, тем достовернее прогноз. Большинство алгоритмов обуче-\\nния можно либо естественным путем преобразовать для многоклассового случая, \\nлибо с их помощью получить результат, который затем использовать в стратегии \\n«один против всех».\\n7.3. Одноклассовая классификация\\nИногда в наличии имеются только данные одного класса и нужно обучить модель, \\nкоторая будет отличать данные этого класса от всех остальных данных.\\nОдноклассовая классификация, также известная как унарная классификация, \\nили моделирование класса, решает задачу идентификации объектов определен -\\nного класса среди всех объектов через обучение на наборе, содержащем только \\nобъекты этого класса. Эта задача сложнее и отличается от традиционной задачи \\nклассификации, целью которой является выявление различий между двумя или \\nболее классами с помощью обучающего набора, содержащего объекты всех классов. \\nТипичным примером задачи одноклассовой классификации может служить клас-\\nсификация допустимого трафика в защищенной компьютерной сети. В этом сцена-\\nрии обычно имеется очень немного примеров трафика, порождаемого атакующим \\nзлоумышленником, если такие примеры вообще есть. Зато примеров допустимого \\nтрафика часто сколько угодно. Алгоритмы обучения одноклассовой классифика-\\nции используются для обнаружения выбросов, аномалий и новых данных.\\nЕсть несколько алгоритмов обучения одноклассовой классификации. На прак -\\nтике наиболее широко используются одноклассовые версии алгоритма Гаусса, \\nk средних, kNN и SVM.\\nИдея одноклассового алгоритма Гаусса состоит в моделировании данных, как если \\nбы они были получены из распределения Гаусса, точнее, из многомерного нормального \\nраспределения (Multivariate Normal Distribution, MND). Функция плотности вероят-\\nности (probability density unction, pdf) для MND задается следующим уравнением:'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 113, 'page_label': '114'}, page_content='114   Глава 7. Проблемы и решения\\nгде fμ, Σ(x) возвращает плотность вероятности, соответствующую входному вектору \\nпризнаков x. Плотность вероятности можно интерпретировать как достоверность, \\nчто образец x был взят из распределения, которое мы смоделировали как MND. \\nЗначения μ (вектор) и Σ (матрица) являются параметрами, которые требуется опре-\\nделить по обучающим данным. Критерий максимального правдоподобия (анало-\\nгичный тому, что используется в задаче логистической регрессии) оптимизирован \\nдля поиска оптимальных значений этих двух параметров. \\n  — определитель \\nматрицы Σ; обозначение Σ–1 означает матрицу, обратную матрице Σ.\\nЕсли вы не знакомы с терминами определитель  и обратная матрица , не бес -\\nпокойтесь. Это стандартные операции над векторами и матрицами из области \\nматематики — теории матриц. Если у вас появится желание узнать, что это такое, \\nпочитайте «Википедию», где хорошо объясняются эти понятия.\\nНа практике числа в векторе μ определяют место, где находится центр кривой \\nгауссова распределения, а числа в Σ определяют форму кривой. На рис. 7.2 по-\\nказан пример гауссовой модели для случая с обучающим набором, состоящим из \\nдвумерных векторов признаков.\\nПосле построения модели и определения параметров μ и Σ по обучающим данным \\nспрогнозировать вероятность каждого входа x можно с помощью fμ, Σ(x). Если \\nполученная вероятность выше определенного порога, мы предсказываем, что об-\\nразец принадлежит нашему классу; иначе он классифицируется как аномальный. \\nЗначение порога определяется экспериментально или с использованием «обо -\\nснованного предположения».\\nКогда данные имеют более сложную форму, можно использовать более сложный \\nалгоритм, состоящий из нескольких гауссовых моделей (называется смесью гаус-\\nсовых распределений). В этом случае по данным определяется большее число \\nпараметров: по одному μ и Σ для каждого гауссова распределения, а также пара-\\nметры, управляющие объединением нескольких гауссовых моделей в одно значе-\\nние плотности распределения вероятности. В главе 9 мы рассмотрим применение \\nсмеси гауссовых распределений к задаче кластеризации.\\nОдноклассовые версии k средних и kNN основаны на принципах, \\nсхожих с  одноклассовой версией алгоритма Гаусса: создается \\nнекоторая модель данных и затем определяется порог принятия \\nрешения о сходстве нового вектора признаков с другими об -\\nразцами, согласно модели. В первом случае все обучающие при-\\nмеры группируются с использованием алгоритма кластеризации \\nk средних, и, когда появляется новый образец x, расстояние d(x) вычисляется как \\nминимальное расстояние между x и центром каждого кластера. Если d(x) меньше \\nопределенного порога, значит, x принадлежит этому классу.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 114, 'page_label': '115'}, page_content='7.3. Одноклассовая классификация   115\\nРис. 7.2. Решение задачи одноклассовой классификации с использованием \\nодноклассовой версии метода Гаусса. Сверху: двумерные векторы признаков. \\nСнизу: кривая многомерного нормального распределения, которая максимизирует \\nправдоподобие данных сверху\\nОдноклассовая версия SVM, в зависимости от формулировки задачи, пытается \\nлибо 1) отделить гиперплоскостью все обучающие данные от начала координат \\n(в пространстве признаков) и максимизировать расстояние от этой гиперплоскости \\nдо начала координат, либо 2) определить сферическую границу вокруг данных, \\nминимизируя объем этой гиперсферы. Я оставляю изучение одноклассовых версий \\nалгоритмов kNN, k средних и SVM как самостоятельное упражнение.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 115, 'page_label': '116'}, page_content='116   Глава 7. Проблемы и решения\\n7.4. Классификация с многими метками\\nИногда для описания образца из набора данных подходит более одной метки. \\nВ данном случае речь идет о классификации с многими метками.\\nНапример, для описания изображения на рис. 7.3 можем использовать одновре -\\nменно несколько меток: «хвойный лес», «горы», «дорога».\\nРис. 7.3. Изображение с метками «хвойный лес», «горы» и «дорога».  \\nФотограф Кейт Лагадия (Cate Lagadia)\\nЕсли число возможных значений для меток велико, но все они имеют одинаковую \\nприроду, как теги, каждый размеченный образец можно преобразовать в несколько \\nразмеченных данных, по одному для каждой метки. Все эти новые данные будут \\nиметь одинаковые векторы признаков и только одну метку. В результате задача \\nпревращается в  задачу многоклассовой классификации. Решить ее можно, ис -\\nпользуя стратегию «один против всех». Единственное отличие от обычной задачи \\nмногоклассовой классификации заключается в появлении нового гиперпараметра: \\nпорога. Если оценка подобия для какой-то метки выше порогового значения, эта \\nметка присваивается входному вектору признаков. В этом сценарии одному вектору \\nпризнаков может быть присвоено несколько меток. Значение порога выбирается \\nс использованием контрольного набора.\\nДля решения задачи классификации с многими метками аналогично можно при-\\nменять алгоритмы, которые естественным образом преобразуются в многоклас-\\nсовые (деревья решений, логистическая регрессия, нейронные сети и др.). Они \\nвозвращают оценку для каждого класса, поэтому мы можем определить порог'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 116, 'page_label': '117'}, page_content='7.4. Классификация с многими метками   117\\nи затем присвоить одному вектору признаков несколько меток, для которых оценка \\nблизости превышает этот порог.\\nНейронные сети можно естественным образом обучить классификации с многими \\nметками, используя в качестве функции стоимости бинарную перекрестную энтро\\xad\\nпию (binary cross-entropy). Выходной слой нейронной сети в этом случае имеет по \\nодному узлу на метку. Каждый узел в выходном слое имеет сигмоидную функцию \\nактивации. Соответственно, каждая метка l является бинарной \\n , где \\nl = 1, ..., L и i = 1, ..., N. Бинарная перекрестная энтропия определяет вероятность \\n, что образец xi имеет метку l, определяется как \\nКритерий минимизации — простое среднее значение всех членов бинарной пере-\\nкрестной энтропии во всех обучающих образцах и всех их метках.\\nВ случаях, когда число возможных значений меток невелико, можно попробовать \\nпреобразовать задачу классификации с многими метками в задачу многоклассовой \\nклассификации. Представьте следующую задачу. Требуется присвоить изображе-\\nниям метки двух типов. Метки первого типа могут иметь два возможных значе -\\nния: {фото, живопись}; метки второго типа могут иметь три возможных значения: \\n{портрет, пейзаж, другое}. Для каждой комбинации двух исходных классов можно \\nсоздать новый фиктивный класс, например:\\nФиктивный \\nкласс Истинный класс 1 Истинный класс 2\\n1 фото портрет\\n2 фото пейзаж\\n3 фото другое\\n4 живопись портрет\\n5 живопись пейзаж\\n6 живопись другое\\nТеперь мы имеем те же самые размеченные данные, но заменили набор истинных \\nметок одной фиктивной меткой со значениями от 1 до 6. На практике такой под -\\nход дает хорошие результаты, когда возможных комбинаций классов не слишком \\nмного. В противном случае необходимо использовать гораздо больше данных для \\nобучения, чтобы компенсировать увеличение набора классов.\\nОсновное преимущество этого последнего подхода в том, что метки остаются коррели-\\nрованными, в отличие от методов, описанных выше, которые предсказывают каждую \\nметку независимо друг от друга. Во многих задачах корреляция между метками может \\nбыть существенным фактором. Например, представьте, что нужно классифицировать'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 117, 'page_label': '118'}, page_content='118   Глава 7. Проблемы и решения\\nэлектронную почту как спам и не_спам, и одновременно как обычная и важная. Вы \\nнаверняка пожелали бы исключить такие прогнозы, как [спам, важная].\\n7.5. Обучение ансамбля\\nФундаментальные алгоритмы, которые мы рассмотрели в главе 3, имеют свои ограни-\\nчения. Из-за простоты иногда они не могут создать модель, достаточно эффективную \\nдля вашей задачи. В таких случаях можно попробовать использовать глубокие ней-\\nронные сети. Однако на практике глубокие нейронные сети требуют значительного \\nобъема размеченных данных, которых у вас может не быть. Другой способ повысить \\nэффективность простых алгоритмов обучения — использовать обучение ансамбля.\\nОбучение ансамбля — это парадигма обучения, которая основана на обучении не \\nодной сверхправильной модели, а большого числа моделей с низкой правильностью \\nи объединении прогнозов, данных этими слабыми моделями, для получения более \\nправильной метамодели.\\nМодели с низкой правильностью обычно обучаются слабыми алгоритмами об \\xad\\nучения, которые не способны обучать сложные модели и поэтому показывают \\nвысокую скорость работы на этапах обучения и прогнозирования. Наиболее часто \\nв роли слабого алгоритма используется алгоритм обучения дерева решений, кото-\\nрый обычно прекращает разбивать обучающий набор после нескольких итераций. \\nВ результате получаются мелкие и не очень правильные деревья, но, как гласит \\nидея обучения ансамбля, если деревья не идентичны и каждое дерево хотя бы не-\\nмного лучше случайного угадывания, мы можем получить высокую правильность, \\nобъединив большое количество таких деревьев.\\nЧтобы получить окончательный прогноз для входа x, прогнозы всех слабых моде-\\nлей объединяются с использованием некоторого метода взвешенного голосования. \\nКонкретная форма взвешивания голосов зависит от алгоритма, но сама суть не \\nзависит от него: если по совокупности слабые модели предсказывают, что электрон-\\nное письмо является спамом, мы присваиваем образцу x метку спам.\\nДвумя основными методами обучения ансамблей являются бустинг (boosting — \\nфорсирование) и бэггинг (bagging — агрегирование)1.\\n7.5.1. Бустинг и бэггинг\\nМетод бустинга заключается в использовании исходных обучающих данных \\nи итеративного создания нескольких моделей с применением слабого алгоритма. \\n1 Переводы терминов boosting и bagging неточные и не прижившиеся.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 118, 'page_label': '119'}, page_content='7.5. Обучение ансамбля   119\\nКаждая новая модель отличается от предыдущих тем, что, конструируя ее, слабый \\nалгоритм пытается «исправить» ошибки, допускаемые предыдущими моделями. \\nОкончательная ансамблевая модель представляет собой комбинацию этих много-\\nчисленных слабых моделей, построенных итеративно.\\nСуть бэггинга заключается в создании множества «копий» обучающих данных \\n(каждая копия немного отличается от других) и последующем применении слабого \\nалгоритма к каждой копии с целью получить несколько слабых моделей, а затем \\nобъединить их. Широко используемым и эффективным алгоритмом машинного \\nобучения, основанным на идее бэггинга, является случайный лес.\\n7.5.2. Случайный лес\\n«Классический» алгоритм бэггинга работает следующим образом. Из имеющегося \\nобучающего набора создается B случайных выборок Sb (для каждого b = 1, ..., B) и на \\nоснове каждой выборки Sb строится модель fb дерева решений. Чтобы получить \\nвыборку Sb для некоторого b, производится выборка с заменой. То есть сначала \\nсоздается пустая выборка, а затем из обучающего набора выбирается случайный \\nобразец, и его точная копия помещается в Sb, при этом сам образец остается в ис-\\nходном обучающем наборе. Выбор данных продолжается, пока не выполнится \\nусловие | Sb | = N.\\nВ результате обучения получается B деревьев решений. Прогноз для нового об -\\nразца x, в случае регрессии, определяется как среднее из B прогнозов\\nили большинством голосов в случае классификации.\\nСлучайный лес имеет только одно отличие от классического бэггинга. Он ис -\\nпользует модифицированный алгоритм обучения дерева, который при каждом \\nрасщеплении в процессе обучения проверяет случайное подмножество признаков. \\nЭто делается с целью устранить корреляцию между деревьями: если один или не-\\nсколько признаков имеют большую прогнозирующую способность, многие деревья \\nбудут выбирать их для расщепления данных. Это приведет к появлению в «лесу» \\nбольшого числа коррелированных деревьев. Корреляция по признакам с большой \\nпрогнозирующей способностью препятствует повышению точности предсказания. \\nВысокая эффективность ансамбля моделей объясняется тем, что хорошие модели, \\nвероятнее всего, согласятся с одним и тем же прогнозом, а плохие — не согласятся \\nи дадут разные прогнозы. Корреляция сделает плохие модели более склонными \\nк согласию, что исказит картину голосования или повлияет на среднее значение.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 119, 'page_label': '120'}, page_content='120   Глава 7. Проблемы и решения\\nНаиболее важными гиперпараметрами для настройки являются количество \\nдеревьев B и размер случайного подмножества признаков, которые необходимо \\nучитывать при каждом расщеплении.\\nСлучайный лес — один из наиболее широко используемых алгоритмов обучения \\nансамблей. Чем обусловлена его эффективность? Причина в том, что, используя \\nнесколько выборок из исходного набора данных, мы уменьшаем дисперсию конеч-\\nной модели. Помните, что низкая дисперсия означает слабую предрасположенность \\nк переобучению. Переобучение происходит, когда модель пытается объяснить \\nнебольшие вариации в наборе данных, потому что набор данных является лишь \\nнебольшой выборкой из всех возможных примеров явления, которое мы пытаемся \\nсмоделировать. В случае неудачного подхода к формированию обучающего набора \\nв него могут попасть некоторые нежелательные (но неизбежные) артефакты: шум, \\nаномальные и чрезмерно или недостаточно представительные данные. Создавая \\nнесколько случайных выборок с заменой обучающего набора, мы уменьшаем \\nвлияние этих артефактов.\\n7.5.3. Градиентный бустинг\\nДругой эффективный алгоритм обучения ансамблей, основанный на идее бу -\\nстинга, — градиентный бустинг. Сначала рассмотрим применение градиентного \\nбустинга в регрессии. Построение эффективной регрессионной модели мы начнем \\nс константной модели f = f0 (как мы это делали в ID3):\\nЗатем изменим метки во всех образцах i = 1, ..., N в обучающем наборе:\\n \\n   (7.2)\\nгде \\n  называется остатком и является новой меткой образца xi.\\nТеперь используем модифицированный обучающий набор с остатками вместо \\nоригинальных меток, чтобы построить новую модель дерева решений, f1. Модель \\nбустинга теперь определяется как \\n , где α — скорость обучения (гипер-\\nпараметр).\\nЗатем пересчитаем остатки с использованием уравнения 7.2, заменим метки в обу-\\nчающих данных еще раз, обучим новую модель дерева решений f2, переопределим \\nмодель бустинга как \\n  и будем повторять процесс, пока не объеди-\\nним предопределенное максимальное число M деревьев.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 120, 'page_label': '121'}, page_content='7.5. Обучение ансамбля   121\\nДавайте интуитивно разберемся в том, что тут происходит. Вычисляя остатки, \\nмы определяем, насколько хорошо (или плохо) предсказывается цель каждого \\nобучающего образца текущей моделью f. Затем мы обучим другое дерево для \\nисправления ошибок текущей модели (именно поэтому мы используем остатки \\nвместо фактических меток) и добавим новое дерево в существующую модель \\nс некоторым весом α. В результате каждое новое дерево, добавленное в модель, \\nчастично исправляет ошибки, допущенные предыдущими деревьями. Процесс \\nпродолжается, пока не будет объединено максимальное количество M (еще один \\nгиперпараметр) деревьев.\\nТеперь попробуем ответить на вопрос, почему этот алгоритм называется градиент-\\nным бустингом. В градиентном бустинге мы не вычисляем градиент, в отличие от \\nтого, что мы делали в  главе 4, решая задачу линейной регрессии. Чтобы увидеть \\nсходство между градиентным бустингом и градиентным спуском, вспомните, для чего \\nмы вычисляли градиент в линейной регрессии: чтобы узнать направление изменения \\nзначений параметров для минимизации функции стоимости MSE. Градиент показы-\\nвает направление, но не показывает, как далеко идти в этом направлении, поэтому \\nв каждой итерации мы делали небольшой шаг, а затем вновь определяли направле-\\nние. То же происходит в градиентном бустинге, только вместо непосредственного \\nвычисления градиента мы используем его оценку в форме остатков: они показывают, \\nкак следует скорректировать модель, чтобы уменьшить ошибку (остаток).\\nВ градиентном бустинге доступны для настройки три основных гиперпараметра: \\nколичество деревьев, скорость обучения и глубина деревьев. Все три влияют на \\nточность модели. Глубина деревьев также влияет на скорость обучения и прогно-\\nзирования: чем меньше глубина, тем быстрее.\\nМожно показать, что обучение по остаткам оптимизирует общую модель f для \\nкритерия среднеквадратичной ошибки. Здесь можно заметить отличие от бэг -\\nгинга: бустинг уменьшает смещение (или недообученность) вместо дисперсии. \\nКак результат, бустинг подвержен переобучению. Однако, настраивая глубину \\nи количество деревьев, можно в значительной степени избежать переобучения.\\nВ задачах классификации градиентный бустинг применяется аналогично, но шаги \\nнемного отличаются. Рассмотрим случай бинарной классификации. Предположим, \\nесть M деревьев решений регрессии. По аналогии с логистической регрессией прогноз \\nансамбля деревьев решений моделируется с использованием сигмоидной функции:\\nгде \\n  и fm — дерево регрессии.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 121, 'page_label': '122'}, page_content='122   Глава 7. Проблемы и решения\\nИ снова, как в логистической регрессии, при попытке найти модель f, максими-\\nзирующую \\n , применяется принцип максимального \\nправдоподобия. Точно так же, чтобы избежать числового переполнения, мы мак-\\nсимизируем сумму логарифмов правдоподобий, а не произведение правдоподобий.\\nАлгоритм начинает работу с  начальной константной модели \\n , где \\n. (Можно показать, что такая инициализация оптимальна для сигмо-\\nидной функции.) Затем в каждой итерации m в модель добавляется новое дерево fm. \\nЧтобы найти наилучшее дерево fm, сначала вычисляется частная производная gi \\nтекущей модели для каждого i = 1, ..., N:\\nгде f — модель ансамблевого классификатора, построенная на предыдущей итера-\\nции m — 1. Чтобы вычислить gi, нужно найти производные от \\n  \\nпо f для всех i. Обратите внимание, что \\n . Произ-\\nводная по f правого члена в предыдущем уравнении равна \\n.\\nЗатем выполняется преобразование обучающего набора заменой исходной мет -\\nки yi соответствующей частной производной gi, и на основе преобразованного \\nобучающего набора строится новое дерево fm. Далее определяется оптимальный \\nшаг обновления ρm как:\\nВ конце итерации m мы обновляем модель ансамбля f, добавляя новое дерево fm:\\nИтерации продолжаются, пока не выполнится условие m = M, после чего обучение \\nпрекращается и в результате получается модель ансамбля f.\\nГрадиентный бустинг является одним из самых мощных алгоритмов машинного \\nобучения. Не только потому, что создает очень точные модели, но и потому, что спо-\\nсобен обрабатывать огромные наборы данных с миллионами данных и признаков. \\nКак правило, он превосходит в точности случайный лес, но из-за последовательной \\nприроды может обучаться намного медленнее.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 122, 'page_label': '123'}, page_content='7.6. Обучение маркировке последовательностей   123\\n7.6. Обучение маркировке \\nпоследовательностей\\nПоследовательность — один из наиболее распространенных типов структурирован-\\nных данных. Мы общаемся, используя последовательности слов и предложений, \\nмы выполняем действия в определенной последовательности, наши гены, музыка, \\nкоторую мы слушаем, видеофильмы, которые смотрим, наши наблюдения за не -\\nпрерывным процессом, таким как движение автомобиля или изменение цен акций \\nна бирже, — все это последовательности.\\nМаркировка последовательностей — это задача автоматического назначения ме-\\nток элементам последовательности. Обучающим набором для задачи маркировки \\nпоследовательностей является пара списков (X, Y), где X — список векторов при-\\nзнаков, по одному для каждого шага во времени, Y — список меток той же длины. \\nНапример, X может содержать слова в предложении, такие как [«большой», «кра-\\nсивый», «автомобиль»], а Y может содержать соответствующие части речи, такие \\nкак [«прилагательное», «прилагательное», «существительное»]). Более формально: \\nдля образца i, \\n , где sizei — длина последовательности в образце i, \\n и \\n .\\nВы уже знаете, что для маркировки последовательностей можно использовать RNN. \\nНа каждом временном шаге t она читает входной вектор признаков \\n , а послед-\\nний рекуррентный слой выводит метку \\n  (в случае бинарной маркировки) или \\n (в случае многоклассовой маркировки или маркировки с многими метками).\\nОднако RNN — не единственная возможная модель для маркировки последова -\\nтельностей. Модель, которая называется условные случайные поля (Conditional \\nRandom Fields, CRF), является очень эффективной альтернативой, которая \\nчасто дает хорошие результаты для векторов признаков, имеющих много ин -\\nформативных признаков. Например, представьте, что нам поставили задачу \\nреализовать извлечение именованных сущностей , и мы решили построить \\nмодель, которая маркировала бы каждое слово в предложении, например «Я еду \\nв Санкт-Петербург», одним из следующих классов: {местоположение, имя, назва-\\nние_компании, другое}. Если наши векторы признаков (представляющие слова) \\nсодержат такие бинарные признаки, как «слово начинается с заглавной буквы» \\nи «слово присутствует в списке местоположений», такие признаки будут очень \\nинформативными и помогут классифицировать слова Санкт и Петербург как \\nместоположение (так же, как и дефис между ними).\\nИзвестно, что определение признаков вручную — трудоемкий процесс, требующий \\nзначительных знаний в предметной области.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 123, 'page_label': '124'}, page_content='124   Глава 7. Проблемы и решения\\nCRF — очень интересная модель, и ее можно рассматривать как обобщение логи-\\nстической регрессии на последовательности. Однако на практике для маркировки \\nпоследовательностей лучше использовать глубокие двунаправ-\\nленные вентильные RNN. CRF значительно медленнее в обуче-\\nнии, что затрудняет ее применение к большим обучающим на-\\nборам (с сотнями тысяч данных). Кроме того, там, где имеются \\nбольшие обучающие наборы, глубокие нейронные сети выглядят \\nособенно привлекательно.\\n7.7. Обучение преобразованию \\nпоследовательностей в последовательности\\nОбучение преобразованию последовательностей в последовательности (sequence-\\nto-sequence, сокращенно seq2seq) является обобщением задачи маркировки после-\\nдовательностей. В seq2seq Xi и Xi могут иметь разную длину. Модели seq2seq нашли \\nприменение в машинном переводе (где, например, вход — это предложение на англий-\\nском языке, а выход — соответствующее предложение на русском), диалоговых интер-\\nфейсах (где вход — это вопрос, введенный пользователем, а выход — ответ машины), \\nобобщении текста, исправлении орфографических ошибок и многих других сферах.\\nМногие, но не все задачи обучения seq2seq в настоящее время лучше всего решают-\\nся с помощью нейронных сетей. Все сетевые архитектуры, используемые в seq2seq, \\nсостоят из двух частей: кодировщика и декодировщика.\\nКодировщик — это нейронная сеть, принимающая последовательность. Это может \\nбыть рекуррентная сеть (RNN), сверточная (CNN) или сеть с какой-то другой ар-\\nхитектурой. Роль кодировщика состоит в том, чтобы прочитать входные данные \\nи сгенерировать некое состояние (аналогичное состоянию в RNN), которое можно \\nрассматривать как числовое представление смысла входных данных, с которым \\nможет работать машина. Смысл изображения, текста, видеоролика или чего-то \\nеще обычно представляется как вектор или матрица с действительными числами. \\nЭтот вектор (или матрица) на жаргоне машинного обучения называется вложением \\n(embedding) входных данных.\\nДекодировщик — это другая нейронная сеть, которая принимает на входе вложение \\nи генерирует выходную последовательность. Как вы уже могли догадаться, это \\nвложение создается кодировщиком. Чтобы создать выходную последовательность, \\nдекодировщик берет вектор признаков x(0) начала последовательности (обычно \\nвсе нули), генерирует первый выход y(1), обновляет свое состояние, комбинируя \\nвложение и вход x(0), а затем использует выход y(1) в качестве своего следующего \\nвхода x(1). Для простоты будем считать, что y(t) имеет ту же размерность, что и x(t),'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 124, 'page_label': '125'}, page_content='7.7. Обучение преобразованию последовательностей в последовательности   125\\nхотя это необязательно. Как мы видели в главе 6, каждый слой RNN может гене-\\nрировать много выходов сразу: один может использоваться, чтобы сгенерировать \\nметку y(t), а другой, с другой размерностью, может использоваться как x(t).\\nКодировщик и декодировщик обучаются одновременно. Ошибки на выходе деко-\\nдировщика распространяются в кодировщик посредством механизма обратного \\nраспространения.\\nНа рис. 7.4 изображена традиционная архитектура seq2seq. Для \\nполучения более точных прогнозов можно использовать архитек-\\nтуры с механизмом внимания. Механизм внимания реализуется \\nс помощью дополнительного набора параметров, которые объ -\\nединяют некоторую информацию, полученную от кодировщика \\n(в RNN эта информация представлена списком векторов состо -\\nяния последнего рекуррентного уровня из всех временных шагов кодировщика), \\nс текущим состоянием декодировщика для получения метки. Это обеспечивает \\nдаже лучшую сохранность долгосрочных зависимостей, в сравнении с применением \\nвентильных узлов и двунаправленных RNN.\\nКодировщик Декодировщик\\nThe weather is fine < начало >\\nIl fait beau\\nt = 1234 12 3\\nРис. 7.4. Традиционная архитектура для обучения seq2seq. Векторное представление, \\nкоторое обычно определяется состоянием последнего слоя кодировщика, передается \\nиз левой подсети в правую\\nАрхитектура seq2seq с механизмом внимания показана на рис. 7.5.\\nОбучение seq2seq — относительно новая область исследований. Постоянно обна-\\nруживаются и публикуются новые архитектуры сетей. Обучение таких архитектур \\nможет быть сложной задачей, потому что количество настраиваемых гиперпара -'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 125, 'page_label': '126'}, page_content='126   Глава 7. Проблемы и решения\\nметров и других архитектурных решений может быть огромным. Дополнительные \\nсведения, ссылки на руководства и примеры кода ищите в вики для книги.\\nThe weather is fine < начало >\\nIl faitb eau\\nt = 1234 12 3\\nМеханизм внимания\\nРис. 7.5. Архитектура seq2seq с механизмом внимания\\n7.8. Активное обучение\\nАктивное обучение — интересная парадигма обучения с учителем. Она обычно \\nприменяется, когда получение размеченных данных обходится слишком дорого. \\nЭто часто имеет место в медицинской или финансовой областях, где для марки -\\nровки данных о пациентах или клиентах может потребоваться привлекать экс -\\nпертов. Идея состоит в том, чтобы начать обучение с относительно небольшого \\nколичества размеченных и большого количества неразмеченных образцов, а затем \\nмаркировать только те образцы, которые в наибольшей степени способствуют по-\\nвышению качества модели.\\nЕсть несколько стратегий активного обучения. Здесь мы рассмотрим следующие \\nдве:\\n1. На основе плотности и неопределенности данных.\\n2. На основе метода опорных векторов.\\nПервая стратегия применяет текущую модель f, обученную с использованием \\nимеющихся размеченных данных, к  каждому из остальных неразмеченных дан -\\nных (или, чтобы сэкономить время, к некоторой случайной выборке из них). \\nДля каждого неразмеченного образца x вычисляется оценка его важности:'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 126, 'page_label': '127'}, page_content='7.8. Активное обучение   127\\n. Плотность отражает количество ближай -\\nших данных, окружающих x, а неопределенностьf(x) — насколько неопределенным \\nявляется прогноз модели f для x. В бинарной классификации с сигмоидной функ-\\nцией чем ближе прогнозная оценка к 0.5, тем неопределеннее прогноз. В SVM: чем \\nближе образец к границе решения, тем неопределеннее прогноз.\\nВ многоклассовой классификации в качестве меры неопределенности можно ис-\\nпользовать энтропию:\\nгде \\n  — оценка вероятности, с какой модель f отнесет образец x к клас-\\nсу y(c). Как видите, если для каждого y(c) выполняется условие \\n , тогда \\nмодель является полностью неопределенной, а энтропия имеет максимальное зна-\\nчение 1; с другой стороны, если для некоторого y(c) выполняется условие \\n , \\nтогда модель полностью определена относительно класса y(c), а энтропия имеет \\nминимальное значение 0.\\nПлотность для образца x можно получить, взяв среднее значение расстояний от x \\nдо каждого из k ближайших к нему соседей (где k является гиперпараметром).\\nПосле вычисления оценок важности для всех неразмеченных дан-\\nных выбираем наибольшую и просим эксперта присвоить метку \\nсоответствующему образцу. Затем добавляем новый размеченный \\nобразец в обучающий набор, сроим модель заново и продолжаем \\nпроцесс, пока не будет удовлетворен некоторый критерий оста -\\nновки. Критерий остановки можно выбрать заранее (например, \\nмаксимальное количество обращений к эксперту, исходя из выделенного бюджета) \\nили положиться на некоторую метрику, определяющую качество работы модели.\\nСтратегия активного обучения с использованием метода опорных векторов за -\\nключается в построении модели SVM с использованием размеченных данных, \\nпосле чего эксперту предлагается присвоить метку неразмеченному образцу, нахо-\\nдящемуся ближе всех к гиперплоскости, разделяющей два класса. Идея в том, что, \\nесли образец ближе всех лежит к гиперплоскости, значит, он наименее определен \\nи его маркировка внесет наибольший вклад в определение точек, через которые \\nпроходит истинная (та, которую мы ищем) гиперплоскость.\\nНекоторые стратегии активного обучения могут включать стоимость обращения \\nк эксперту для маркировки. Другие учатся спрашивать мнение эксперта. Стратегия \\n«запрос комитетом» (query by committee) предполагает обучение нескольких мо-'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 127, 'page_label': '128'}, page_content='128   Глава 7. Проблемы и решения\\nделей с применением разных методов, после чего эксперту предлагается присвоить \\nметку образцу, на котором модели разошлись во мнении больше всего. Некоторые \\nстратегии пытаются выбирать для маркировки такие данные, чтобы максимально \\nуменьшить смещение или дисперсию модели.\\n7.9. Обучение с частичным \\nпривлечением учителя\\nВ обучении с частичным привлечением учителя (Semi-Supervised Learning, SSL) \\nточно так же маркируется небольшая часть набора данных; большинство данных \\nостаются неразмеченными. Цель — использовать большое количество неразмечен-\\nных данных для повышения эффективности модели без запроса дополнительных \\nразмеченных данных.\\nВ истории науки было несколько попыток решить эту задачу. Но ни одно из реше-\\nний не получило общего признания и широкого применения на практике. Чаще \\nдругих упоминается метод SSL, который называется самообучением. В этом ме-\\nтоде с помощью алгоритма обучения и размеченных данных строится начальная \\nмодель. Затем эта модель применяется ко всем неразмеченным примерам и произ-\\nводится их маркировка. Если показатель достоверности прогноза для некоторого \\nнеразмеченного примера x выше некоторого порогового значения (выбранного \\nэкспериментально), этот размеченный пример добавляется в обучающий набор, \\nпроизводится повторное обучение модели, и так повторяется, пока не будет удов-\\nлетворен критерий остановки. Критерием остановки, например, может служить \\nотсутствие роста правильности модели в течение последних m итераций.\\nМетод, описанный выше, может обеспечить некоторое улучшение модели по \\nсравнению с использованием только исходного размеченного набора данных, но \\nобычно это улучшение не особо впечатляет. Кроме того, качество модели может \\nдаже снизиться. Это зависит от свойств статистического распределения, из кото-\\nрого взяты данные, которые обычно неизвестны.\\nС другой стороны, недавние достижения в обучении нейронных сетей привели к до-\\nвольно впечатляющим результатам. Например, было показано, что для некоторых \\nнаборов данных, таких как MNIST (тестовый набор, состоящий из размеченных \\nизображений рукописных цифр от 0 до 9, известный в сфере распознавания об-\\nразов), модель, обученная с частичным привлечением учителя, показывает почти \\nидеальную эффективность при наличии 10 размеченных образцов на класс (всего \\n100 размеченных данных). Для сравнения, MNIST содержит 70 000 размеченных \\nобразцов (60 000 для обучения и 10 000 для тестирования). Архитектура нейрон-'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 128, 'page_label': '129'}, page_content='7.9. Обучение с частичным привлечением учителя   129\\nной сети, которая достигла такой замечательной производительности, называется \\nлестничной сетью . Чтобы понять идею, лежащую в основе лестничных сетей, \\nнужно сначала разобраться с понятием автокодировщик.\\nАвтокодировщик — это нейронная сеть прямого распространения с архитектурой \\nкодировщик-декодировщик. Она обучается восстанавливать свой вход. Соот -\\nветственно обучающий образец — это пара ( x, x). Нам нужно, чтобы, выход \\n  \\nмодели f(x) был максимально похож на вход x.\\nВажно отметить, что сеть автокодировщика напоминает песочные часы, имея узкий \\nслой «горлышка» в середине, который содержит вложение D-мерного входного \\nвектора. Обычно слой вложения имеет гораздо меньше узлов, чем D. Цель декоди-\\nровщика — восстановить входной вектор признаков из этого вложения. Теоретиче-\\nски достаточно 10 узлов в узком слое, чтобы успешно закодировать изображения \\nMNIST. В типичном автокодировщике, схематически изображенном на рис. 7.6, \\nв роли функции стоимости обычно используется либо среднеквадратическая \\nошибка (когда признаками могут быть любые числа), либо бинарная перекрест -\\nная энтропия (когда признаки имеют бинарную природу и узлы последнего слоя \\nдекодировщика имеют сигмоидную функцию активации). Когда используется \\nсреднеквадратическая ошибка, она определяется так:\\nгде \\n  — евклидово расстояние между двумя векторами.\\nКодировщик\\nДекодировщик\\nВложение\\nРис. 7.6. Автокодировщик'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 129, 'page_label': '130'}, page_content='130   Глава 7. Проблемы и решения\\nАвтокодировщик с шумоподавлением  искажает левый элемент x в обучающем \\nобразце (x, x), добавляя в признаки некоторые случайные возмущения. В случае, \\nкогда данные являются черно-белыми изображениями — с пикселами, представлен-\\nными значениями от 0 до 1, — в каждый признак обычно добавляется нормальный \\nгауссов шум. Для каждого признака j во входном векторе x значение шума n(j) \\nвыбирается из следующего распределения:\\nгде символ ~ означает «выбирается из», π — это константа и θ =  \\ndef\\n [μ, s] — гипер-\\nпараметр. Новое искаженное значение признака x(j) получается путем сложения \\nx(j) + n(j) .\\nЛестничная сеть — это усовершенствованный шумоподавляющий автокодиров -\\nщик. Кодировщик и декодировщик имеют одинаковое количество слоев. Слой \\nузкого горлышка используется непосредственно для прогнозирования метки (с по-\\nмощью функции активации softmax). Сеть имеет несколько функций стоимости. \\nДля каждого слоя l в кодировщике и соответствующего слоя l в декодировщике \\nприменяется функция \\n , штрафующая за разность между выходами двух уровней \\n(квадрат евклидова расстояния). Когда во время обучения используется разме -\\nченный образец, применяется другая функция стоимости, Cc, которая штрафует \\nза ошибку в прогнозировании метки (отрицательный логарифм правдоподобия). \\nКомбинированная функция стоимости, \\n  (усредненная по всем об -\\nразцам в пакете), оптимизируется с помощью мини-пакетного стохастического \\nградиентного спуска с обратным распространением. Гиперпараметры λl для каждого \\nслоя l определяют компромисс между стоимостью классификации и кодирования-\\nдекодирования.\\nВ лестничной сети шумом искажается не только вход, но и выход каждого слоя \\nкодировщика (в процессе обучения). При применении обученной модели к ново-\\nму входу x для предсказания его метки этот вход не искажается.\\nСуществуют и другие методы обучения с частичным привлече-\\nнием учителя, не связанные с нейронными сетями. Один из них \\nпредполагает построение модели с использованием размеченных \\nданных и кластеризацию размеченных и неразмеченных данных \\nвместе с использованием любого метода кластеризации (не -\\nкоторые из них мы рассмотрим в главе 9). Для каждого нового \\nобразца выводится прогноз — метка, присущая большинству данных в кластере, \\nкоторому он принадлежит.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 130, 'page_label': '131'}, page_content='7.10. Обучение с первого раза   131\\nЕще один метод, называемый S3VM, основан на использовании SVM. При его \\nиспользовании строится одна модель SVM для каждого возможного способа \\nмаркировки неразмеченных данных, а затем выбирается модель с наибольшим \\nзазором. В статье о S3VM (ссылку на которую вы найдете в вики) описывается \\nподход, который позволяет решить эту проблему без фактического перебора всех \\nвозможных способов маркировки.\\n7.10. Обучение с первого раза\\nЭта глава была бы неполной без упоминания двух других важных парадигм обу-\\nчения с учителем. Одна из них — обучение с первого раза (one-shot learning). \\nВ обучении с первого раза, которое обычно применяется для распознавания лиц, \\nтребуется построить модель, которая распознает, что две фотографии одного \\nчеловека действительно представляют одного и того же человека. Если показать \\nмодели две фотографии двух разных людей, она должна распознать, что это два \\nразных человека.\\nМожно попробовать решить эту задачу традиционным путем и построить бинарный \\nклассификатор, который принимает два изображения на входе и предсказывает \\nлибо истинное значение (если два изображения представляют одного и того же \\nчеловека), либо ложное (когда два изображения принадлежат разным людям). \\nОднако на практике это приведет к тому, что нейронная сеть окажется в два раза \\nбольше типичной нейронной сети, потому что для представления каждого из двух \\nизображений нужна своя подсеть. Обучить такую сеть будет сложно не только из-\\nза ее размера, но и потому, что получить положительные данные гораздо сложнее, \\nчем отрицательные. То есть задача крайне несбалансированная.\\nОдним из эффективных решений этой задачи является обучение сиамской нейрон\\xad\\nной сети (Siamese Neural Network, SNN). SNN можно реализовать как нейронную \\nсеть любого типа: CNN, RNN или MLP. Сеть принимает изображения по одному; \\nпоэтому размер сети не удваивается. Чтобы получить из сети бинарный класси -\\nфикатор «тот_же_человек»/«другой», который принимает на вход только одно \\nизображение за раз, сеть обучается особым образом.\\nДля обучения SNN мы используем функцию триплетной потери  (triplet loss). \\nНапример, пусть есть три изображения лица: изображение A (для привязки), \\nизображение P (положительное изображение) и изображение N (отрицательное \\nизображение). А и Р — два разных изображения одного и того же человека; N — \\nизображение другого человека. Каждый обучающий образец i теперь является \\nтриплетом (Ai, Pi, Ni).'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 131, 'page_label': '132'}, page_content='132   Глава 7. Проблемы и решения\\nДопустим, у нас есть модель нейронной сети f, которая принимает изображение \\nлица на входе и выводит его векторное представление. Потеря триплета для об -\\nразца i определяется как\\n max(||f(Ai) – f(Pi)||2 – ||f(Ai) – f(Ni)||2 + α, 0).  (7.3)\\nФункция стоимости определяется как среднее потери триплета:\\nгде α — положительный гиперпараметр. Очевидно, что значение || f(A) – f(P) ||2 \\nнизко, когда нейронная сеть выводит одинаковые векторные представления для A \\nи P; значение || f(Ai) – f(Ni) ||2 высоко, когда векторные представления изображений \\nдвух разных людей различны. Если модель работает правильно, тогда член m =  \\n= (|| f(Ai) – f(Pi)||2 – || f(Ai) – f(Ni) ||2 всегда будет отрицательным, потому что большое \\nзначение будет вычитаться из маленького. Увеличивая α, можно еще уменьшить \\nчлен m, чтобы убедиться, что модель научилась надежно распознавать одинаковые \\nи разные лица. Если значение m недостаточно мало, то из-за α стоимость полу -\\nчится положительной и параметры модели скорректируются на этапе обратного \\nраспространения.\\nВместо выбора случайного изображения N лучший способ создания триплетов для \\nобучения — использовать текущую модель после нескольких эпох обучения и оты-\\nскивать кандидатов на N, которые похожи на A и P, согласно этой модели. Исполь-\\nзование случайных данных в качестве N значительно замедлит процесс обучения, \\nпоскольку нейронная сеть легко будет находить различия между изображениями \\nдвух случайных людей, из-за чего средняя потеря триплета в большинстве случаев \\nбудет низкой и параметры будут обновляться недостаточно быстро.\\nЧтобы построить SNN, сначала нужно выбрать архитектуру нейронной сети. На-\\nпример, для обработки изображений часто выбирается CNN. Чтобы вычислить \\nсредние потери триплета в нашем примере, мы последовательно применяем модель \\nк A, затем к P, затем к N, а потом вычисляем потери, используя уравнение 7.3. Про-\\nцедура повторяется для всех триплетов в партии, а затем вычисляется стоимость; \\nградиентный спуск с обратным распространением распространяет стоимость через \\nсеть и тем самым корректирует ее параметры.\\nМногие заблуждаются, думая, что для обучения с первого раза нужен только \\nодин обучающий образец каждой сущности. В действительности, чтобы модель \\nидентификации получилась точной, необходимо подобрать несколько образцов \\nдля каждого человека. Это обучение называется «с первого раза» из-за сферы \\nприменения таких моделей: для идентификации по лицу. Например, такую модель'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 132, 'page_label': '133'}, page_content='7.11. Обучение без подготовки   133\\nможно использовать для разблокировки телефона. Если модель хорошо обучена, \\nвам достаточно будет хранить в телефоне только одну свою фотографию , и она \\nбудет уверенно узнавать вас, а также отличать других людей. Имея модель, которая \\nспособна определить, принадлежат ли два изображения A и \\n  одному и тому же \\nлицу, мы сравниваем \\n  с τ — гиперпараметром.\\n7.11. Обучение без подготовки\\nВ завершение главы я упомяну метод обучения без подготовки. Это относитель-\\nно новая область исследований, поэтому пока отсутствуют алгоритмы, доказав -\\nшие свою практическую ценность. Я только обрисую основную идею и оставлю \\nзнакомство с различными алгоритмами вам, как самостоятельное упражнение. \\nВ обу чении без подготовки (Zero-Shot Learning, ZSL) модель обучается назначать \\nметки объектам. Наиболее часто этот метод обучения применяется для назначения \\nметок изображениям. Однако, в отличие от стандартной классификации, модель \\nдолжна уметь прогнозировать метки, отсутствующие в обучающих данных. Как \\nтакое возможно?\\nХитрость заключается в использовании вложений, которые представляют не только \\nвходные данные x, но и выходные данные y. Представьте, что у нас есть модель, \\nкоторая для любого слова может сгенерировать вектор вложения, обладающий \\nследующим свойством: если по значению слово yi похоже на слово yk, векторы \\nвложения этих двух слов должны быть одинаковыми. Например, если yi — это \\nПариж, а yk — Рим, они будут иметь похожие векторные представления; с другой \\nстороны, если yk — это картошка, векторы вложения слов yi и yk должны быть \\nразными. Такие векторы вложения называют вложениями слов (word embeddings) \\nи обычно сравниваются с использованием мер косинусного сходства1.\\nВложения слов обладают важным свойством: каждое измерение во вложении \\nпредставляет определенную особенность значения слова. Например, если вло -\\nжение слов имеет четыре измерения (обычно их намного больше, от 50 до 300), \\nэти измерения могут представлять такие особенности значения, как животность, \\nабстрактность, кислость и желтизна (да, выглядит забавно, но это всего лишь \\nпример). Согласно такому определению, слово пчела будет иметь такое вложение: \\n[1, 0, 0, 1]. Слово желтый — такое: [0, 1, 0, 1]. Слово единорог — такое: [1, 1, 0, 0]. \\nЗначения для каждого вложения получаются с помощью специальной процедуры \\nобучения, применяемой к обширному текстовому корпусу.\\n1 В главе 10 я покажу, как получать вложения слов из данных.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 133, 'page_label': '134'}, page_content='134   Глава 7. Проблемы и решения\\nТеперь, продолжая нашу задачу классификации, заменим метку yi каждого образ-\\nца i в обучающем наборе ее вложением слова и обучим модель классификации \\nс многими метками, которая предсказывает вложения слов. Чтобы получить мет-\\nку для нового образца x, нужно применить модель f к x, получить векторное пред-\\nставление \\n , а затем найти среди всех слов те, вложения которых наиболее похожи \\nна \\n , используя косинусное сходство.\\nПочему это работает? Возьмем, к примеру, зебру. Это млекопи-\\nтающее белого цвета с полосами. Теперь возьмем рыбу-клоуна: \\nэто не млекопитающее, имеет оранжевую окраску с полосами. \\nТеперь возьмем тигра: это млекопитающее оранжевого цвета \\nс полосами. Если эти три признака присутствуют во вложениях \\nслов, CNN научится обнаруживать эти признаки на изображени-\\nях. Даже если метка тигр отсутствовала в обучающих данных, но другие объекты, \\nвключая зебру и рыбу-клоуна, присутствовали, то CNN, скорее всего, научится \\nопределять понятия млекопитающее, оранжевый и полосы для предсказания меток \\nэтих объектов. Когда мы передадим в модель изображение тигра, эти признаки бу-\\nдут правильно идентифицированы на изображении, и, скорее всего, самым близким \\nвложением слова из нашего словаря окажется вложение слова тигр.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 134, 'page_label': '135'}, page_content='8 Продвинутые методики\\nВ этой главе описываются методики, которые могут пригодиться вам в вашей \\nпрактике для решения некоторых задач. Она называется «Продвинутые методики» \\nне потому, что представленные здесь методы более сложные, а потому что они при-\\nменяются для решения узкоспециализированных задач. Во многих ситуациях эти \\nметодики вам едва ли потребуются, но иногда они оказываются очень полезными.\\n8.1. Работа с несбалансированными \\nнаборами данных\\nНа практике некоторые классы часто оказываются недостаточно представленны-\\nми в обучающих данных. Примером могут служить наборы данных, используе -\\nмые для обучения классификатора, различающего законные и мошеннические \\nтранзакции в электронной коммерции: данные законных транзакций встречаются \\nгораздо чаще. При использовании SVM с мягким зазором можно определить \\nстоимость для неправильно классифицированных данных. Поскольку в обуча-\\nющих данных всегда присутствует шум, высока вероятность, что многие данные \\nзаконных транзакций окажутся не на той стороне границы и это будет способ -\\nствовать увеличению цены.\\nАлгоритм SVM попытается сместить гиперплоскость, чтобы избежать как можно \\nбольшего числа ошибок в классификации данных. При этом стремление правильно \\nклассифицировать данные, принадлежащие к классу подавляющего большинства, \\nувеличивает риск неправильной классификации «мошеннических» данных, кото-\\nрые находятся в меньшинстве. Эта ситуация показана на рис. 8.1a. Эта проблема \\nнаблюдается в большинстве алгоритмов обучения, применяемых к несбалансиро-\\nванным наборам данных.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 135, 'page_label': '136'}, page_content='136   Глава 8. Продвинутые методики\\nЕсли увеличить стоимость ошибочной классификации данных из класса меньшин-\\nства, то модель постарается избежать неправильной классификации этих данных, \\nно ценой неправильной классификации некоторых данных из класса большинства, \\nкак показано на рис. 8.1б.\\nНекоторые реализации SVM позволяют задавать вес каждого класса. Алгоритм \\nобучения учтет эту информацию при поиске лучшей гиперплоскости.\\nx(2)\\nx(1)         \\n(а)\\nx(2)\\nx(1)         \\n(б)\\nРис. 8.1. Иллюстрация проблемы несбалансированности набора данных. (a) Оба класса \\nимеют одинаковый вес; (б) данные в классе меньшинства имеют более высокий вес'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 136, 'page_label': '137'}, page_content='8.2. Объединение моделей   137\\nЕсли алгоритм обучения не позволяет задавать вес классов, можно попробовать \\nметод увеличения выборки (oversampling). Он позволяет увеличить важность не-\\nкоторого класса путем создания нескольких копий данных из этого класса.\\nПротивоположный подход, сокращение выборки (undersampling), состоит в слу-\\nчайном исключении из обучающего набора некоторых данных из класса боль -\\nшинства.\\nТакже можно попробовать создать синтетические данные, случайно выбирая \\nзначения признаков из нескольких данных класса меньшинства и объединяя их \\nв новые данные этого класса. Есть два популярных алгоритма увеличения выбор-\\nки с образцами из класса меньшинства путем создания синтетических примеров: \\nметод расширения выборки меньшинства синтетическими образцами (Synthetic \\nMinority Oversampling Technique, SMOTE) и метод адаптивной синтетической \\nвыборки (Adaptive Synthetic Sampling, ADASYN).\\nМетоды SMOTE и ADASYN во многих отношениях действуют одинаково. Для \\nданного образца xi класса меньшинства они выбирают k ближайших его соседей \\n(обозначим этот набор из k данных как Sk), а затем создают синтетический обра-\\nзец xнов. как xi + λ(xzi –xi), где xzi — представитель класса меньшинства, выбранный \\nслучайным образом из Sk. Гиперпараметр интерполяции λ — это любое число \\nв диапазоне [0, 1].\\nОба метода, SMOTE и ADASYN, случайно выбирают все возможные xi в наборе \\nданных. В ADASYN число синтетических данных, генерируемых для каждого xi, \\nпропорционально количеству данных в Sk, не принадлежащих классу меньшинства. \\nСоответственно, в областях, где данные класса меньшинства встречаются редко, \\nгенерируется больше синтетических данных.\\nНекоторые алгоритмы менее чувствительны к проблеме несбалансированности \\nнабора данных. Деревья решений, а также случайный лес и градиентный бустинг ча-\\nсто показывают неплохую эффективность на несбалансированных наборах данных.\\n8.2. Объединение моделей\\nАнсамблевые алгоритмы, такие как случайный лес, обычно объединяют модели \\nодинаковой природы. Они увеличивают эффективность, объединяя сотни слабых \\nмоделей. На практике иногда можно получить дополнительный выигрыш в эффек-\\nтивности, комбинируя сильные модели, созданные с использованием различных \\nалгоритмов обучения. В этом случае обычно используются только две или три \\nтакие модели.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 137, 'page_label': '138'}, page_content='138   Глава 8. Продвинутые методики\\nТри типичных способа объединения моделей: 1) усреднение, 2) большинство го -\\nлосов и 3) штабелирование.\\nУ среднение может применяться к  моделям регрессии, а  также к моделям клас-\\nсификации, которые дают классификационные баллы. В этом случае все модели, \\nназовем их базовыми моделями, применяются к входу x, а их прогнозы усредняются. \\nЧтобы увидеть, обеспечивает ли модель «усреднения» более высокое качество про-\\nгнозирования, чем каждый отдельный алгоритм, ее можно проверить на тестовом \\nнаборе с использованием метрики по вашему выбору.\\nМетод большинства голосов используется в моделях классификации. Согласно \\nэтому методу, все базовые модели применяются к входу x, а в качестве общего ре-\\nзультата возвращается класс, выбранный большинством моделей. Если несколько \\nклассов получили одинаковое число голосов, результат выбирается случайным \\nобразом или возвращается сообщение об ошибке (если неправильная классифи -\\nкация имеет высокую цену).\\nШтабелирование заключается в создании метамодели, которая принимает на вход \\nвыходы базовых моделей. Допустим, нужно объединить классификаторы f1 и f2, \\nкоторые выбирают предсказание из одного набора классов. Чтобы создать обуча-\\nющий образец \\n  для суммирующей модели, нужно задать \\n  \\nи \\n .\\nЕсли какие-то из базовых моделей возвращают не только класс, но и оценку прав-\\nдоподобия для каждого класса, эти оценки тоже можно использовать как признаки.\\nДля обучения штабелирующей модели рекомендуется использовать данные из \\nобучающего набора, а настройку гиперпараметров производить с помощью пере-\\nкрестной проверки.\\nРазумеется, эффективность штабелирующей модели следует проверить на кон -\\nтрольном наборе и сравнить с эффективностью базовых моделей.\\nУвеличение эффективности объединения нескольких моделей обусловлено \\nтем, что при согласии нескольких сильных некоррелированных моделей высока \\nвероятность, что они сойдутся во мнении в отношении правильного результата. \\nКлючевое слово здесь «некоррелированный». В идеале базовые модели должны \\nбыть получены с использованием разных признаков или алгоритмов с разной при-\\nродой — например, SVM и случайный лес. Объединение разных версий алгоритма \\nдерева решений или нескольких SVM с разными гиперпараметрами может не дать \\nзначительного увеличения качества прогнозирования.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 138, 'page_label': '139'}, page_content='8.3. Обучение нейронных сетей   139\\n8.3. Обучение нейронных сетей\\nОдним из сложных аспектов в обучении нейронной сети является преобразование \\nданных во входы, которые сеть сможет обрабатывать. Если сеть должна обрабаты-\\nвать изображения, прежде всего необходимо привести все изображения к одному \\nразмеру. После этого обычно выполняется сначала стандартизация пикселов, а за-\\nтем нормализация в диапазон [0, 1].\\nТекст необходимо разбить на лексемы (то есть на такие части, как слова, знаки \\nпрепинания и другие символы). Для CNN и RNN каждая лексема преобразуется \\nв вектор с использованием унитарного кодирования, в результате чего текст пре-\\nвращается в список векторов. Другой, часто лучший способ представления лексем \\nзаключается в создании вложений слов. Для многослойного перцептрона неплохие \\nрезультаты, особенно для длинных текстов (длиннее, чем SMS-сообщения и тви-\\nты), можно получить, преобразуя тексты в векторы с использованием подхода \\n«мешок слов».\\nВыбор конкретной архитектуры нейронной сети является сложной задачей. На -\\nпример, для задачи обучения seq2seq уже создано множество архитектур и почти \\nкаждый год появляются новые. Я советую отыскать современные решения, подхо-\\nдящие для вашей конкретной задачи, с помощью поисковых систем Google Scholar \\nили Microsoft Academic, которые позволяют находить научные публикации по \\nключевым словам и диапазонам времени. Если вы не имеете ничего против менее \\nсовременных архитектур, поищите уже реализованные архитектуры на GitHub \\nи выберите такую, которую можно применить к вашим данным с минимальными \\nизменениями.\\nНа практике преимущество современной архитектуры перед более старой не так \\nважно, когда выполняются предварительная обработка, очистка и  нормализа-\\nция данных и создается больший обучающий набор. Современные архитектуры \\nнейронных сетей являются результатом сотрудничества ученых из нескольких \\nлабораторий и компаний; такие модели могут быть очень сложными для самосто-\\nятельной реализации и обычно требуют большой вычислительной мощности для \\nобучения. Время, потраченное на попытки воспроизвести результаты недавней \\nнаучной работы, может не стоить того. Это время лучше потратить на создание \\nрешения на основе пусть и менее современной, но стабильной модели, и получение \\nбольшего количества обучающих данных.\\nОпределившись с выбором архитектуры сети, нужно также определиться с ко-\\nличеством слоев, их типами и размерами. Рекомендую начать с одного или двух \\nслоев, обучить модель и посмотреть, хорошо ли она предсказывает обучающие \\nданные (имеет малое смещение). Если результат не удовлетворит вас, постепенно'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 139, 'page_label': '140'}, page_content='140   Глава 8. Продвинутые методики\\nувеличивайте размер каждого слоя и  их количество, пока модель не будет иде -\\nально прогнозировать обучающие данные. Если модель дает высокое качество \\nна обучающих данных, но низкое на контрольных (имеет высокую дисперсию), \\nдобавьте в модель регуляризацию. Если после добавления регуляризации модель \\nначала плохо предсказывать обучающие данные, немного увеличьте размер сети. \\nПродолжайте итеративно наращивать сеть и регуляризовать, пока модель не до-\\nстигнет достаточно высокого качества предсказания обучающих и контрольных \\nданных в соответствии с вашей метрикой.\\n8.4. Продвинутая регуляризация\\nВ нейронных сетях кроме L1- и L2-регуляризации можно также использовать \\nтипы регуляризации, характерные для нейронных сетей: прореживание, ранняя \\nостановка и пакетная нормализация. Последний технически не является методом \\nрегуляризации, но он часто оказывает регулирующее влияние на модель.\\nИдея прореживания очень проста. Каждый раз, передавая в сеть обучающий обра-\\nзец, нужно на время отключать некоторые узлы. Чем выше процент отключенных \\nузлов, тем выше эффект регуляризации. Библиотеки нейронных сетей позволяют \\nдобавлять прореживающий слой между двумя соседними слоями или определить \\nв самом слое параметр, управляющий прореживанием. Параметр прореживания \\nможет иметь значение в диапазоне [0, 1], и его необходимо подобрать эксперимен-\\nтально, по результатам прогнозирования на контрольных данных.\\nРанняя остановка — это метод обучения нейронной сети, предусматривающий \\nсохранение предварительной модели после каждой эпохи и оценку ее эффектив-\\nности на контрольном наборе. Как рассказывалось в разделе о градиентном спуске \\nв главе 4, с увеличением количества эпох ошибка уменьшается. Уменьшение ошиб-\\nки означает высокое качество модели на обучающих данных. Однако в какой-то \\nмомент, после некоторой эпохи, может начать развиваться эффект переобучения: \\nошибка продолжает снижаться, но качество модели на контрольных данных ухуд-\\nшается. Если сохранять в файле версию модели после каждой эпохи, вы можете \\nпрекратить обучение, как только начнет наблюдаться снижение качества прогно-\\nзирования на контрольном наборе. Как вариант, можно продолжить процесс об -\\nучения в течение определенного количества эпох, а затем выбрать лучшую модель. \\nМодели, сохраненные после каждой эпохи, называются контрольными точками. \\nНекоторые специалисты, использующие машинное обучение на практике, очень \\nчасто используют этот прием; другие пытаются найти подходящий метод регуля-\\nризации, чтобы избежать такого нежелательного поведения.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 140, 'page_label': '141'}, page_content='8.5. Обработка нескольких входов   141\\nПакетная нормализация (которую правильнее называть пакетной стандартизаци-\\nей) — это метод, заключающийся в стандартизации выходов каждого слоя перед \\nпередачей их узлам последующего слоя. На практике пакетная нормализация \\nувеличивает скорость и стабильность обучения, а также дает некоторый эффект \\nрегуляризации. Поэтому всегда полезно попробовать использовать пакетную \\nнормализацию. В библиотеках нейронных сетей часто есть возможность вставить \\nслой пакетной нормализации между двумя соседними слоями.\\nЕще один метод регуляризации, который можно применять не только к нейронным \\nсетям, но и практически к любому алгоритму обучения, называется расширением \\nданных (data augmentation). Этот метод часто используется для регуляризации \\nмоделей, работающих с изображениями. Получив исходный размеченный обу-\\nчающий набор, вы можете создать синтетический образец из исходного образца, \\nприменяя различные преобразования: слегка увеличивая размеры исходного \\nобразца, поворачивая, переворачивая, затемняя и т. д. В таких синтетических об-\\nразцах сохраняется оригинальная метка. На практике это часто дает увеличение \\nкачества модели.\\n8.5. Обработка нескольких входов\\nНа практике часто приходится работать с мультимодальными данными. Например, \\nна вход могут подаваться изображение и текст, а бинарный выход может опреде-\\nлять, описывает ли текст это изображение.\\nАлгоритмы поверхностного обучения трудно адаптировать для работы с мульти-\\nмодальными данными. Тем не менее это возможно. Можно попробовать обучить \\nдве поверхностные модели — одну для изображений, а другую для текста. После \\nэтого можно применить метод объединения моделей, описанный выше.\\nЕсли не получается разделить задачу на две независимые подзадачи, можно по -\\nпытаться преобразовать в вектор каждый вход (применяя соответствующий метод \\nпроектирования признаков), а затем просто объединить два вектора признаков, \\nчтобы сформировать один более широкий вектор признаков. Например, если \\nизображение имеет признаки [i(1), i(2), i(3)], а текст имеет признаки [t(1), t(2), t(3), t(4)], \\nтогда объединенный вектор признаков будет иметь вид [i(1), i(2), i(3), t(1), t(2), t(3), t(4)].\\nНейронные сети дают больше гибкости. Можно создать две подсети, по одной для \\nвхода каждого типа. Например, подсеть CNN может читать изображение, а под-\\nсеть RNN — текст. Последние слои обеих подсетей будут возвращать вложение: \\nCNN — вложение изображения, а RNN — вложение текста. После этого можно объ-\\nединить (конкатенировать) два вложения и добавить слой классификации, такой'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 141, 'page_label': '142'}, page_content='142   Глава 8. Продвинутые методики\\nкак softmax или sigmoid, принимающий объединенные вложения. Библиотеки \\nнейронных сетей предлагают простые в использовании инструменты, которые \\nпозволяют объединять или усреднять выходы слоев из нескольких подсетей.\\n8.6. Обработка нескольких выходов\\nВ некоторых задачах требуется предсказать несколько выходов для одного входа. \\nВ предыдущей главе мы рассмотрели классификацию с многими метками. Неко-\\nторые задачи с несколькими выходами можно эффективно преобразовать в задачу \\nклассификации с многими метками. Особенно если они имеют метки одинаковой \\nприроды (например, теги). Или можно создать фиктивные метки, как комбинации \\nоригинальных меток.\\nОднако в некоторых случаях с мультимодальными выходами нет возможности \\nперечислить их комбинации. Рассмотрим следующий пример: нужно построить \\nмодель, которая обнаруживает объект на изображении и возвращает его коорди-\\nнаты. Кроме того, модель должна возвращать тег, описывающий объект, например: \\n«человек», «кошка» или «хомяк». В обучающих образцах имеется вектор при -\\nзнаков, представляющий изображение. Метка представлена вектором координат \\nобъекта и еще одним вектором с закодированным тегом.\\nВ ситуациях, подобных этой, можно создать одну подсеть, которая будет работать \\nкак кодировщик и читать входное изображение, используя, например, один или \\nнесколько сверточных слоев. Последним слоем кодировщика будет вложение \\nизображения. Поверх слоя с вложением можно добавить еще две подсети, одна \\nиз которых будет принимать вложение и предсказывать координаты объекта. Эта \\nпервая подсеть может иметь выходной слой ReLU, что является хорошим выбором \\nдля прогнозирования положительных действительных чисел, таких как коорди -\\nнаты, и использовать в качестве функции стоимости среднеквадратичную ошибку \\nC1. Вторая подсеть будет принимать то же вложение и прогнозировать вероятность \\nкаждой метки. Эта вторая подсеть может иметь выходной слой softmax, который \\nхорошо подходит для прогнозирования вероятностей, и использовать в качестве \\nфункции стоимости усредненный отрицательный логарифм правдоподобия C2 \\n(также называется стоимостью перекрестной энтропии).\\nОчевидно, что в этом случае важно, насколько точно предсказываются и коорди-\\nнаты, и метка. Однако невозможно оптимизировать сразу две функции стоимости. \\nЕсть риск, что оптимизация одного критерия пойдет в  ущерб другому. В такой \\nситуации можно добавить еще один гиперпараметр γ в диапазоне (0, 1) и опреде-'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 142, 'page_label': '143'}, page_content='8.7. Перенос обучения   143\\nлить комбинированную функцию стоимости как γC1 + (1 – γ)C2, а затем настроить \\nзначение γ с использованием контрольных данных, как еще один гиперпараметр.\\n8.7. Перенос обучения\\nПеренос обучения (transfer learning) — это тот случай, когда нейронные сети имеют \\nуникальное преимущество перед поверхностными моделями. При переносе обуче-\\nния выбирается существующая модель, обученная на некотором наборе данных, \\nи адаптируется для прогнозирования данных из другого набора данных, отличного \\nот того, на котором была построена модель. Этот второй набор данных не похож \\nна контрольные наборы, которые используются для проверки и тестирования. \\nОн может представлять какое-то другое явление или, как говорят специалисты \\nпо машинному обучению, он может происходить из другого статистического рас-\\nпределения.\\nНапример, представьте, что вы обучили модель распознавать (и маркировать) \\nдиких животных, использовав большой набор размеченных данных. Через неко -\\nторое время вам предложили решить еще одну задачу: построить модель, которая \\nраспознавала бы домашних животных. С поверхностными алгоритмами обучения \\nу вас не так много вариантов: вам придется создать еще один большой набор раз-\\nмеченных данных, но уже для домашних животных.\\nПри использовании нейронных сетей ситуация обстоит намного лучше. Можно \\nвоспользоваться переносом обучения, который в нейронных сетях работает сле-\\nдующим образом.\\n1. На основе оригинального набора данных (с дикими животными) строится \\nглубокая модель.\\n2. Собирается намного меньший набор размеченных данных для второй модели \\n(с домашними животными).\\n3. С конца первой модели удаляется один или несколько слоев. Обычно это слои, \\nотвечающие за классификацию или регрессию, и следуют за слоем, создающим \\nвекторное представление (вложение).\\n4. Удаленные слои заменяются новыми, адаптированными для решения новой \\nзадачи.\\n5. Фиксируются («замораживаются») параметры слоев, доставшихся от первой \\nмодели.\\n6. С использованием небольшого набора размеченных данных и градиентного \\nспуска производится обучение параметров новых слоев.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 143, 'page_label': '144'}, page_content='144   Глава 8. Продвинутые методики\\nВ интернете можно найти множество глубоких моделей для задач распознавания \\nобразов, и среди них вам вполне вероятно удастся найти ту, которая окажется \\nполезной для вашей задачи. Скачайте эту модель, удалите несколько последних \\nслоев (количество слоев для удаления — это гиперпараметр), добавьте свои слои \\nпрогнозирования и обучите полученную модель на ваших данных.\\nДаже если вы не найдете готовые модели, прием переноса обучения все равно смо-\\nжет помочь вам в ситуациях, когда задача требует очень дорогостоящего набора \\nразмеченных данных и есть возможность получить другой, более доступный набор \\nразмеченных данных. Допустим, вы строите модель классификации документов \\nи получили от заказчика список, содержащий тысячу категорий. В этом случае \\nвам нужно будет заплатить кому-то, чтобы тот: а) прочитал, понял и запомнил раз-\\nличия между категориями и б) прочитал до миллиона документов и разметил их.\\nЧтобы сэкономить на маркировке такого большого количества данных, вы можете \\nиспользовать страницы «Википедии» в качестве обучающего набора данных и по-\\nстроить свою первую модель. Метки для страницы в «Википедии» можно получить \\nавтоматически, взяв, например, категории, к которым относится страница. Обучив \\nпервую модель предсказывать категории из «Википедии», вы сможете «настроить» \\nэту модель, чтобы предсказать категории из списка вашего заказчика. Для решения \\nпоставленной задачи вам, вероятно, понадобится гораздо меньше размеченных \\nданных, чем если бы вы начали решать ее с нуля.\\n8.8. Эффективность алгоритмов\\nНе все алгоритмы, способные решить задачу, являются практичными. Некоторые \\nмогут работать слишком медленно. Некоторые задачи можно решить с помощью \\nбыстрого алгоритма, для других задач быстрых алгоритмов может и вовсе не су -\\nществовать.\\nРаздел информатики, называемый анализом алгоритмов, занимается проблемами \\nопределения и сравнения сложности алгоритмов. Для классификации алгоритмов \\nв соответствии с ростом их требований к времени выполнения или объему памяти \\nпри увеличении размера входных данных используется критерий О большое.\\nНапример, допустим, что у нас есть задача поиска двух самых удаленных друг \\nот друга одномерных данных в множестве S размера N. Один алгоритм для ре -\\nшения этой задачи мог бы выглядеть так (здесь и далее приводится реализация \\nна Python):'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 144, 'page_label': '145'}, page_content='8.8. Эффективность алгоритмов   145\\n1 def find_max_distance(S):\\n2     result = None\\n3     max_distance = 0\\n4     for x1 in S:\\n5         for x2 in S:\\n6             if abs(x1 - x2) >= max_distance:\\n7                 max_distance = abs(x1 - x2)\\n8                 result = (x1, x2)\\n9     return result\\nАлгоритм выше перебирает все значения в S и в каждой итерации первого цикла \\nповторно перебирает все значения в S. То есть этот алгоритм выполняет N 2 сравне-\\nний чисел. Если время выполнения сравнения, вычисления абсолютного значения \\nи присваивания принять за единицу времени, тогда временная сложность (или про-\\nсто сложность) этого алгоритма в худшем случае составит 5N 2. (В каждой итерации \\nмы имеем одно сравнение, две операции вычисления абсолютного значения и две \\nоперации присваивания.) Когда измеряется сложность алгоритма в худшем случае, \\nиспользуется запись O большое. Сложность алгоритма выше можно записать как \\nO (N2); константы, такие как число 5, игнорируются.\\nТ у же задачу можно решить с помощью другого алгоритма:\\n1 def find_max_distance(S):\\n2     result = None\\n3     min_x = float(\"inf\")\\n4     max_x = float(\"-inf\")\\n5     for x in S:\\n6         if x < min_x:\\n7             min_x = x\\n8         if x > max_x:\\n9             max_x = x\\n10     result = (max_x, min_x)\\n11     return result\\nЭтот алгоритм предусматривает обход элементов множества S только один раз, \\nпоэтому он имеет сложность O (N). В таких случаях мы говорим, что этот алгоритм \\nэффективнее предыдущего.\\nАлгоритм считается эффективным, когда его сложность находится в полиноми-\\nальной зависимости от объема входных данных. Следовательно, эффективны оба \\nалгоритма, со сложностью O (N) и O (N 2), потому что N — это полином степени 1, \\nа N2 — полином степени 2. Однако для очень больших объемов входных данных \\nалгоритм O (N 2) может оказаться слишком медленным. В эпоху больших данных \\nученые часто стремятся отыскать алгоритмы O (log N).'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 145, 'page_label': '146'}, page_content='146   Глава 8. Продвинутые методики\\nС практической точки зрения, реализуя свой алгоритм, старайтесь по возможности \\nизбегать циклов. Например, вместо циклов используйте операции с  матрицами \\nи векторами. В Python для вычисления wx вы должны написать:\\n1 import numpy\\n2 wx = numpy.dot(w,x),\\nа не\\n1 wx = 0\\n2 for i in range(N):\\n3     wx += w[i]*x[i]\\nИспользуйте подходящие структуры данных. Если порядок элементов в коллек-\\nции не имеет значения, используйте set вместо list. В Python операция провер-\\nки принадлежности конкретного экземпляра x множеству S выполняется более \\nэффективно, когда S объявлено как множество set, и менее эффективно, когда S \\nобъявлено как список list.\\nДругая важная структура данных, которую можно использовать для увеличения \\nэффективности кода на Python, — это словарь dict. В других языках он называется \\nтакже ассоциативным массивом. Словарь позволяет определить набор пар ключ/\\nзначение и обеспечивает очень быстрый поиск ключей.\\nЕсли у вас нет абсолютной уверенности в своих действиях, всегда старайтесь ис-\\nпользовать популярные библиотеки для научных вычислений. Пакеты для Python, \\nтакие как numpy, scipy и scikit-learn, были созданы опытными учеными и инженерами \\nи реализуют очень эффективные алгоритмы. Они предлагают множество методов, \\nнаписанных на языке программирования C, для максимальной эффективности.\\nЕсли вам понадобится выполнить обход элементов очень большой коллекции, ис-\\nпользуйте генераторы, которые создают функцию, возвращающую один элемент \\nза раз, а не все сразу.\\nИспользуйте пакет cProfile для поиска неэффективных фрагментов в своем коде \\nна Python.\\nНаконец, когда в вашем коде не осталось ничего, что можно было бы улучшить \\nс алгоритмической точки зрения, у вас все равно остается возможность увеличить \\nскорость выполнения кода, если задействовать:\\n  пакет multiprocessing для параллельного выполнения сразу нескольких вычис-\\nлений;\\n  PyPy, Numba или другие похожие инструменты для компиляции кода на \\nPython в быстрый и оптимизированный машинный код.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 146, 'page_label': '147'}, page_content='9 Обучение без учителя\\nОбучение без учителя используется для решения задач, когда отсутствуют раз -\\nмеченные данные. Это свойство делает данный подход трудноприменимым для \\nрешения многих практических задач. Отсутствие меток, представляющих желаемый \\nрезультат, означает отсутствие надежной контрольной точки для оценки качества \\nмодели. В этой книге я представляю только методы обучения без учителя, позволя-\\nющие строить модели, которые можно оценить исключительно на основе данных, \\nа не человеческих суждений.\\n9.1. Оценка плотности\\nОценка плотности — это задача моделирования функции плотности вероятности \\n(probability density function, pdf) неизвестного распределения, из которого был по-\\nлучен набор данных. Этот метод может пригодиться во многих случаях, в частности \\nдля обнаружения новизны или факта вторжения. В главе 7 мы уже использовали \\nоценку функции плотности вероятности, когда решали задачу одноклассовой клас-\\nсификации. Тогда мы решили, что наша модель будет параметрической, а точнее, \\nмногомерным нормальным распределением (Multivariate Normal Distribution, \\nMND). Это решение было несколько произвольным, потому что, если фактическое \\nраспределение, из которого получен набор данных, отличается от MVN, модель, \\nскорее всего, будет далека от идеальной. Мы также знаем, что модели могут быть \\nнепараметрическими. Мы использовали непараметрическую модель в ядерной \\nрегрессии. Как оказывается, тот же подход можно применять для оценки плотности.\\nПусть \\n  — набор одномерных данных (решение задачи для многомерного слу-\\nчая выглядит аналогично), полученный из распределения с неизвестной функцией \\nплотности вероятности f с \\n  для всех i = 1, ..., N. Нам требуется смоделировать \\nформу f. Наша ядерная модель f, обозначенная как \\n , определяется как\\n \\n   (9.1)'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 147, 'page_label': '148'}, page_content='148   Глава 9. Обучение без учителя\\nгде b — гиперпараметр, управляющий компромиссом между смещением и диспер-\\nсией модели, а k — ядро. Так же как в главе 7, используем ядро Гаусса:\\nТребуется найти значение b, минимизирующее разницу между фактической фор-\\nмой f и формой нашей модели \\n . Для оценки разницы разумно выбрать средний \\nнакопленный квадрат ошибки (Mean Integrated Squared Error, MISE):\\n \\n   (9.2)\\nВ уравнении 9.2 мы возводим в квадрат разницу между фактической pdf f и нашей \\nмоделью \\n . Интеграл \\n  заменяет суммирование \\n  в среднеквадратичной \\nошибке, а оператор ожидания \\n  заменяет среднее значение \\n .\\nДействительно, когда потеря является функцией с непрерывной областью значе-\\nний, такой как \\n , мы должны заменить суммирование интегралом. \\nОперация ожидания \\n  означает, что b должно быть оптимальным для всех возмож-\\nных реализаций обучающего набора \\n . Это важно, потому что \\n  определена \\nна конечной выборке некоторого распределения вероятностей, а фактическая pdf f \\nопределена в бесконечной области (множество \\n ).\\nТеперь перепишем правую сторону уравнения 9.2, как показано ниже:\\nТретий член в формуле выше не зависит от b, следовательно, его можно игнориро-\\nвать. Несмещенная оценка первого слагаемого задается как \\n , тогда как \\nнесмещенную оценку второго слагаемого можно аппроксимировать перекрестной \\nпроверкой \\n , где \\n  — ядерная модель f, вычисленная на обучаю-\\nщем наборе после исключения образца xi.\\nЧлен \\n  известен в статистике как оценка с одним отделяемым объектом, \\nформа перекрестной проверки, в которой каждый блок состоит из одного образца. \\nВозможно, вы заметили, что член \\n  (назовем его a) — это ожидаемое \\nзначение функции \\n , потому что f — это функция плотности вероятности (pdf). \\nМожно показать, что оценка с одним отделяемым объектом является несмещенной \\nоценкой \\n .'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 148, 'page_label': '149'}, page_content='9.2. Кластеризация   149\\nобучающие данные\\nистинная pdf\\n    \\nобучающие данные\\nистинная pdf\\n (а)  (б)\\nистинная pdf\\nобучающие данные\\n    \\n (в) (г)\\nРис. 9.1. Ядерная оценка плотности: (a) хорошее соответствие; (б) модель переобучена; \\n(в) модель недообучена; (г) кривая поиска по сетке для выбора оптимального значения b\\nТеперь, чтобы найти оптимальное значение b* для b, минимизируем стоимость, \\nкоторая определяется как\\nНайти b* можно с помощью поиска по сетке. Для D-мерных векторов признаков член \\nошибки x – xi в уравнении 9.1 можно заменить евклидовым расстоянием || x – xi ||. На \\nрис. 9.1 показаны оценки для одной и той же pdf, полученные с тремя разными зна-\\nчениями b из набора данных со 100 образцами, а также кривая поиска по сетке. Мы \\nвыбираем значение b*, соответствующее нижней точке на кривой поиска по сетке.\\n9.2. Кластеризация\\nКластеризация — это задача обучения выбору меток для данных с использовани-\\nем набора неразмеченных данных. Поскольку набор данных не содержит меток,'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 149, 'page_label': '150'}, page_content='150   Глава 9. Обучение без учителя\\nоценить оптимальность полученной модели намного сложнее, чем в обучении \\nс учителем.\\nСуществует множество алгоритмов кластеризации, и, к сожалению, сложно сказать, \\nкакой из них окажется лучшим для того или иного набора данных. Обычно каче-\\nство работы каждого алгоритма зависит от неизвестных свойств распределения, \\nиз которого был получен набор данных. В этой главе я опишу наиболее полезные \\nи широко используемые алгоритмы кластеризации.\\n9.2.1. Кластеризация k средних\\nАлгоритм кластеризации k средних работает следующим образом. Сначала вы -\\nбирается k — количество кластеров. Затем в пространстве признаков случайным \\nобразом выбираются k векторов признаков, называемых центроидами.\\nЗатем, с использованием некоторой метрики, например евклидова расстояния, вы-\\nчисляется расстояние от каждого образца x до каждого центроида. Затем каждому \\nобразцу ставится в соответствие ближайший центроид (как если бы мы назначали \\nкаждому образцу метку с идентификатором центроида). Для каждого центроида \\nвычисляется средний вектор признаков данных, связанных с ним. Эти средние \\nвекторы признаков становятся новыми местоположениями центроидов.\\nДалее снова вычисляется расстояние от каждого образца до каждого центроида и из-\\nменяется его метка. Процедура повторяется до тех пор, пока после очередного пере-\\nсчета местоположений центроидов связи не останутся неизменными. Модель пред-\\nставляет собой список связей между идентификаторами центроидов и образцами.\\nНачальное положение центроидов влияет на конечные положения, поэтому два \\nпрогона алгоритма k средних могут дать две разные модели. Некоторые вариан -\\nты k средних вычисляют начальные положения центроидов, исходя из некоторых \\nсвойств набора данных.\\nНа рис. 9.2 показан один прогон алгоритма k средних. Кружки на рис. 9.2 представля-\\nют двумерные векторы признаков; квадраты — движущиеся центроиды. Различные \\nцвета фона представляют области, в которых все точки принадлежат одному кластеру.\\nЗначение k — количество кластеров — является гиперпараметром, который вы -\\nбирается аналитиком. Существует несколько методов выбора k, но ни один не \\nявляется оптимальным. Большинство из этих методов требуют, чтобы аналитик \\nсделал «обоснованное предположение», просматривая некоторые метрики или \\nвизуально изучая разбиение на кластеры. В этой главе я представлю один из под-\\nходов, помогающий выбрать достаточно хорошее значение для k, не требующий \\nпросматривать данные и делать какие-либо предположения.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 150, 'page_label': '151'}, page_content='9.2. Кластеризация   151\\n    \\n Исходные данные Итерация 1\\n    \\n Итерация 3 Итерация 5\\nРис. 9.2. Ход выполнения алгоритма k средних для k = 3\\n9.2.2. DBSCAN и HDBSCAN\\nВ отличие от k средних и других подобных алгоритмов, основанных на центрои -\\nдах, алгоритм DBSCAN осуществляет кластеризацию на основе плотности. Алго-\\nритм DBSCAN не требует угадывать количество кластеров, вместо этого нужно \\nопределить два гиперпараметра: ϵ и n. В самом начале выбирается случайный \\nобразец x и маркируется как принадлежащий кластеру 1. Затем подсчитывается \\nчисло данных, расстояние от которых до x меньше или равно ϵ. Если это число \\nбольше или равно n, тогда все эти ϵ-соседи помещаются в один и тот же кластер 1. \\nЗатем проверяется каждый член кластера 1 и выявляются соответствующие им \\nϵ-соседи. Если какой-либо член кластера 1 имеет n или больше ϵ-соседей, все они \\nтоже добавляются в кластер 1. Процесс расширения кластера 1 продолжается, пока \\nне останется данных, которые можно было бы добавить в него. После этого из на-\\nбора данных выбирается другой образец, не принадлежащий ни одному кластеру,'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 151, 'page_label': '152'}, page_content='152   Глава 9. Обучение без учителя\\nи помещается в кластер 2. Так продолжается до тех пор, пока все данные не будут \\nпринадлежать какому-либо кластеру или не будут отмечены как аномальные. \\nАномальный образец — это образец, имеющий меньше n ϵ-соседей.\\nПреимущество алгоритма DBSCAN состоит в том, что он может создавать кластеры \\nпроизвольной формы, в то время как k средних и другие алгоритмы на основе цен-\\nтроидов создают кластеры, имеющие форму гиперсферы. Очевидный недостаток \\nDBSCAN в том, что он имеет два гиперпараметра, выбор хороших значений для \\nкоторых (особенно для ϵ) может вызывать затруднения. Кроме того, с фиксирован-\\nным гиперпараметром ϵ алгоритм кластеризации не может эффективно работать \\nс кластерами, имеющими различную плотность.\\nHDBSCAN — это алгоритм кластеризации, сохраняющий преимущества DBSCAN \\nи устраняющий необходимость выбирать значение ϵ. Алгоритм способен строить \\nкластеры, имеющие разную плотность. HDBSCAN  — это искусная комбинация \\nмножества идей, так что полное описание алгоритма выходит за рамки этой книги.\\nHDBSCAN имеет только один важный гиперпараметр: n, минимальное количество \\nданных в одном кластере. Этот гиперпараметр относительно легко выбрать, осно-\\nвываясь на интуиции. HDBSCAN имеет очень быстрые реализации, способные \\nэффективно работать с миллионами данных. Современные реализации k средних \\nнамного быстрее, чем HDBSCAN, однако качества последнего могут перевесить \\nего недостатки при решении многих практических задач. Я рекомендую всегда \\nпробовать использовать HDBSCAN для ваших данных в первую очередь.\\n9.2.3. Определение числа кластеров\\nСамый важный вопрос — сколько кластеров в наборе данных? Когда векторы при-\\nзнаков одно-, дву- или трехмерные, можно нарисовать распределение данных на \\nграфике и увидеть «облака» точек в пространстве признаков. Каждое облако — это \\nпотенциальный кластер. Однако для D-мерных данных, с D > 3, нарисовать такой \\nграфик проблематично1.\\nОдин из способов определения разумного количества кластеров основан на идее \\nпрогнозирующей силы. Суть состоит в том, чтобы разделить данные на обучающий \\nи тестовый наборы, как это делается в обучении с учителем. Выделив обучающий \\nи тестовый наборы, Str с размером Ntr и Ste с размером Nte соответственно, вы фикси-\\n1 Некоторые аналитики строят несколько двумерных графиков, на которых одновременно \\nприсутствует только пара признаков. Это тоже может дать представление о количестве \\nкластеров. Однако такой подход страдает субъективностью, подвержен ошибкам и счи-\\nтается обоснованным предположением, а не научным методом.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 152, 'page_label': '153'}, page_content='9.2. Кластеризация   153\\nруете количество кластеров k, запускаете алгоритм кластеризации C на наборах Str \\nи Ste и получаете результаты кластеризации C(Str, k) и C(Ste, k).\\nПусть A — результат кластеризации C(Str, k), полученный для обучающего набора. \\nКластеры в A можно рассматривать как области. Если образец попадает в одну из \\nэтих областей, значит, он принадлежит некоторому конкретному кластеру. Напри-\\nмер, если применить алгоритм k средних к некоторому набору данных, в результате \\nполучится разбиение пространства признаков на k многоугольных областей, как \\nпоказано на рис. 9.2.\\nОпределим матрицу N te × Nte совместной принадлежности D[A, Ste], элементы \\nкоторой D[A, Ste](i, i`) = 1 тогда и только тогда, когда данные xi и xi`  из тестового на-\\nбора принадлежат тому же кластеру, согласно разбиению A. В противном случае \\nD[A, Ste](i, i`) = 0.\\nА теперь прервемся и посмотрим, что у нас получилось. Мы создали разбиение A, \\nиспользовав обучающий набор данных, на k кластеров. Затем построили матрицу \\nсовместной принадлежности, которая указывает, принадлежат ли два образца из \\nтестового набора одному кластеру в A.\\nОчевидно, что если величина k является разумной, тогда два образца, принадлежа-\\nщие одному кластеру в решении C(Ste, k), скорее всего, будут принадлежать одному \\nкластеру в решении и C(Str, k). С другой стороны, если значение k не является \\nразумным (слишком высокое или слишком низкое), тогда разбиения на основе \\nобучающих и тестовых данных, вероятно, будут менее согласованными.\\nНа рис. 9.3 показаны использованные данные, а рис. 9.4 иллюстрирует идею. Гра-\\nфики на рис. 9.4a и 9.4б показывают результаты C(Str, 4) и C(Ste, 4) с соответству-\\nющими областями кластеров. На рис. 9.4в показаны тестовые данные, нанесенные \\nна области кластеров, полученных в ходе кластеризации обучающих данных. На \\nрис. 9.4в можно видеть, что оранжевые тестовые данные больше не принадлежат \\nодному кластеру в соответствии с областями, полученными на обучающих данных. \\nВ результате в матрице D[A, Ste] появляется множество нулей, что в свою очередь \\nпоказывает, что k = 4, вероятно, не лучшее число кластеров.\\nБолее формально прогнозирующая сила числа кластеров k определяется как\\nгде \\n , Aj — j-й кластер из разбиения C(Ste, k) и | Aj | — число данных \\nв кластере Aj.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 153, 'page_label': '154'}, page_content='154   Глава 9. Обучение без учителя\\n    \\n Полный набор данных Обучающий набор\\nТестовый набор\\nРис. 9.3. Данные, использованные в задаче кластеризации,  \\nрешение которой показано на рис. 9.4\\nС учетом разбиения C(Str, k) для каждого тестового кластера вычисляется доля \\nпар в нем, которые также попали в один и тот же кластер, определяемый центро-\\nидом для обучающего набора. Прогнозирующая сила определяется как минимум \\nэтой величины для k тестовых кластеров.\\nКак показывают эксперименты, разумное количество кластеров \\nявляется наибольшим k при ps(k) выше 0.8. На рис 9.5 показаны \\nпримеры определения прогнозирующей силы разных значений k \\nдля данных, делящихся на два, три и четыре кластера.\\nДля недетерминированных алгоритмов кластеризации, таких как \\nk средних, которые могут генерировать разные варианты разбиения, в зависимо-\\nсти от начальных положений центроидов, рекомендуется выполнить несколько \\nпрогонов алгоритма кластеризации для одного и того же k и вычислить среднюю \\nпрогнозирующую силу \\n .'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 154, 'page_label': '155'}, page_content='9.2. Кластеризация   155\\n   \\n (а) (б)\\n(в)\\nРис. 9.4. Результат кластеризации для k = 4: (a) результат кластеризации обучающего \\nнабора; (б) результат кластеризации тестового набора; (в) тестовые данные, нанесенные \\nповерх результатов кластеризации обучающего набора\\nДругой эффективный метод оценки количества кластеров называется статистикой \\nразрывов (gap statistic). К другим, менее автоматизированным методам, которые \\nвсе еще используются некоторыми аналитиками, относятся метод «локтя» (elbow \\nmethod) и метод среднего силуэта (average silhouette).\\n9.2.4. Другие алгоритмы кластеризации\\nМетоды DBSCAN и k средних реализуют так называемую жесткую кластери \\xad\\nзацию, в которой каждый образец может принадлежать только одному класте -\\nру.  Модель смеси гауссовых распределений  (Gaussian Mixture Model, GMM) \\nдопускает включение каждого образца в несколько кластеров с разным баллом \\nчленства (HDBSCAN тоже поддерживает такую возможность). Кластеризация'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 155, 'page_label': '156'}, page_content='156   Глава 9. Обучение без учителя\\n    \\n    \\n    \\nРис. 9.5. Прогнозирующая сила разных значений k для данных, делящихся на два, \\nтри и четыре кластера\\nметодом GMM очень похожа на оценку плотности на основе модели. В GMM \\nвместо одного многомерного нормального распределения (MND) используется \\nвзвешенная сумма нескольких MND:'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 156, 'page_label': '157'}, page_content='9.2. Кластеризация   157\\nгде fμj, Σj\\n — многомерное нормальное распределение j, а ϕj — его вес в сумме. Значения \\nпараметров μj, Σj и ϕj для всех j = 1, ..., k получаются с использованием алгоритма \\nмаксимизации ожидания  (Expectation Maximization, EM), оптимизирующего \\nкритерий максимального правдоподобия.\\nИ снова ради простоты рассмотрим пример с одномерными данными. Также пред-\\nположим, что есть два кластера: k = 2. В этом случае мы имеем два распределения \\nГаусса\\n  (9.3)\\nгде \\n  и \\n  — две функции плотности вероятности (pdf), опре-\\nделяющие вероятность X = x.\\nИспользуем алгоритм EM (максимизации ожидания) для оценки μ1, \\n , μ2, \\n , ϕ1 \\nи ϕ2. Параметры ϕ1 и ϕ2 больше пригодятся для оценки плотности, чем для класте-\\nризации, как мы увидим ниже.\\nАлгоритм EM действует, как описывается далее. Сначала выбираем наугад на -\\nчальные значения μ1, σ1\\n2, μ2 и \\n  и устанавливаем ϕ1 = ϕ2 = 1/2 (в общем случае 1/k \\nдля каждого ϕj, j ∈ 1, …, k).\\nВ каждой итерации алгоритма EM выполняются четыре шага:\\n1. Для всех i = 1, ..., N вычисляется вероятность для каждого xi с использованием \\nуравнения 9.3:\\n2. С использованием правила Байеса для каждого образца xi вычисляется веро-\\nятность \\n  его принадлежности кластеру j ∈ {1, 2} (то есть вероятность, что \\nобразец получен из распределения Гаусса j):\\nПараметр ϕj отражает вероятность, что распределение Гаусса j с параметрами μj и \\n  \\nмогло дать наш набор данных. Вот почему вначале мы устанавливаем ϕ1 = ϕ2 = 1/2: \\nмы не знаем, насколько вероятно каждое из двух распределений, и отражаем нашу \\nнеосведомленность, устанавливая вероятность того и другого равной одной второй.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 157, 'page_label': '158'}, page_content='158   Глава 9. Обучение без учителя\\nистинная pdf\\nобучающие данные\\n   \\nистинная pdf\\nобучающие данные\\nистинная pdf\\nобучающие данные\\n    \\nистинная pdf\\nобучающие данные\\nРис. 9.6. Ход создания модели смеси гауссовых распределений с использованием \\nалгоритма EM для двух кластеров (k = 2)\\n3. Вычисляются новые значения \\n  и \\n , \\n  как\\n \\n   (9.4)\\n4. Корректируется \\n , \\n  как\\nШаги 1–4 повторяются, пока значения μ j и \\n  не перестанут существенно из -\\nменяться: например, изменение становится меньше, чем некоторое пороговое \\nзначение ϵ. Этот процесс иллюстрирует рис. 9.6.\\nВозможно, вы обратили внимание, что алгоритм EM очень похож на алгоритм k \\nсредних: сначала случайно выбираются кластеры, затем в цикле корректируются'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 158, 'page_label': '159'}, page_content='9.3. Сокращение размерности   159\\nпараметры каждого кластера путем усреднения данных, связанных с этим класте-\\nром. Единственное отличие GMM от EM состоит в том, что образец xi связывается \\nс кластером j не жестко: xi принадлежит кластеру j с вероятностью \\n . Вот поче-\\nму новые значения для μj и \\n  в уравнении 9.4 вычисляются не как средние (как \\nв методе k средних), а как средневзвешенные, с весами \\n .\\nПосле определения значений параметров μ j и \\n  для каждого кластера j, оценка \\nвероятности принадлежности образца x к кластеру j определяется как \\n .\\nОписанный алгоритм легко распространить на случай D-мерных данных (D > 1). \\nЕдинственное отличие — вместо дисперсии σ2 потребуется использовать ковари-\\nационную матрицу Σ, которая параметризует полиномиальное нормальное рас -\\nпределение (MND).\\nВ отличие от метода k средних, где кластеры могут быть только сферическими, \\nкластеры в GMM имеют эллиптическую форму с произвольным удлинением и углом \\nповорота. Эти свойства определяются значениями в ковариационной матрице.\\nНе существует общепризнанного метода выбора правильного \\nзначения k в GMM. Я советую сначала разбить набор данных \\nна обучающий и тестовый наборы. Затем выбрать разные значе-\\nния k, для каждого построить модель \\n  на основе обучающих \\nданных и по окончании выбрать значение k, максимизирующее \\nвероятности принадлежности данных в тестовом наборе:\\nгде | Nte | — размер тестового набора.\\nВ литературе можно найти описание многих других алгоритмов кластеризации. \\nОтдельно стоит упомянуть алгоритмы спектральной и иерархической класте \\xad\\nризации . Они могут оказаться более оптимальными для некоторых наборов \\nданных. Однако в большинстве случаев вполне достаточно алгоритмов k средних, \\nHDBSCAN и модели гауссовой смеси.\\n9.3. Сокращение размерности\\nСовременные алгоритмы машинного обучения, такие как ансамблевые алгоритмы \\nи нейронные сети, хорошо справляются с многомерными образцами, имеющими \\nочень большую размерность, вплоть до миллионов признаков. В настоящее время, \\nна современном уровне развития вычислительной техники с мощными графиче-\\nскими процессорами, методы сокращения размерности используются реже, чем'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 159, 'page_label': '160'}, page_content='160   Глава 9. Обучение без учителя\\nв прошлом. Чаще всего этот прием применяется для визуализации данных: люди \\nмогут интерпретировать графики, имеющие не больше трех измерений.\\nДругая ситуация, где можно извлечь выгоду из сокращения размерности, — когда \\nнужно построить интерпретируемую модель и вы ограничены в выборе алгорит-\\nмов обучения. Например, вам разрешено использовать только обучение деревьев \\nрешений или линейную регрессию. Сокращая размерность данных и выясняя, \\nкакое качество исходного образца отражает каждый новый признак в сокращенном \\nпространстве признаков, вы получаете возможность использовать более простые \\nалгоритмы. Сокращение размерности устраняет избыточные или сильно коррели-\\nрованные признаки, а также уменьшает долю шума в данных — все это способствует \\nувеличению интерпретируемости модели.\\nНа практике для сокращения размерности широко используются три основных \\nметода: метод главных компонент (Principal Component Analysis, PCA), равномер\\xad\\nная аппроксимация и проекция многообразия (Uniform Manifold Approximation \\nand Projection, UMAP) и автокодировщики.\\nЯ уже рассказывал об автокодировщиках в главе 7. Используя этот подход, в каче-\\nстве вектора с уменьшенной размерностью можно использовать низкоразмерный \\nвыход слоя узкого горлышка  автокодировщика, который представляет вектор \\nвходных объектов с высокой размерностью. Известно, что этот низкоразмерный \\nвектор представляет значимую информацию, содержащуюся во входном векторе, \\nблагодаря чему автокодировщик способен восстановить входной вектор признаков, \\nопираясь исключительно на слой узкого горлышка.\\n9.3.1. Метод главных компонент\\nМетод главных компонент (Principal Component Analysis, PCA) является одним из \\nстарейших методов сокращения размерности. Математический аппарат, лежащий \\nв его основе, опирается на выполнение операций с матрицами, о которых я ничего \\nне говорил в главе 2, поэтому оставлю знакомство с PCA как самостоятельное \\nупражнение. Здесь я приведу только краткий пример применения этого метода.\\nПусть имеется массив двумерных данных, как показано на рис. 9.7a. Основными \\nкомпонентами являются векторы, определяющие новую систему координат, в ко-\\nторой первая ось направлена в сторону наибольшей дисперсии в данных. Вторая \\nось ортогональна первой и направлена в сторону второй наибольшей дисперсии \\nв данных. Если бы данные были трехмерными, можно было бы провести третью \\nось, ортогональную к первой и ко второй осям, направленную в сторону третьей \\nнаибольшей дисперсии, и т. д. На рис. 9.7б показаны две основные компоненты \\nв виде стрелок. Длина стрелки отражает дисперсию в данном направлении.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 160, 'page_label': '161'}, page_content='9.3. Сокращение размерности   161\\n   \\n (а) (б)\\n(в)\\nРис. 9.7. Метод главных компонент: (a) исходные данные; (б) две главные компоненты \\nв виде векторов; (в) проекция данных на первую главную компоненту\\nТеперь, чтобы сократить размерность данных до Dнов. < D, нужно выбрать Dнов. самых \\nбольших главных компонент и спроецировать на них точки данных. Для нашей \\nдвумерной иллюстрации можно принять Dнов. = 1, спроецировать данные на первую \\nглавную компоненту и получить оранжевые точки, как на рис. 9.7в.\\nЧтобы описать каждую оранжевую точку, нужна только одна ко-\\nордината вместо двух: координата относительно первой главной \\nкомпоненты. Когда данные имеют очень большую размерность, \\nна практике часто случается так, что первые две или три главные \\nкомпоненты «объясняют» большую часть дисперсии в данных, \\nпоэтому, отображая данные на двух- или трехмерном графике, \\nмы действительно можем получить наглядную картину, отражающую основные \\nсвойства многомерных данных.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 161, 'page_label': '162'}, page_content='162   Глава 9. Обучение без учителя\\n9.3.2. UMAP\\nМногие современные алгоритмы сокращения размерности, особенно разработан-\\nные специально для целей визуализации, такие как t\\xadSNE и UMAP, основываются \\nна схожих идеях. Сначала разрабатывается метрика сходства двух данных. Для \\nцелей визуализации, помимо евклидова расстояния между двумя образцами, эта \\nметрика сходства часто отражает некоторые локальные свойства двух данных, \\nтакие как плотность других данных вокруг них.\\nВ UMAP такая метрика сходства w определяется как\\n \\n   (9.5)\\nФункция wi(xi, xj) определяется как\\nгде d(xi, xj) — евклидово расстояние между двумя образцами, ρi — расстояние от \\nxi до ближайшего соседа, σi — расстояние от xi до k-го ближайшего соседа (k — ги-\\nперпараметр алгоритма).\\nМожно показать, что метрика, определяемая уравнением 9.5, изменяется в диа-\\nпазоне от 0 до 1 и симметрична, то есть w (xi, xj) = w (xj, xi).\\nОбозначим через w сходство двух данных в исходном многомерном пространстве, \\nи пусть \\n  представляет сходство, заданное тем же уравнением 9.5, в новом про-\\nстранстве с меньшей размерностью.\\nЧтобы продолжить, я должен ввести понятие нечеткого множества . Нечеткое \\nмножество является обобщением множества. Для каждого элемента x нечеткого \\nмножества S существует функция принадлежности μS (x) ϵ [0, 1] , которая опреде-\\nляет степень принадлежности x к множеству S. Мы говорим, что x в малой степени \\nпринадлежит нечеткому множеству S, если значение  μS (x) близко к нулю. С другой \\nстороны, если значение μS (x) близко к 1, тогда x имеет сильную принадлежность \\nк S. Если μS (x) = 1 для всех x ϵ S, то нечеткое множество S становится эквивалент-\\nным нормальному, четкому множеству.\\nТеперь посмотрим, зачем нам здесь нужно это понятие нечеткого множества.\\nПоскольку значения w и w′ лежат в диапазоне от 0 до 1, мы можем рассматривать \\nw (xi, xj) как метрику принадлежности пары данных (xi, xj) некоторому нечеткому'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 162, 'page_label': '163'}, page_content='9.3. Сокращение размерности   163\\nмножеству. То же самое можно сказать и о w′. Сходство двух нечетких множеств \\nназывается перекрестной энтропией нечетких множеств и определяется как\\n \\n   (9.6)\\nгде x′ — низкоразмерная «версия» оригинального образца x с б\\ue088 ольшим числом \\nизмерений.\\nПараметры xi′ (для всех i = 1, ..., N) в уравнении 9.6 представляют искомые низко-\\nразмерные данные. Их можно вычислить с помощью градиентного спуска, путем \\nминимизации Cw, wʹ.\\n PCA UMAP\\nАвтокодировщик\\nРис. 9.8. Сокращение размерности набора данных MNIST с использованием  \\nтрех разных методов'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 163, 'page_label': '164'}, page_content='164   Глава 9. Обучение без учителя\\nНа рис. 9.8 показан результат сокращения размерности набора данных MNIST, \\nсодержащего изображения рукописных цифр. Набор MNIST часто используется \\nдля сравнительного анализа разных систем обработки изображений; он содержит \\n70 000 размеченных данных. Десять разных цветов на диаграмме соответствуют \\nдесяти классам. Каждая точка соответствует конкретному образцу в наборе дан-\\nных. Как видите, UMAP визуально лучше разделяет данные (не забывайте, что \\nэтот метод не использует метки). На практике UMAP немного медленнее метода \\nглавных компонент (PCA), но быстрее автокодировщика.\\n9.4. Обнаружение аномалий\\nЗадача обнаружения аномалий заключается в выявлении в некоем наборе данных \\nтаких данных, которые сильно отличаются от типичного представителя из этого \\nнабора. Мы уже познакомились с некоторыми методами, способными помочь ре-\\nшить эту задачу: автокодировщики и обучение классификатора с единственным \\nклассом. В случае с автокодировщиком мы обучаем его на наборе данных, а затем, \\nкогда требуется предсказать, является ли образец аномальным, используем модель \\nавтокодировщика и реконструируем образец из слоя узкого горлышка. Модель \\nвряд ли сможет реконструировать аномальный образец.\\nВ случае с классификатором с одним классом модель предсказывает, что входной \\nобразец принадлежит классу или является аномальным.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 164, 'page_label': '165'}, page_content='10\\nДругие формы \\nобучения\\n10.1. Определение метрик\\nЯ уже говорил, что чаще всего в качестве метрик сходства (или различий) между \\nдвумя векторами признаков используются евклидово расстояние и косинусное \\nсходство. Такой выбор метрики кажется логичным, но необоснованным, как и вы-\\nбор квадрата ошибки в линейной регрессии (или сама линейная форма регрессии). \\nТот факт, что качество метрики зависит от набора данных, явно показывает, что \\nни одна метрика не является идеальной.\\nВы можете создать метрику, которая лучше подходит для вашего набора данных, \\nи интегрировать ее в любой алгоритм обучения, которому требуется метрика, \\nнапример, k средних или kNN. Как без опробования всех возможных вариантов \\nузнать, какое уравнение будет хорошей метрикой? Как вы уже наверняка догада-\\nлись, метрику можно вывести из самих данных.\\nНапомню, как определяется евклидово расстояние между двумя векторами при -\\nзнаков, x и \\n :\\nЭту метрику можно немного изменить и сделать ее параметризуемой, а затем \\nопределить эти параметры из данных. Рассмотрим следующую модификацию:\\nгде A — матрица D × D. Пусть D = 3. Если принять, что A является единичной \\nматрицей,'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 165, 'page_label': '166'}, page_content='166   Глава 10. Другие формы обучения\\nтогда \\n  становится евклидовым расстоянием. Если A является неединичной \\nдиагональной матрицей, такой как\\nтогда разные измерения будут иметь в метрике разную важность. (В примере выше \\nвторое измерение является более важным в вычислении метрики.) В общем случае, \\nчтобы называться метрикой, функция двух переменных должна удовлетворять \\nтрем условиям:\\n1. d(x, x′) ≥ 0, неотрицательность;\\n2. d(x, x′) ≤ d(x, z) + d(z, x), неравенство треугольника;\\n3. d(x, x′) = d(x′, x), симметрия.\\nДля удовлетворения первых двух условий матрица A должна быть положительно \\nполуопределенной. Положительно полуопределенную матрицу можно рассматри-\\nвать как обобщение понятия неотрицательного действительного числа. Любая \\nположительно полуопределенная матрица M удовлетворяет условию\\nzTMz ≥ 0,\\nдля любого вектора z, размерность которого совпадает с числом строк и столбцов в M.\\nУказанное выше свойство следует из определения положительно полуопреде -\\nленной матрицы. Доказательство выполнения второго условия, когда матрица A \\nявляется положительно полуопределенной, можно найти на веб-сайте книги.\\nЧтобы удовлетворить третье условие, можно просто взять (d(x, x′) + d(x′, x))/2.\\nДопустим, что у нас есть неразмеченное множество \\n . Чтобы построить \\nобучающие данные для задачи определения метрики, вручную создаются два \\nнабора. В первый набор S включаются пары данных ( xi, xk), если xi и xk похожи \\n(с субъективной точки зрения). Во второй набор D включаются пары данных \\n(xi, xk), если xi и xk непохожи.\\nЧтобы получить матрицу параметров A из данных, нужно найти положительную \\nполуопределенную матрицу A, которая решает следующую задачу оптимизации:'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 166, 'page_label': '167'}, page_content='10.2. Определение ранга   167\\nгде c — положительная константа (может быть любым числом).\\nРешение этой задачи оптимизации находится с помощью модифицированного \\nградиентного спуска, гарантирующего, что найденная матрица A является поло-\\nжительно полуопределенной. Я оставляю описание алгоритма за рамками этой \\nкниги для самостоятельного изучения.\\nСледует отметить, что обучение с первого раза с использованием \\nсиамских сетей и триплетных потерь можно рассматривать как \\nзадачу определения метрики: пары изображений одного человека \\nпринадлежат множеству S, а пары случайных изображений при-\\nнадлежат D.\\nСуществует много других способов определения метрики, в том числе нелинейных \\nи ядерных. Однако метода, представленного в книге, а также адаптации метода \\nобучения с первого раза должно быть достаточно для большинства практических \\nприменений.\\n10.2. Определение ранга\\nОпределение ранга является задачей обучения с учителем. Среди прочего определе-\\nние ранга часто используется для оптимизации результатов поиска, возвращаемых \\nпоисковой системой в ответ на запрос. В оптимизации рангов результатов поиска \\nразмеченный образец Xi в обучающем наборе с размером N является ранжирован-\\nной коллекцией документов размера ri (метки определяют ранг документов). Век-\\nтор признаков представляет каждый документ в коллекции. Цель обучения — найти \\nфункцию ранжирования f, возвращающую значения, которые можно использовать \\nдля ранжирования документов. Для каждого обучающего образца идеальная функ-\\nция f будет возвращать значения, которые определяют тот же ранг, что и метки.\\nКаждый образец Xi, i = 1, ..., N — это коллекция векторов признаков с метками: \\n. Элементы в векторе признаков xi,j представляют документ j = 1, \\n..., ri. Например, \\n  может представлять давность создания документа, \\n  — на-\\nличие искомых слов в названии документа, \\n  — размер документа и т. д. Метка yi,j \\nможет быть рангом (1, 2, ..., ri) или оценкой. Например, чем ниже оценка, тем выше \\nрейтинг документа.\\nСуществует три подхода к решению этой задачи: поточечный, попарный и спи\\xad\\nсочный.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 167, 'page_label': '168'}, page_content='168   Глава 10. Другие формы обучения\\nПри использовании поточечного подхода каждый обучающий образец преоб -\\nразуется в несколько данных: по одному на документ. Задача обучения в этом \\nслучае превращается в стандартную задачу обучения с учителем, регрессии или \\nлогистической регрессии. В каждом образце (x, y) в задаче поточечного обучения \\nx — это вектор признаков некоторого документа, а y — исходная оценка (если \\nyi, j — оценка) или синтетическая оценка, полученная из ранжирования (чем выше \\nранг, тем ниже синтетическая оценка). В этом случае можно использовать любой \\nалгоритм обучения с учителем. Однако решение обычно получается далеким от \\nидеального. В основном это связано с тем, что каждый документ рассматривается \\nизолированно, в то время как исходное ранжирование (заданное метками yi,j в ис-\\nходном обучающем наборе) может оптимизировать позиции всего набора докумен-\\nтов. Например, если мы уже присвоили высокий ранг странице из «Википедии» \\nв некоторой коллекции документов, мы бы предпочли не давать высокий ранг \\nдругой странице с этого же сайта в ответ на тот же запрос.\\nПри использовании попарного подхода документы тоже рассматриваются изоли-\\nрованно, однако в этом случае рассматривается сразу пара документов. Для пары \\nдокументов (xi, xk) строится модель f, которая получает пару (xi, xk) и возвращает \\nзначение, близкое к 1, если ранг документа xi должен быть выше ранга документа xk; \\nв противном случае f возвращает значение, близкое к 0. Во время тестирования \\nокончательный ранг для неразмеченного образца X получается путем агрегиро -\\nвания прогнозов для всех пар документов в X. Попарный подход работает лучше \\nпоточечного, но все еще далек от совершенства.\\nСовременные алгоритмы обучения, такие как LambdaMART, реализуют подход, \\nоснованный на списках. При использовании списочного подхода модель оптими-\\nзируется непосредственно по некоторому показателю, который отражает качество \\nранжирования. Существуют разные метрики для оценки ранжирования результа-\\nтов в поисковых системах, в том числе точность и полнота. Одна из популярных \\nметрик, которая сочетает в себе точность и полноту, называется усредненной \\nсредней точностью (Mean Average Precision, MAP).\\nЧтобы определить MAP , попросим экспертов (в Google их называют ранжиров-\\nщиками) изучить коллекцию результатов поиска для запроса и присвоить оценки \\nрелевантности каждому результату. Метки могут быть бинарными (1 для «реле -\\nвантных» и 0 для «нерелевантных») или иметь некоторый масштаб, скажем, от 1 \\nдо 5: чем выше значение, тем более релевантным для запроса является документ. \\nПусть наши эксперты выполнят такую маркировку для коллекции из 100 запро -\\nсов. Теперь проверим нашу модель ранжирования для этой коллекции. Точность \\nмодели для некоторого запроса определяется как'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 168, 'page_label': '169'}, page_content='10.2. Определение ранга   169\\nгде запись \\n  означает «число документов». Метрика средней точности, AveP , \\nопределяется для ранжированной коллекции документов, возвращаемых поис -\\nковой системой в ответ на запрос q как\\nгде n — количество найденных документов, P(k) обозначает точность, вычисленную \\nдля k первых результатов поиска, возвращаемых моделью ранжирования в ответ на \\nзапрос, rel(k) — это индикаторная функция, равная 1, если элемент с рангом k явля-\\nется релевантным документом (по мнению экспертов), и ноль в противном случае. \\nНаконец, MAP для коллекции поисковых запросов размера Q определяется как\\nТеперь вернемся к алгоритму LambdaMART. Он реализует попарный подход \\nи использует градиентный бустинг для обучения функции ранжирования h(x). \\nЗатем бинарная модель f(xi, xk), предсказывающая, что документ xi должен иметь \\nболее высокий ранг, чем документ xk (для того же поискового запроса), задается \\nсигмоидой с гиперпараметром α:\\nИ снова, как во многих моделях, предсказывающих вероятность, функция стоимо-\\nсти является перекрестной энтропией, вычисляемой с использованием модели f. \\nВ нашем градиентном бустинге мы объединяем несколько деревьев регрессии, \\nчтобы построить функцию h, пытаясь минимизировать стоимость. Напомню, что \\nв градиентном бустинге мы добавляем дерево в модель, чтобы уменьшить ошибку \\nтекущей модели на обучающих данных. Для задачи классификации мы вычисляем \\nпроизводную функции стоимости, чтобы заменить фактические метки обучающих \\nданных этими производными. Алгоритм LambdaMART работает аналогично, за \\nодним исключением. Он заменяет фактический градиент комбинацией градиента \\nи еще одного фактора, который зависит от метрики, такой как MAP. Этот фактор \\nизменяет исходный градиент, увеличивая или уменьшая его, что способствует \\nулучшению метрики.\\nЭто блестящая идея, и не многие алгоритмы обучения с учителем могут похва -\\nстаться тем, что оптимизируют метрику напрямую. Оптимизация метрики — это \\nто, в чем мы действительно заинтересованы, однако типичный алгоритм обучения \\nс учителем оптимизирует стоимость вместо метрики (это делается потому, что'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 169, 'page_label': '170'}, page_content='170   Глава 10. Другие формы обучения\\nобычно метрики не дифференцируемы). В обучении с учителем после создания \\nмодели, оптимизирующей функцию стоимости, мы часто пытаемся настроить ги-\\nперпараметры, чтобы улучшить метрику. Алгоритм LambdaMART оптимизирует \\nметрику непосредственно.\\nОстается вопрос: как построить ранжированный список результатов, опираясь на \\nпрогнозы модели f, которая предсказывает, должен ли ее первый вход иметь более \\nвысокий ранг, чем второй. В общем случае это сложная вычислительная задача, \\nи существует множество реализаций механизмов ранжирования, способных пре-\\nобразовывать попарные сравнения в список ранжирования.\\nСамый простой подход — использовать существующий алгоритм \\nсортировки. Алгоритмы сортировки сортируют коллекцию чисел по \\nвозрастанию или убыванию. (Самый простой алгоритм сортировки \\nназывается пузырьковой сортировкой. Его часто преподают в вузах.) \\nОбычно алгоритмы сортировки итеративно сравнивают пары чисел \\nв коллекции и меняют их местами, исходя из результатов сравнения. \\nЕсли внедрить функцию f в алгоритм сортировки, чтобы выполнить это сравнение, \\nалгоритм сортировки будет сортировать документы, а не числа.\\n10.3. Обучение делать рекомендации\\nОбучение делать рекомендации — это подход к созданию рекомендательных си-\\nстем. Обычно есть пользователь, который потребляет контент, есть история потреб-\\nления и требуется предложить этому пользователю новый контент, который мог бы \\nему понравиться. Это может быть фильм на «Нетфликсе» или книга на «Амазоне».\\nДля реализации рекомендаций традиционно используются два подхода: фильтра\\xad\\nция контента и совместная фильтрация.\\nФильтрация контента заключается в изучении того, что нравится пользователям, \\nна основе описания потребляемого ими контента. Например, если пользователь \\nновостного сайта часто читает статьи по науке и технике, мы могли бы предложить \\nему больше документов по науке и технике. В более общем случае мы могли бы \\nсоздать обучающий набор для каждого пользователя  и добавить в него статьи, \\nкаждая из которых представлена в виде вектора признаков x, а также метки y, от-\\nражающей то, что пользователь недавно читал данную статью. После этого остается \\nтолько построить модель каждого пользователя и регулярно проверять каждый \\nновый контент, чтобы определить, заинтересует ли он конкретного пользователя.\\nПодход на основе контента имеет много ограничений. Например, пользователь \\nможет оказаться в так называемом пузыре фильтров: система всегда будет пред -'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 170, 'page_label': '171'}, page_content='10.3. Обучение делать рекомендации   171\\nлагать пользователю информацию, которая выглядит очень похожей на то, что он \\nуже потреблял. В  результате пользователь может оказаться в  полной изоляции \\nот информации, которая не соответствует его точке зрения или дополняет ее. \\nВ итоге пользователи могут просто перестать следовать таким рекомендациям, \\nчто нежелательно.\\nСовместная фильтрация имеет важное преимущество перед фильтрацией контента: \\nрекомендации для конкретного пользователя вычисляются на основе того, что по-\\nтребляют или оценивают другие пользователи. Например, если два пользователя \\nдали высокие оценки одним и тем же десяти фильмам, тогда весьма вероятно, что \\nпользователь 1 высоко оценит новые фильмы, рекомендованные на основе вкусов \\nпользователя 2, и наоборот. Недостаток этого подхода заключается в игнорирова-\\nнии содержания рекомендуемых элементов.\\nПри совместной фильтрации информация о пользовательских предпочтениях \\nорганизована в виде матрицы. Каждая строка соответствует пользователю, а каж-\\nдый столбец — контенту, который пользователь оценил или потребил. Обычно \\nэта матрица огромна и чрезвычайно разрежена, то есть большинство ее ячеек не \\nзаполнены (или заполнены нулями). Причина разреженности заключается в том, \\nчто большинство пользователей потребляют или оценивают лишь небольшую \\nчасть доступного контента. На основе таких разреженных данных очень сложно \\nдать содержательные рекомендации.\\nВ большинстве действующих рекомендательных систем используется гибридный \\nподход: они сочетают рекомендации, полученные с помощью моделей фильтрации \\nконтента и совместной фильтрации.\\nЯ уже отмечал, что модель рекомендаций на основе контента можно построить \\nс использованием модели классификации или регрессии, которая предсказывает \\nотношение пользователя к контенту на основе признаков этого контента. Приме-\\nрами признаков могут служить слова в книгах или статьях, которые понравились \\nпользователю, цена, актуальность контента, личность автора контента и т. д.\\nДвумя наиболее эффективными алгоритмами обучения системы рекомендаций \\nсчитаются метод факторизации (Factorization Machines, FM) и автокодировщики \\nс шумоподавлением (Denoising Autoencoders, DAE).\\n10.3.1. Метод факторизации\\nМетод факторизации — это относительно новый вид алгоритмов. Он специально \\nразрабатывался для разреженных наборов данных. Проиллюстрируем его при -\\nменение на примере.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 171, 'page_label': '172'}, page_content='172   Глава 10. Другие формы обучения\\nx(1)\\nx(2)\\nx(3)\\nx(4)\\nx(5)\\nx(6)\\n...\\nx(D)\\n1\\n1\\n1\\n1\\n1\\n1\\n000\\n... ... ... ...\\n00\\n00\\n00\\n00\\n00\\n00 ...\\n...\\n...\\n...\\n...\\n...\\n...\\nпользователь\\nEd Al Zak It Up Jaws HerIt Up Jaws Her...\\n1\\n0\\n0\\n0\\n0\\n0\\n100\\n... ... ... ...\\n00\\n01\\n01\\n01\\n00\\n10 ...\\n...\\n...\\n...\\n...\\n...\\n...\\n0\\n0\\n...\\n0\\n0\\n0\\n0\\n1\\nфильм\\n0.2\\n0.2\\n0.2\\n0\\n0\\n0\\n100\\n... ... ... ...\\n0.8 0.4\\n0.40.8\\n0.8 0.4\\n0 0.7\\n0 0.7\\n0.8 0 ...\\n...\\n...\\n...\\n...\\n...\\n...\\n0.6\\n0\\n...\\n0\\n0\\n0.7\\n0.1\\n0.1\\nоцененные фильмы\\nx99 x100\\n0.3\\n0.3\\n0.3\\n0.35\\n0.35\\n0.5\\n0.95\\n...\\n0.8\\n0.8\\n0.8 \\n0.78\\n0.78\\n0.77\\n...\\n0.85\\n1\\n3\\n2\\n3\\n1\\n4\\n5\\n...\\ny \\ny(1)\\ny(2)\\ny(3)\\ny(4)\\ny(5)\\ny(6)\\ny(D)\\n...\\nx1 x2 x3 x21 x22 x23 x24... ... x40 x41 x42 x43 ...\\nРис. 10.1. Пример разреженных векторов признаков x и соответствующих им меток y\\nНа рис. 10.1 показан пример разреженных векторов признаков с метками. Каждый \\nвектор признаков представляет информацию об одном конкретном пользователе \\nи одном конкретном фильме. Признаки в синей области представляют пользова-\\nтеля. Векторы, представляющие пользователей, получены методом унитарного \\nкодирования. Элементы в зеленой области представляют фильмы. Эти векторы \\nтакже получены методом унитарного кодирования. Признаки в желтой области \\nпредставляют оценки, которые пользователь из синей области присвоил каждому \\nоцененному им фильму. Признак x99 представляет долю фильмов, получивших \\nОскара, среди просмотренных пользователем. Признак x100 представляет процент \\nобщей протяженности фильма, просмотренного пользователем из синей области, до \\nтого, как он оценил фильм в зеленой области. Цель y представляет оценку, данную \\nпользователем из синей области фильму из зеленой области.\\nВ настоящих рекомендательных системах количество пользователей может исчис-\\nляться миллионами, поэтому матрица на рис. 10.1 будет насчитывать сотни милли-\\nонов строк. Количество признаков может составлять сотни тысяч, в зависимости от \\nбогатства выбора контента и вашей изобретательности, как аналитика, в разработке \\nпризнаков. Элементы x99 и x100 были определены вручную, в процессе проектирования \\nпризнаков, и в этом примере я остановлюсь только на двух признаках.\\nПопытка обучить регрессионную модель или модель классификации на таком \\nчрезвычайно разреженном наборе данных приведет к плохому обобщению. Метод \\nфакторизации решает эту задачу по-другому.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 172, 'page_label': '173'}, page_content='10.3. Обучение делать рекомендации   173\\nМодель метода факторизации определяется следующим образом:\\nгде b и wi, i = 1, ..., D — скалярные параметры, подобные тем, что используются \\nв линейной регрессии. Векторы vi — это k-мерные векторы факторов. k является \\nгиперпараметром и обычно имеет значение намного меньше, чем D. Выражение \\nvivj — это скалярное произведение i-го и j-го векторов факторов.\\nКак видите, вместо попытки отыскать один большой вектор параметров, который \\nможет плохо отражать взаимосвязи между признаками из-за разреженности, мы \\nдополняем его дополнительными параметрами, отражающими парные взаимосвязи \\nxi xj между признаками. Однако вместо параметра wi,j для каждой взаимосвязи, что \\nдобавило бы огромное1 количество новых параметров в модель, мы факторизуем \\nwi,j на vivj, добавляя Dk << D(D – 1) параметров в модель2.\\nВ зависимости от задачи функция потерь может быть квадратом ошибок потерь \\n(для регрессии) или кусочно-линейной функцией потерь. Для классификации \\nс y ϵ {–1, +1}, прогнозирование с кусочно-линейной функцией потерь или логи -\\nстическими потерями осуществляется по формуле y = sign(f(x)). Логистические \\nпотери определяются как\\nДля оптимизации средней потери можно использовать градиентный спуск. В при-\\nмере на рис. 10.1 метки принадлежат множеству {1, 2, 3, 4, 5}, соответственно, это \\nзадача классификации с многими классами. Мы можем использовать стратегию \\n«один против всех», чтобы преобразовать эту задачу в пять задач бинарной клас-\\nсификации.\\n10.3.2. Автокодировщики с шумоподавлением\\nВ главе 7 вы узнали, что такое автокодировщик с шумоподавлением: это нейрон-\\nная сеть, которая восстанавливает входные данные из слоя узкого горлышка. Тот \\nфакт, что входные данные искажены шумом, а выход должен быть свободен от \\nнего, делает автокодировщики с шумоподавлением идеальным инструментом для \\nпостроения модели рекомендации.\\n1 Точнее, добавилось бы D (D – 1) параметров wi, j.\\n2 Запись << означает «намного меньше, чем».'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 173, 'page_label': '174'}, page_content='174   Глава 10. Другие формы обучения\\nИдея очень проста: новые фильмы, которые могут понравиться пользователю, вы-\\nглядят так, будто они были удалены из полного набора предпочтительных фильмов \\nв результате какого-то процесса. Цель автокодировщика с шумоподавлением — \\nвосстановить эти удаленные элементы.\\nЧтобы подготовить обучающий набор для автокодировщика с шумоподавлением, \\nнужно удалить синие и зеленые элементы из обучающего набора на рис. 10.1. По-\\nскольку после этого некоторые примеры будут повторять друг друга, их нужно \\nудалить и оставить только уникальные элементы.\\nЗатем производится обучение автокодировщика восстановлению поврежденного \\nвхода, с заменой нулями некоторых ненулевых признаков в желтой области слу-\\nчайным образом во время обучения.\\nВо время прогнозирования нужно создать вектор признаков, представляющий \\nпользователя, содержащий неповрежденные признаки из желтой области, а также \\nэлементы, созданные вручную, такие как x99 и x100. С помощью обученной модели \\nDAE восстановить неповрежденный вход и вернуть пользователю рекомендован-\\nные фильмы, имеющие самые высокие оценки в выходе модели.\\nДругая эффективная модель совместной фильтрации — FFNN \\nс двумя входами и одним выходом. Как говорилось в главе 8, \\nнейронные сети хорошо справляются сразу с несколькими вхо-\\nдами. Обучающим образцом здесь является триплет ( u, m, r). \\nВходной вектор u представляет пользователя и получен методом \\nунитарного кодирования. Второй входной вектор m представляет \\nфильм и тоже получен методом унитарного кодирования. Выходной слой может \\nбыть сигмоидой (в этом случае метка r принадлежит диапазону [0, 1]) или ReLU, \\nкогда r может принадлежать некоторому типичному диапазону, например [1, 5].\\n10.4. Самообучение с учителем: \\nвложения слов\\nМы уже обсуждали вложения слов в главе 7. Напомню, что вложения — это век-\\nторы признаков, представляющие слова. Главное их свойство заключается в том, \\nчто похожие слова имеют похожие векторы признаков. Вопрос, который наверняка \\nвозник у вас — откуда берутся эти вложения. Ответ: они извлекаются из данных.\\nЕсть много алгоритмов для создания вложений слов. Здесь мы рассмотрим толь-\\nко один из них: word2vec, и только одну версию, которая называется skip\\xadgram, \\nхорошо зарекомендовавшую себя на практике. В интернете можно найти готовые \\nвложения word2vec для многих языков, доступные для скачивания.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 174, 'page_label': '175'}, page_content='10.4. Самообучение с учителем: вложения слов   175\\nГлавная цель при создании вложений слов — получить модель, которую можно \\nиспользовать для преобразования векторов, полученных методом унитарного \\nкодирования, во вложения слов. Пусть словарь содержит 10 000 слов. При исполь-\\nзовании унитарного кодирования для каждого слова получается 10 000-мерный \\nвектор с нулями во всех элементах, кроме одного, содержащего 1. Разные слова \\nимеют значение 1 в разных измерениях.\\nРассмотрим предложение: «Я почти закончил читать книгу по машинному обу-\\nчению». Теперь рассмотрим то же предложение, из которого мы удалили одно \\nслово, например «книгу». Теперь предложение выглядит так: «Я почти закончил \\nчитать · по машинному обучению». Теперь оставим только три слова перед · и три \\nпосле: «почти закончил читать · по машинному обучению». Посмотрите на этот \\nфрагмент из семи слов с · в центре. А теперь представьте, что я предложил вам \\nугадать, что означает ·. Вы почти наверняка дадите ответ: «книга», «статья» или \\n«документ». Именно так слова из контекста позволяют предсказать слово, которое \\nони окружают. Машина тоже может определить, что слова «книга», «документ» \\nи «статья» имеют схожее значение: потому что они имеют схожий контекст во \\nмножестве текстов.\\nКак оказывается, обратное тоже верно: слово может предсказать контекст, который \\nего окружает. Часть «почти закончил читать · по машинному обучению» называется \\nскипграммой (skip-gram) с размером окна 7 (3 + 1 + 3). Используя документы, до-\\nступные в интернете, можно создать сотни миллионов скипграмм.\\nОбозначим скипграмму следующим образом: [x–3, x–2, x–1, x, x+1, x+2, x+3]. В нашем \\nпредложении x –3 — это вектор унитарного кодирования для слова «почти», x–2 со-\\nответствует «закончил», x — пропущенное слово (·), x+1 — «по» и т. д. Скипграмма \\nс размером окна 5 будет выглядеть следующим образом: [x–2, x–1, x, x+1, x+2].\\nМодель скипграммы с размером окна 5 схематически изображена на рис. 10.2. \\nЭто полносвязанная сеть, подобная многослойному перцептрону. Входное слово \\nобозначено в скипграмме как ·. Нейронная сеть должна научиться предсказывать \\nконтекстные слова скипграммы с учетом центрального слова.\\nТеперь должно быть понятно, почему обучение такого рода называется самообу\\xad\\nчением с учителем: размеченные данные извлекаются из неразмеченных данных, \\nтаких как текст.\\nВ выходном слое используется функция активации softmax. \\nФункция стоимости — отрицательное логарифмическое прав -\\nдоподобие. Вложение слова возвращается слоем вложения после \\nпередачи на вход модели вектора унитарного кодирования этого \\nслова.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 175, 'page_label': '176'}, page_content='176   Глава 10. Другие формы обучения\\nРис. 10.2. Модель скипграммы с размером окна 5 и слоем вложения с 300 узлами\\nМодели word2vec имеют большое количество параметров, поэтому для повыше -\\nния эффективности вычислений используются два метода: иерархический softmax \\n(эффективный способ вычисления softmax, заключающийся в представлении \\nвыходных данных softmax в виде листьев бинарного дерева) и отрицательная вы-\\nборка (идея которой состоит в обновлении в каждой итерации градиентного спуска \\nслучайной выборки из всех выходов). Знакомство с этими методами я оставляю \\nвам для самостоятельного изучения.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 176, 'page_label': '177'}, page_content='11 Заключение\\nУх ты, как быстро! Вы отлично поработали, если попали сюда и сумели понять \\nб\\ue088ольшую часть того, о чем рассказывалось в книге.\\nКнига получилась чуть больше, чем планировалось. В конце концов, если бы я хо-\\nтел ограничить эту книгу, например, ровно сотней страниц, то мог бы уменьшить \\nразмер шрифта, поля и межстрочный интервал или удалить раздел об алгоритме \\nUMAP и отправить вас к оригинальному источнику. Уверяю вас: вам едва ли по-\\nнравилось бы самостоятельно знакомиться с оригинальной статьей об UMAP! \\n(Шутка!)\\nЯ уверен, что вы получили все необходимое, чтобы стать отличным современным \\nаналитиком или специалистом по машинному обучению. Это не значит, что я ох-\\nватил все, что только можно, но то, что мне удалось описать, в других книгах рас-\\nтянуто на тысячи страниц. Многое из того, о чем я рассказал, вообще отсутствует \\nв книгах: типичные книги по машинному обучению консервативны и академичны, \\nя же сделал упор на алгоритмах и методах, которые пригодятся вам в повседневной \\nработе.\\nО чем бы я рассказал в книге по машинному обучению в тысячу страниц? \\n11.1. Что не было затронуто\\n11.1.1. Тематическое моделирование\\nВ текстовом анализе широко используется метод обучения без учителя, который \\nназывается тематическим моделированием. Представьте, что у вас есть коллекция'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 177, 'page_label': '178'}, page_content='178   Глава 11. Заключение\\nтекстовых документов и вам нужно определить тему каждого документа. Латентное \\nразмещение Дирихле (Latent Dirichlet Allocation, LDA) — очень эффективный \\nалгоритм определения темы. Вы сами решаете, сколько тем присутствует в кол-\\nлекции документов, а алгоритм назначает тему каждому слову в этой коллекции. \\nЗатем, чтобы определить тему документа, вы просто подсчитываете количество \\nслов в этом документе, соответствующих каждой теме.\\n11.1.2. Гауссовские процессы\\nГауссовские процессы (Gaussian Processes, GP)  — это метод обучения с  учите-\\nлем, конкурирующий с ядерной регрессией. Он имеет некоторые преимущества \\nперед последней. Например, поддерживает доверительные интервалы для линии \\nрегрессии в каждой точке. Я решил не объяснять этот метод, потому что не смог \\nпридумать простой способ объяснить его, но вам определенно стоит потратить \\nнекоторое время, чтобы познакомиться с гауссовскими процессами поближе. Это \\nне будет пустой тратой времени.\\n11.1.3. Обобщенные линейные модели\\nОбобщенная линейная модель (Generalized Linear Model, GLM) — это обобщение \\nлинейной регрессии для моделирования разного вида зависимостей между вход-\\nным вектором признаков и целью. Например, логистическая регрессия является \\nодной из форм GLM. Если вас интересует регрессия и вы ищете простые и объ-\\nяснимые модели, обязательно познакомьтесь с GLM поближе.\\n11.1.4. Вероятностные графические модели\\nЯ упомянул один пример вероятностных графических моделей  (Probabilistic \\nGraphical Models, PGM) в главе 7: условные случайные поля (Conditional Random \\nFields, CRF). С помощью CRF можно смоделировать входную последовательность \\nслов и отношения между признаками и метками в этой последовательности в виде \\nпоследовательного графа зависимостей. В общем случае PGM может быть любым \\nграфом. Граф — это структура, состоящая из набора узлов и ребер, соединяющих \\nпары узлов. Каждый узел в PGM представляет некоторую случайную переменную \\n(значения которой могут наблюдаться или не наблюдаться), а ребра представля-\\nют условную зависимость одной случайной переменной от другой. Например, \\nслучайная переменная «влажность тротуара» зависит от случайной переменной \\n«погодные условия». Наблюдая значения некоторых случайных переменных, алго-\\nритм оптимизации способен извлечь из данных зависимости между наблюдаемыми \\nи ненаблюдаемыми переменными.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 178, 'page_label': '179'}, page_content='11.1. Что не было затронуто   179\\nВероятностные графические модели позволяют аналитику увидеть, как значения \\nодного признака зависят от значений других признаков. Если ребра графа зависи-\\nмостей ориентированы, появляется возможность вывести причинно-следственную \\nсвязь. К сожалению, создание таких моделей вручную требует значительного опыта \\nв предметной области и глубокого понимания теории вероятностей и математи-\\nческой статистики. Последнее требование часто оказывается невыполнимым для \\nмногих экспертов в предметной области. Некоторые алгоритмы могут определять \\nструктуру зависимостей на основе данных, но полученные таким способом модели \\nчасто трудно поддаются интерпретации и поэтому они малополезны для понимания \\nсложных вероятностных процессов, которые генерируют данные. На сегодняшний \\nдень CRF является наиболее часто используемой вероятностно графической моде-\\nлью, применяемой в основном для обработки текста и изображений. Однако в этих \\nдвух областях этот метод уступил пальму первенства нейронным сетям. Другая \\nграфическая модель, скрытая марковская модель (Hidden Markov Model, HMM), \\nв прошлом часто использовалась в задачах распознавания речи, анализе временных \\nрядов и других задачах определения временн\\ue088ых зависимостей, но HMM точно так \\nже проиграла нейронным сетям.\\nЕсли вы все же решите узнать больше о PGM, то знайте, что они также известны под \\nназваниями байесовские сети, сети доверия и вероятностные сети независимости.\\n11.1.5. Методы Монте-Карло с цепями Маркова\\nЕсли при работе с графическими моделями возникает необходимость выбрать \\nданные из очень сложного распределения, определяемого графом зависимостей, \\nможно попробовать использовать алгоритмы  Монте\\xadКарло с цепями Маркова \\n(Markov Chain Monte Carlo, MCMC). MCMC — это целый класс алгоритмов для \\nвыборки из любого распределения вероятностей, определенного математически. \\nКогда мы говорили об автокодировщиках с шумоподавлением, мы отбирали шум \\nиз нормального распределения. Выборка из стандартных распределений, таких как \\nнормальное или равномерное, осуществляется относительно просто, потому что \\nих свойства хорошо известны. Однако задача выборки значительно усложняется, \\nкогда распределение вероятностей может иметь произвольную форму, определя-\\nемую сложной формулой.\\n11.1.6. Генеративно-состязательные сети\\nГенеративно-состязательные сети (Generative Adversarial Networks, GAN) — это \\nкласс нейронных сетей, использующих обучение без учителя. Они реализуются \\nкак система двух нейронных сетей, состязающихся друг с другом в условиях игры'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 179, 'page_label': '180'}, page_content='180   Глава 11. Заключение\\nс нулевой суммой. Самое популярное применение GAN — обучение созданию \\nфотографий, которые для людей-наблюдателей выглядят достоверно. Первая из \\nдвух сетей принимает случайный вход (обычно гауссовский шум) и учится гене-\\nрировать изображение в виде матрицы пикселов. Вторая сеть принимает на входе \\nдва изображения: одно «реальное», взятое из некоторой коллекции, и второе — \\nсгенерированное первой сетью. Она должна научиться распознавать, какое из двух \\nизображений сгенерировано первой сетью. Первая сеть получает отрицательные \\nпотери, если вторая распознала «поддельное» изображение.  \\nВторая сеть, в свою очередь, получает штраф, если не может распознать, какое из \\nдвух изображений является поддельным.\\n11.1.7. Генетические алгоритмы\\nГенетические алгоритмы  (Genetic Algorithms, GA) — это методика численной \\nоптимизации, используемая для оптимизации недифференцируемых целевых \\nфункций. В ней для поиска глобального оптимума (минимума или максимума) \\nиспользуются понятия эволюционной биологии и имитируются эволюционные \\nбиологические процессы.\\nПри использовании генетических алгоритмов сначала создается первоначальное \\nпоколение решений-кандидатов. Если мы хотим найти оптимальные значения па-\\nраметров модели, сначала случайным образом генерируется несколько комбинаций \\nтаких значений. Затем каждая комбинация проверяется по отношению к целевой \\nфункции. Представьте себе каждую комбинацию значений параметров как точку \\nв многомерном пространстве. Затем из предыдущего поколения генерируется \\nпоследующее поколение точек, с  применением таких понятий, как «селекция», \\n«пересечение» и «мутация».\\nВ итоге это приводит к тому, что в каждом новом поколении сохраняется боль -\\nше точек, схожих с теми, которые имелись в предыдущем поколении и которые \\nпоказали лучшие результаты по отношению к цели. Точки в новом поколении, \\nкоторые показали худшие результаты в предыдущем поколении, заменяются \\n«мутациями» и «пересечениями» точек, показавших лучшие результаты. Мута -\\nция точки получается случайным искажением некоторых атрибутов исходной \\nточки. Пересечение — это определенная комбинация нескольких точек (напри -\\nмер, среднее значение).\\nГенетические алгоритмы позволяют находить решения для любых измеримых \\nкритериев оптимизации. Например, GA можно использовать для оптимизации \\nгиперпараметров алгоритма обучения. Они обычно намного медленнее методов \\nоптимизации на основе градиента.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 180, 'page_label': '181'}, page_content='11.2. Благодарности   181\\n11.1.7. Обучение с подкреплением\\nКак уже говорилось, обучение с подкреплением (Reinforcement Learning, RL) ре-\\nшает очень специфическую задачу, когда решения принимаются последовательно. \\nОбычно агент действует в неизвестном окружении. Каждое действие приносит \\nвознаграждение и переносит агента в другое состояние окружения (обычно в ре-\\nзультате какого-то случайного процесса с неизвестными свойствами). Цель аген-\\nта — оптимизировать долгосрочное вознаграждение.\\nАлгоритмы обучения с подкреплением, такие как Q-обучение (Q-learning), а также \\nего аналоги на основе нейронной сети используются при обучении видеоиграм, \\nроботизированной навигации и координации, управлению запасами и цепочками \\nпоставок, оптимизации сложных электроэнергетических систем (электросетей) \\nи изучении финансовых торговых стратегий.\\nНа этом книга заканчивается. Не забывайте время от времени посещать вики-\\nстраницу книги, чтобы быть в курсе событий в областях машинного обучения, \\nрассмотренных в книге. Как я уже говорил в предисловии, благодаря постоянно \\nобновляемой вики-странице эта книга, как хорошее вино, со временем становится \\nтолько лучше.\\n11.2. Благодарности\\nВысокое качество этой книги было бы невозможно без редакторов-волонтеров. \\nЯ особенно благодарен следующим читателям за их систематический вклад: Мар-\\nтейну ван Аттекуму (Martijn van Attekum), Даниэлю Мараини (Daniel Maraini), \\nАли Азизу (Ali Aziz), Рэйчел Мак (Rachel Mak), Кельвину Сундли (Kelvin Sundli) \\nи Джону Робинсону (John Robinson).\\nТакже я очень благодарен за помощь: Кнуту Свердрупу (Knut Sverdrup), Фредди \\nДреннану (Freddy Drennan), Карлу У. Хэндлину (Carl W. Handlin), Абхиджиту \\nКумару (Abhijit Kumar), Лаззе Веддбарду (Lazze Veddbärd), Рикардо Рейсу (Ricardo \\nReis), Даниэлю Гроссу (Daniel Gross), Иогану Фаузи (Johann Faouzi), Акашу Агра-\\nвалу (Akash Agrawal), Натанаэлю Вайлю (Nathanael Weill), Филипу Джекичу (Filip \\nJekic), Абишеку Бабуджи (Abhishek Babuji), Луану Виейре (Luan Vieira), Саяку \\nПолу (Sayak Paul), Вахейду У оллетсу (Vaheid Wallets), Лоренцо Буффони (Lorenzo \\nBuffoni), Эли Фридман (Eli Friedman), Лукашу Мёдри ( Łukasz Madry), Хаолану \\nЦиню (Haolan Qin), Бибеку Бехере (Bibek Behera), Дженнифер Купер (Jennifer \\nCooper), Нишанту Тяги (Nishant Tyagi), Денису Ахиярову (Denis Akhiyarov), Арону \\nДжанарву (Aron Janarv), Александру Овчаренко, Рикардо Риосу (Ricardo Rios), \\nМайклу Муллену (Michael Mullen), Мэтью Эдвардсу (Matthew Edwards), Дэвиду'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 181, 'page_label': '182'}, page_content='182   Глава 11. Заключение\\nЭтлину (David Etlin), Манодж Баладжи Дж. (Manoj Balaji J), Давиду Руа (David \\nRoy), Луису Феликсу (Luiz Felix), Ананду Мохану (Anand Mohan), Хади Сотуде \\n(Hadi Sotudeh), Чарли Ньюи (Charlie Newey), Замиру Акимбекову, Хесусу Ренеро \\n(Jesus Renero), Карану Гадия (Karan Gadiya), Мустафе Анил Дербенту (Mustafa \\nAnıl Derbent), Джейкью Веенстра (JQ Veenstra), Жолту Крезису (Zsolt Kreisz), \\nЯну Келли (Ian Kelly), Лукашу Заваде (Lukasz Zawada), Роберту Уэрхэму (Robert \\nWareham), Томасу Босману (Thomas Bosman), Льву Стивену (Lv Steven), Ариэлю \\nРоссаниго (Ariel Rossanigo), Майклу Лумпкинсу (Michael Lumpkins), Сесил Созуер \\n(Secil Sozuer), Борису Куамбо (Boris Kouambo), И Джеону (Yi Jayeon), Тиму Фло-\\nку (Tim Flocke), Мохамеду Бехери (Mohamed Behery), Ане Фотине (Ana Fotina), \\nСамину Иштяку (Samin Ishtiaq), Алексею Шматову, Кристиану Йеншу (Christian \\nJaensch) и Лучано Сегуре (Luciano Segura).'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 182, 'page_label': '183'}, page_content='Алфавитный указатель\\nA\\nAdam  66\\nI\\nID3  50\\nK\\nkNN  113\\nL\\nL1-регуляризация  81\\nL2-регуляризация  81\\nLambdaMART  168\\nR\\nReLU  95\\nRMSprop  66\\nRNN\\nпреобразование последовательностей \\nв последовательности  109\\nс механизмом внимания  109\\nS\\nSkip-gram  174\\nSVM  113\\nс жестким зазором  55\\nс мягким зазором  55\\nT\\nTanH  95\\nt-SHE  162\\nU\\nUMAP  162\\nW\\nWord2vec  174\\nА\\nАвтокодировщик  129, 160\\nАвтокодировщик с шумоподавлением  \\n130, 171, 179\\nАктивное обучение  126\\nАлгоритм\\nГаусса  113\\nмаксимизации ожидания  157\\nМонте-Карло с цепями Маркова  179\\nАлгоритм обучения  19, 22\\nбез учителя  19\\nклассификации  39\\nрегрессии  40\\nслабый  118\\nс учителем  19\\nАномалия  25\\nАприорная вероятность  38\\nАрхитектура полносвязанная  93'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 183, 'page_label': '184'}, page_content='184   Алфавитный указатель\\nБ\\nБайесовская оптимизация гиперпара-\\nмет ров  89\\nБалл членства  155\\nБинарная перекрестная энтропия  117\\nБинарная функция потерь  44\\nБиннинг  71\\nБольшинство голосов  138\\nБольшое смещение  78\\nБустинг  118\\nБэггинг  118\\nВ\\nВектор  27\\nпризнака  18, 69\\nВентильный RNN  108\\nВентильный рекуррентный узел  108\\nВзрывной рост градиента  95\\nВложение входных данных  124\\nВложения  174\\nслов  133, 139\\nВложенная функция  91\\nВознаграждение  20\\nВыборка  37\\nс заменой  119\\nВыборочное среднее  37\\nВысокая дисперсия  79\\nВыявление аномалий  19\\nГ\\nГауссовские процессы  178\\nГенератор  146\\nГенетический алгоритм  180\\nГлобальный минимум  32\\nГрадиент  34\\nГрадиентный бустинг  75, 120\\nГрадиентный спуск  46, 49, 59\\nГраница принятия решения  22\\nГраф  49, 178\\nГребневая регуляризация  82\\nД\\nДействие  20\\nДекодировщик  124\\nДилемма смещения-дисперсии  81\\nДискретная величина  34\\nслучайная  34\\nДисперсия  120\\nДифференцирование  33\\nДолгая краткосрочная  108\\nДоля\\nистинно положительного результата  \\n87\\nложноположительного результата  87\\nДополнение  101\\nЕ\\nЕвклидово расстояние  57, 165\\nЗ\\nЗазор  23\\nЗатухание градиента  95\\nИ\\nИзвлечение именнованных сущностей  \\n123\\nИзмерение  27\\nИнкрементальный алгоритм обучения  \\n75\\nИнтервал  32\\nИнформативный признак  70\\nК\\nКвадратичная функция потерь  44\\nКласс  19, 40'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 184, 'page_label': '185'}, page_content='Алфавитный указатель   185\\nКлассификация  39\\nбинарная  40\\nмногоклассовая  40\\nмультиномиальная  40\\nодноклассовая  113\\nс многими метками  116\\nс несколькими классами  40\\nунарная  113\\nКластеризация  149\\nk средних  150\\nжесткая  155\\nиерархическая  159\\nспектральная  159\\nКодировщик  124\\nКонтрольный набор  76\\nКосинусное сходство  58, 165\\nКусочно-линейная функция потерь  54\\nЛ\\nЛассо  82\\nЛатентное размещение Дирихле  178\\nЛестничная сеть  129, 130\\nЛиния поведения  20\\nЛогарифм правдоподобия  49\\nЛогистический сигмоид  47\\nЛокальный минимум  32\\nМ\\nМаксимальное правдоподобие  48, 114, \\n157\\nМаксимум апостериорной вероятности  \\n39\\nМалое смещение  70\\nМаркировка последовательностей  123\\nМатрица  28\\nМатрица ошибок  83\\nМетамодели  118\\nМетка  19, 39\\nМетод\\nk ближайших соседей  57\\nадаптивного градиента  66\\nадаптивной синтетической выборки  \\n137\\nглавных компонент  160\\n«локтя»  155\\nмножителей Лагранжа  56\\nмоментов  66\\nна основе градиента  89\\nопорных векторов  22\\nрасширения выборки меньшинства \\nсинтетическими образцами  137\\nсреднего силуэта  155\\nунитарного кодирования  174\\nфакторизации  171\\nэволюционной оптимизации  89\\nМеханизм внимания  125\\nМешок слов  21\\nМинимальный вентильный узел  108\\nМини-пакетный стохастический гради-\\nентный спуск  65\\nМногослойный перцептрон  92\\nМножество  29\\nМоделирование класса  113\\nМодель  19, 22, 23, 40\\nансамблевая  119\\nвероятностная графическая  178\\nнепараметрическая  50, 147\\nобобщенная линейная  178\\nпараметрическая  50, 147\\nразреженная  81\\nрегуляризации эластичных сетей  82\\nскрытая марковская  179\\nсмеси гауссовых распределений  155\\nсредних  82\\nстатистическая  23'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 185, 'page_label': '186'}, page_content='186   Алфавитный указатель\\nН\\nНабор данных  18, 22, 37, 69\\nНедообученность  78\\nНейронная сеть  41, 75\\nглубокая  41\\nклассическая  92\\nостаточная  96\\nпрямого распространения  92\\nрекуррентная  105\\nрекурсивная  109\\nсверточная  97\\nсиамская  131\\nНепрерывная величина  34\\nслучайная  36\\nНеразмеченный образец  19, 39\\nНесмещенная оценка  37\\nНечеткое множество  162\\nНормализация  71\\nz-оценки  72\\nНормальный гауссов шум  130\\nО\\nОбласть значений  32\\nОбласть определения  31\\nОбнаружение аномалий  164\\nОбобщение  23\\nО большое  144, 145\\nОбразец  37\\nОбратное распространение  96\\nОбратное распространение во времени  \\n107\\nОбучение  23\\nансамбля  118\\nбез подготовки  133\\nбез учителя  19\\nпреобразованию последовательно-\\nстей в последовательности  124\\nс первого раза  131, 167\\nс подкреплением  20\\nс учителем  18\\nОбъединение  29\\nОграничение градиента  95\\nОдин против всех  112\\nОдноклассовая версия алгоритма Гаусса  \\n113\\nОжидаемое значение  36\\nОжидаемое среднее вознаграждение  20\\nОжидание  36\\nОстаток  120\\nОтбор признаков  82\\nОтложенная выборка  76\\nОценка плотности  147\\nП\\nПакетная нормализация  82, 140\\nПараметр  22, 40\\nПерекрестная проверка  90, 148\\nПеренос обучения  143\\nПереобучение  45, 79, 120\\nПересечение  29\\nПодвыборки  103\\nПоиск по сетке  88\\nПолнота  84, 87\\nПопарный подход  167\\nПоточечный подход  167\\nПравдоподобие  48\\nПравило Байеса  38, 157\\nПравило дифференцирования сложной \\nфункции  33\\nПравильность  85\\nс учетом цены  87\\nПризнак  18, 69\\nПрогнозирующая сила  152\\nПрогнозирующая способность  70'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 186, 'page_label': '187'}, page_content='Алфавитный указатель   187\\nПроектирование признака  69\\nПроекция многообразия  160\\nПроизводная  33\\nПрореживание  82, 140\\nР\\nРавномерная аппроксимация  160\\nРазмеченные данные  39\\nРазмеченный образец  18, 69\\nРанняя остановка  82, 140\\nРаспределение вероятности  35\\nРасширение данных  82, 141\\nРегрессия  40\\nРегуляризация  80\\nРезультат\\nистинно отрицательный  84\\nистинно положительный  84\\nложноотрицательный  84\\nложноположительный  84\\nС\\nСамообучение  128\\nс учителем  175\\nСвертка  98\\nСиамские сети  167\\nСкаляр  27\\nСкалярное произведение  30\\nСкользящее окно  97\\nСлой  41, 91, 92\\nполносвязанный  93\\nскрытый  96\\nузкого горлышка  160\\nСлучайная величина  34\\nСлучайный лес  119\\nСлучайный поиск  89\\nСмещение  78\\nСовместная фильтрация  170\\nСоединение с пропуском слоя  96\\nСокращение выборки  137\\nСостояние  20, 105\\nСписочный подход  167\\nСреднее значение  36\\nСреднеквадратичная ошибка  48\\nСредний накопленный квадрат ошибки  \\n148\\nСредняя точность  169\\nСтандартизация  72\\nСтандартная логистическая функция   \\n47\\nСтандартное отклонение  36\\nСтатистика разрывов  155\\nСтатистическая характеристика  36\\nСтатистическая характеристика выбор-\\nки  37\\nСтохастический градиентный спуск  59\\nТ\\nТеорема Байеса  38\\nТом  99\\nТочность  25, 84, 168\\nТранспонирование  31\\nТриплетная потеря  131, 167\\nУ\\nУвеличения выборки  137\\nУзел  92\\nУменьшение размерности  19\\nУ словные случайные поля  123\\nУ среднение  138\\nУ средненная средняя точность  168\\nФ\\nФактор  173\\nФильтрация контента  170'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 187, 'page_label': '188'}, page_content='188   Алфавитный указатель\\nФункция\\nsoftmax  107, 112\\nактивации  91\\nплотности вероятности  36\\nпотерь  44\\nраспределения дискретной случай-\\nной величины  35\\nстоимости  44\\nстрого возрастающая  49\\nядра  56\\nЦ\\nЦелевое значение  40\\nЦентроид  150\\nЧ\\nЧастная производная  34\\nЧисловое переполнение  72\\nШ\\nШаг  101\\nШтабелирование  138\\nЭ\\nЭмпирический риск  44\\nЭнтропия  51\\nЭпоха  62\\nЯ\\nЯдерный трюк  55\\nЯдро  24, 56, 110\\nЯдро RBF  57'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 188, 'page_label': '189'}, page_content='Андрей Бурков\\nМашинное\\tобучение\\tбез\\tлишних\\tслов\\nПеревел с английского А. Киселев\\n Заведующая редакцией Ю. Сергиенко\\n Ведущий редактор К. Тульцева\\n Литературный редактор А. Руденко\\n Художественный редактор В. Мостипан\\n Корректоры С. Беляева, М. Молчанова\\n Верстка Л. Егорова\\nИзготовлено в России. Изготовитель: ООО «Прогресс книга». \\nМесто нахождения и фактический адрес: 194044, Россия, г. Санкт-Петербург, \\nБ. Сампсониевский пр., д. 29А, пом. 52. Тел.: +78127037373.\\nДата изготовления: 02.2020. Наименование: книжная продукция. Срок годности: не ограничен.\\nНалоговая льгота — общероссийский классификатор продукции ОК 034-2014, 58.11.12 — Книги печатные  \\nпрофессиональные, технические и научные.\\nИмпортер в Беларусь: ООО «ПИТЕР М», 220020, РБ, г. Минск, ул. Тимирязева, д. 121/3, к. 214, тел./факс: 208 80 01.\\nПодписано в печать 23.01.20. Формат 70×100/16. Бумага офсетная. У сл. п. л. 15,480. Тираж 1700. Заказ 0000.'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 189, 'page_label': '190'}, page_content=''),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 190, 'page_label': '191'}, page_content=''),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2020-01-27T12:04:11+03:00', 'moddate': '2020-03-18T12:39:28+03:00', 'trapped': '/False', 'source': 'data\\\\book3.pdf', 'total_pages': 192, 'page': 191, 'page_label': '192'}, page_content='')]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f09feb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c8c89645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "def filter_to_minimal_docs(documents: List[Document]) -> List[Document]:\n",
    "    minimal_docs: List[Document] = []\n",
    "    for doc in documents:\n",
    "        src = doc.metadata.get(\"source\")\n",
    "        minimal_docs.append(\n",
    "            Document(page_content=doc.page_content, metadata={\"source\": src})\n",
    "        )\n",
    "    return minimal_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1f77d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_docs = filter_to_minimal_docs(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2702eaef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(minimal_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "368aff08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\book3.pdf'}, page_content=''),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='Andriy Burkov\\nThe Hundred-Page Machine Learning Book'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='МАШ ИННОЕ ОБУЧЕНИЕ \\nАндрей Бурков\\nбез лишних слов\\n2020'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='ББК 32.813\\nУДК 004.8\\nБ91 \\n\\t Бурков\\tАндрей\\nБ91   Машинное обучение без лишних слов. — СПб.: Питер, 2020. — 192 с.: ил. — (Се-\\nрия «Библиотека программиста»).\\n ISBN 978-5-4461-1560-0\\nВсе, что вам действительно нужно знать о машинном обучении, может уместиться на паре сотен \\nстраниц.\\nНачнем с простой истины: машины не учатся. Типичное машинное обучение заключается в по-\\nиске математической формулы, которая при применении к набору входных данных (называемых \\nобучающими данными) даст желаемые результаты.\\nАндрей Бурков постарался дать все необходимое, чтобы каждый мог стать отличным совре -\\nменным аналитиком или специалистом по машинному обучению. То, что удалось вместить в пару \\nсотен страниц, в других книгах растянуто на тысячи. Типичные книги по машинному обучению \\nконсервативны и академичны, здесь же упор сделан на алгоритмах и методах, которые пригодятся \\nв повседневной работе.\\n16+ (В соответствии с Федеральным законом от 29 декабря 2010 г. № 436-ФЗ.)\\n ББК 32.813\\n УДК 004.8\\nПрава на издание получены по соглашению с Andriy Burkov. Все права защищены. Никакая часть данной книги \\nне может быть воспроизведена в какой бы то ни было форме без письменного разрешения владельцев автор -\\nских прав.\\nИнформация, содержащаяся в данной книге, получена из источников, рассматриваемых издательством как на-\\nдежные. Тем не менее, имея в виду возможные человеческие или технические ошибки, издательство не может \\nгарантировать абсолютную точность и полноту приводимых сведений и не несет ответственности за возможные \\nошибки, связанные с использованием книги. Издательство не несет ответственности за доступность матери -\\nалов, ссылки на которые вы можете найти в этой книге. На момент подготовки книги к изданию все ссылки на \\nинтернет-ресурсы были действующими.\\nISBN 978-1999579500 англ. © Andriy Burkov, 2019\\nISBN 978-5-4461-1560-0 © Перевод на русский язык ООО Издательство «Питер», 2020\\n ©  Издание на русском языке, оформление ООО Издательство «Питер», \\n2020\\n © Серия «Библиотека программиста», 2020'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='Оглавление\\nПредисловие к русскому изданию ....................................................................10\\nПредисловие из оригинального издания ..........................................................13\\nВступление .............................................................................................................15\\nКому адресована эта книга ...................................................................................16\\nОт издательства ...................................................................................................17\\nГлава 1. Введение ....................................................................................................18\\n1.1. Что такое машинное обучение ....................................................................... 18\\n1.2. Типы обучения .............................................................................................. 18\\n1.3. Как работает обучение с учителем ................................................................20\\n1.4. Почему модель способна работать с новыми данными ...................................25\\nГлава 2. Обозначения и определения ....................................................................... 27\\n2.1. Обозначения ..................................................................................................27\\n2.2. Случайная величина ......................................................................................34\\n2.3. Несмещенные оценки .................................................................................... 37\\n2.4. Правило Байеса ............................................................................................. 37\\n2.5. Оценка параметров ........................................................................................ 38\\n2.6. Параметры и гиперпараметры ....................................................................... 39\\n2.7. Классификация и регрессия ...........................................................................39\\n2.8. Обучение на основе моделей и на основе примеров ...................................... 40\\n2.9. Поверхностное и глубокое обучение ..............................................................41\\nГлава 3. Фундаментальные алгоритмы .....................................................................42\\n3.1. Линейная регрессия ....................................................................................... 42\\n3.2. Логистическая регрессия ............................................................................... 46\\n3.3. Обучение дерева решений ............................................................................. 49'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='6   Оглавление\\n3.4. Метод опорных векторов ............................................................................... 53\\n3.5. Метод k ближайших соседей ..........................................................................57\\nГлава 4. Анатомия алгоритмов обучения ..................................................................59\\n4.1. Строительные блоки алгоритмов обучения .................................................... 59\\n4.2. Градиентный спуск ........................................................................................ 60\\n4.3. Как работают инженеры, занимающиеся машинным обучением .....................66\\n4.4. Особенности алгоритмов обучения ................................................................ 67\\nГлава 5. Практические основы ................................................................................. 69\\n5.1. Проектирование признаков ............................................................................ 69\\n5.2. Выбор алгоритма обучения ............................................................................ 74\\n5.3. Три набора .................................................................................................... 76\\n5.4. Недообучение и переобучение ....................................................................... 78\\n5.5. Регуляризация ...............................................................................................81\\n5.6. Оценка эффективности модели ......................................................................82\\n5.7. Настройка гиперпараметров ...........................................................................88\\nГлава 6. Нейронные сети и глубокое обучение .........................................................91\\n6.1. Нейронные сети ............................................................................................. 91\\n6.2. Глубокое обучение ........................................................................................ 95\\nГлава 7. Проблемы и решения ................................................................................ 110\\n7.1. Ядерная регрессия .......................................................................................110\\n7.2. Многоклассовая классификация ...................................................................112\\n7.3. Одноклассовая классификация .................................................................... 113\\n7.4. Классификация с многими метками .............................................................. 116\\n7.5. Обучение ансамбля ......................................................................................118\\n7.6. Обучение маркировке последовательностей ................................................123\\n7.7. Обучение преобразованию последовательностей в последовательности ......124\\n7.8. Активное обучение....................................................................................... 126\\n7.9. Обучение с частичным привлечением учителя ............................................. 128\\n7.10. Обучение с первого раза ............................................................................ 131\\n7.11. Обучение без подготовки ........................................................................... 133'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='Оглавление   7\\nГлава 8. Продвинутые методики ............................................................................. 135\\n8.1. Работа с несбалансированными наборами данных .......................................135\\n8.2. Объединение моделей ................................................................................. 137\\n8.3. Обучение нейронных сетей ..........................................................................139\\n8.4. Продвинутая регуляризация ........................................................................ 140\\n8.5. Обработка нескольких входов ...................................................................... 141\\n8.6. Обработка нескольких выходов ................................................................... 142\\n8.7. Перенос обучения ........................................................................................143\\n8.8. Эффективность алгоритмов ......................................................................... 144\\nГлава 9. Обучение без учителя .............................................................................. 147\\n9.1. Оценка плотности ........................................................................................147\\n9.2. Кластеризация ............................................................................................. 149\\n9.3. Сокращение размерности ............................................................................. 159\\n9.4. Обнаружение аномалий ............................................................................... 164\\nГлава 10. Другие формы обучения ......................................................................... 165\\n10.1. Определение метрик ..................................................................................165\\n10.2. Определение ранга ....................................................................................167\\n10.3. Обучение делать рекомендации ................................................................. 170\\n10.4. Самообучение с учителем: вложения слов .................................................174\\nГлава 11. Заключение ............................................................................................ 177\\n11.1. Что не было затронуто ...............................................................................177\\n11.2. Благодарности ...........................................................................................181\\nАлфавитный указатель ....................................................................................... 183'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='Моим родителям Татьяне и Валерию и моей семье:  \\nдочерям Катрин и Еве и брату Дмитрию'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='Все модели ошибочны, но некоторые \\n полезны.\\nДжордж Бокс\\nПисьмо это вышло более длинным \\nтолько потому, что мне некогда было \\nнаписать его короче.\\nБлез Паскаль'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='Предисловие \\nк русскому изданию\\nМашинное обучение, наверное, самая горячая и быстроразвивающаяся дисци -\\nплина в современной информатике, если не в современной науке вообще. Каж -\\nдый день появляются новые модели и выходят новые статьи, раз в пару месяцев \\nпроисходит очередной прорыв, который попадает в новости и открывает новые \\nвозможности, а раз в год-два происходит переворот в целой отрасли. Вот уже \\nдесять лет, после революции глубокого обучения, мы живем на новой (третьей) \\nволне хайпа искусственного интеллекта, и пока ничто не предвещает, что она \\nскоро закончится.\\nНеудивительно, что сейчас машинное обучение привлекает множество людей, \\nкоторые никогда раньше им не занимались. Кто-то узнал о заработках в инду -\\nстрии и хочет «разрабатывать искусственный интеллект за 300 К/сек», кто-то \\nхочет узнать, не пора ли «перевести свой бизнес с big data на machine learning», \\nа кто-то приходит в AI с глубокими идеями о том, как сделать этичным общий \\nискусственный интеллект, который не поработит и не убьет людей, а будет по -\\nмогать им (в целом это вполне серьезный разговор, но любому профессионалу \\nочевидно, что до практики или содержательных исследований этого еще очень, \\nочень, очень далеко).\\nПоэтому в наше время действительно очень полезно иметь краткое введение \\nв машинное обучение, на которое всегда можно давать ссылку и после которого \\nможно быть уверенным, что человек говорит на одном с тобой языке. Попытку \\nдать именно такое введение я вижу в этой книге, и мне кажется, что эта попытка \\nполучилась очень удачной. Книга действительно представляет читателю широкий \\nспектр основных понятий и методов машинного обучения, которые здесь изложены \\nкорректно, хоть и по понятным причинам очень кратко. Но если освоить эту книгу, \\nдальше самообразование может пойти куда проще и быстрее, ведь вы уже сможете \\nчитать более специальные источники. Кроме того, вам будет куда понятнее, что \\nименно делает код библиотек машинного обучения — для специалиста в этом не \\nдолжно оставаться никакой магии.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='Предисловие к русскому изданию   11\\nНе стоит обольщаться: царского пути нет ни в геометрии, ни в машинном обу-\\nчении, ни вообще где бы то ни было. На свете нет и не может быть волшебного \\nспособа «обучиться разрабатывать искусственный интеллект за 30 дней без sms и \\nрегистрации». И эта книга тоже, конечно, такого способа не дает. С одной стороны, \\nвам потребуется некоторая математическая квалификация, чтобы понять изло -\\nженное здесь (хотя глава 2 начинается буквально с того, что такое «множество», \\nее, конечно, следует рассматривать скорее как напоминание для тех, кто когда-то \\nэто уже изучал). С другой стороны, эта книга — только самое начало пути в ин -\\nтересный и разнообразный мир машинного обучения; прочитав ее, вы не станете \\nпрофессионалом — вы сделаете первый маленький шаг.\\nНо если книгу прочитать вдумчиво и действительно освоить то, о чем здесь го -\\nворится, этот шаг может превратиться в большой скачок. Чего я и желаю всем \\nчитателям: разбирайтесь, познавайте, интересуйтесь новым и не бойтесь труд -\\nностей. Удачи!\\nСергей Николенко, \\nавтор книги «Глубокое обучение. Погружение в мир нейронных сетей»,  \\nсотрудник лаборатории математической логики Санкт-Петербургского  \\nотделения Математического института РАН,  \\nдиректор по научным исследованиям (Chief Research Officer)  \\nплатформы Neuromation'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='Отличное введение в машинное обучение от специалиста мирового уровня.\\nКаролис Урбонас (Karolis Urbonas),  \\nруководитель отдела анализа данных в Amazon\\nХотела бы я встретить такую книгу, когда обучалась статистике в аспирантуре \\nи пыталась освоить машинное обучение.\\nЧао Хан (Chao Han),  \\nвице-президент, руководитель исследований и разработок в Lucidworks\\nКнига Андрея, фантастическим образом устраняя все лишнее, идет на полной \\nскорости прямо к цели с самой первой страницы.\\nСуджит Варахеди (Sujeet Varakhedi),  \\nтехнический руководитель в eBay\\nПрекрасная книга для инженеров, желающих начать использовать машинное обу-\\nчение в своей повседневной работе и не затратить на это слишком много времени.\\nДипак Агарвал (Deepak Agarwal),  \\nвице-президент по развитию искусственного интеллекта в LinkedIn'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='Предисловие \\nиз оригинального издания\\nВ последние двадцать лет мы наблюдаем взрывной рост объемов доступных данных \\nи, как следствие, интереса к статистическим приложениям и машинному обучению. \\nПоследствия оказались далекоидущими. Десять лет назад, когда я смог привлечь \\nполный класс студентов MBA к изучению моего нового факультативного курса по \\nстатистике, коллеги были удивлены, потому что наш факультет не мог добиться \\nтакого результата для большинства факультативов. Сегодня мы предлагаем курс \\nмагистратуры по бизнес-аналитике, который является крупнейшей специализиро-\\nванной магистерской программой в университете и по популярности конкурирует \\nс нашими программами MBA. Количество предлагаемых нами курсов значительно \\nвозросло, однако наши студенты все еще жалуются на нехватку мест. Наш опыт \\nне уникален, поскольку программы по науке о данных и машинному обучению \\nразвиваются с необычайной скоростью, так как спрос на специалистов в этой об-\\nласти непрерывно растет.\\nТакая популярность обусловлена простым, но неоспоримым фактом. Развитие \\nмашинного обучения привело к новым открытиям во многих областях, таких как \\nсоциальные науки, бизнес, биология и медицина, и это далеко не полный список. \\nВ результате возник огромный спрос на людей с определенным набором навыков. \\nТем не менее обучение студентов этим навыкам оказалось сложной задачей, потому \\nчто большая часть ранней литературы по этим методам была нацелена на людей, \\nзанимающихся академическими исследованиями, и сосредоточена на статистиче-\\nских и теоретических свойствах алгоритмов обучения или полученных моделей. \\nПочти полностью отсутствовали материалы, ориентированные на исследователей \\nи практиков, нуждавшихся в помощи при реализации определенного метода для \\nрешения практических задач. Таким людям важнее знать и понимать спектр мето-\\nдов, применимых к каждой задаче, их сильные и слабые стороны и лежащие в их \\nоснове предположения, а теоретические свойства или подробная информация об \\nалгоритмах подбора имеют для них второстепенное значение. Работая над книгой \\n«An Introduction to Statistical Learning with R» 1 (ISLR), мы преследовали цель \\n1 Джеймс Г., Уиттон Д., Хасти Т., Тибширани Р. Введение в статистическое обучение с при-\\nмерами на языке R. ДМК-Пресс, 2016. — Примеч. пер.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='14   Предисловие из оригинального издания\\nсоздать источник информации для такой группы людей. Энтузиазм, с которым \\nбыла встречена эта книга, демонстрирует спрос, существующий в обществе.\\nКнига «Машинное обучение без лишних слов» следует аналогичной парадигме. \\nТак же как в ISLR, в ней отсутствуют теоретические выводы, и основное внима-\\nние уделяется описанию ключевых деталей реализации различных подходов. \\nЭто компактное руководство «как анализировать данные», и я убежден, что оно \\nстанет ценным источником информации для научных сотрудников и практиков. \\nКнига достаточно коротка, чтобы ее можно было прочитать за один присест. Тем \\nне менее, несмотря на небольшой объем, она охватывает все основные подходы \\nмашинного обучения, от классической линейной и логистической регрессии до со-\\nвременного метода опорных векторов, глубокого обучения, бустинга и случайных \\nлесов. При этом описание различных подходов не страдает от недостатка деталей, \\nи заинтересованный читатель сможет получить дополнительную информацию \\nо любом конкретном методе в «Википедии». Книга не предполагает наличия ма-\\nтематической или статистической подготовки высокого уровня или даже опыта \\nпрограммирования, поэтому доступна почти каждому, кто решит потратить время \\nна изучение этих методов. С другой стороны, эту книгу обязательно должны про-\\nчитать все начинающие обучение в этой области, и она послужит им полезным \\nсправочником в будущем. Наконец, книга иллюстрирует некоторые алгоритмы, \\nиспользуя код на Python, одном из самых популярных языков программирования \\nдля машинного обучения. Я настоятельно рекомендую книгу «Машинное обучение \\nбез лишних слов» как для начинающих, желающих узнать больше о машинном \\nобучении, так и для опытных практиков, стремящихся расширить свой кругозор.\\nГарет Джеймс (Gareth James),  \\nпрофессор в области теории и методов анализа данных в Южно-Калифорний-\\nском университете, соавтор (вместе с Уиттоном, Хасти и Тибширани) книги-\\nбестселлера «An Introduction to Statistical Learning, with Applications in R»'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='Вступление\\nНачнем с простой истины: машины не учатся. Типичное машинное обучение за -\\nключается в поиске математической формулы, которая при применении к набору \\nвходных данных (называемых обучающими данными) дает желаемые результаты. \\nЭта математическая формула также генерирует правильные выходные данные для \\nбольшинства других входных данных (отличных от обучающих) при условии, что \\nэти входные данные поступают из того же или подобного статистического распре-\\nделения, из которого были получены обучающие данные.\\nПочему это не является обучением? Потому что стоит слегка исказить входные \\nданные, и результат, скорее всего, получится полностью неправильным. Обучение \\nу животных — это нечто иное. Если вы научились играть в видеоигру при прямой \\nориентации экрана, вы все равно сможете играть в  нее, даже если кто-то слегка \\nповернет экран. Алгоритм машинного обучения, обучавшийся при прямой ори -\\nентации экрана и не обученный распознаванию поворота, не сможет играть в игру \\nна повернутом экране.\\nНо почему тогда используется название «машинное обучение»? Причина, как это \\nчасто бывает, заключается в маркетинге: Артур Сэмюэл (Arthur Samuel), американ-\\nский пионер в области компьютерных игр и искусственного интеллекта, придумал \\nэтот термин в 1959 году, когда работал в IBM. Подобно тому как в 2010-х годах IBM \\nпыталась продвигать термин «когнитивные вычисления», чтобы выделиться среди \\nконкурентов, в 1960-х годах IBM использовала новый крутой термин «машинное \\nобучение», чтобы привлечь клиентов и талантливых сотрудников.\\nКак видите, подобно тому как искусственный интеллект не является интеллектом, \\nмашинное обучение тоже не является обучением. Тем не менее термин «машинное \\nобучение» получил широкое распространение и под ним часто подразумевается \\nтеория и практика создания машин, способных выполнять различные полезные \\nдействия без явного программирования. Слово «обучение» в данном случае ис-\\nпользуется лишь как аналогия с обучением в животном мире, а не буквально.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='16    Вступление\\nКому адресована эта книга\\nЭта книга содержит только те сведения о машинном обучении, которые появились \\nпосле 1960-х годов и доказали свою практическую ценность. Новичок в машинном \\nобучении найдет в этой книге достаточно подробностей, чтобы обеспечить себе \\nтакой уровень понимания, который позволит начать задавать правильные вопросы.\\nПрактики с опытом могут использовать эту книгу как набор рекомендаций для \\nдальнейшего самосовершенствования. Книга также пригодится при мозговом \\nштурме в начале проекта, когда требуется ответить на вопрос, является ли данная \\nтехническая или бизнес-задача «машинно-обучаемой», и, если да, какие методы \\nспособны помочь решить ее.\\nКак пользоваться этой книгой\\nЕсли вы собираетесь приступить к изучению темы машинного обучения, жела -\\nтельно, чтобы вы прочитали эту книгу от начала и до конца. (Здесь всего чуть \\nбольше ста страниц, и вы без труда одолеете их.) Если вас заинтересует какая-то \\nконкретная тема из описываемых в книге и вы захотите узнать больше, в большин-\\nстве разделов вы найдете QR-код.\\nОтсканировав такой QR-код с помощью телефона, вы получите ссылку на страни-\\nцу в сопутствующем вики-справочнике книги на сайте theMLbook.com, где найдете \\nрекомендуемые материалы для чтения, видеоролики, вопросы и ответы, фрагменты \\nкода, учебные пособия и многое другое. Вики-справочник постоянно пополняется \\nпубликациями самого автора книги, а также добровольцев со всего мира, то есть \\nэта книга, как хорошее вино, со временем становится только лучше.\\nОтсканируйте QR-код слева, чтобы попасть в вики-справочник \\nдля книги. В некоторых разделах нет QR-кода, но для многих из \\nних тоже есть страницы в вики. Вы сможете найти их, выполнив \\nпоиск по названию раздела в поисковой системе вики. \\nТеперь устраивайтесь поудобнее. Приятного чтения!\\nАндрей Бурков\\nQR-код \\nс адресом \\nстатьи в вики'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='От издательства   17\\nОт издательства\\nВаши замечания, предложения, вопросы отправляйте по адресу comp@piter.com \\n(издательство «Питер», компьютерная редакция). \\nМы будем рады узнать ваше мнение! \\nНа веб-сайте издательства www.piter.com вы найдете подробную информацию о на-\\nших книгах.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='1 Введение\\n1.1. Что такое машинное обучение\\nМашинное обучение — это раздел информатики, посвященный созданию алгорит-\\nмов, опирающихся на набор данных о каком-либо явлении. Эти данные могут быть \\nполучены из естественной среды, созданы вручную или сгенерированы другим \\nалгоритмом. \\nМашинное обучение также можно определить как процесс решения практической \\nзадачи путем 1) формирования набора данных и 2) алгоритмического построения \\nстатистической модели на его основе. Предполагается, что эта статистическая мо-\\nдель будет каким-то образом использоваться для решения практической задачи.\\nЧтобы сэкономить на нажатиях клавиш, я буду использовать термины «обучение» \\nи «машинное обучение» как взаимозаменяемые.\\n1.2. Типы обучения\\nОбучение может быть с учителем, без учителя и с подкреплением.\\n1.2.1. Обучение с учителем\\nВ обучении с учителем набор данных организован как коллекция размеченных \\nобразцов \\n . Каждый элемент xi из N называется вектором признаков. \\nВектор признаков — это вектор, в котором каждое измерение j = 1, ..., D содержит \\nзначение, описывающее некоторую характеристику образца. Это значение называ-\\nется признаком и обозначается как x(j). Например, если каждый образец x в нашей'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='1.2. Типы обучения   19\\nколлекции представляет человека, тогда первый признак, x(1), мог бы описывать его \\nрост в сантиметрах, второй признак, x(2), мог бы описывать его вес в килограммах, \\nx(3) — пол, и т. д. Для всех данных в наборе данных признак в позиции j в векторе \\nпризнаков всегда описывает одну и ту же характеристику. Это означает, что если \\n описывает вес некоторого образца xi в килограммах, тогда \\n  также будет \\nописывать вес в килограммах каждого образца xk, k = 1, ..., N. Метка yi может быть \\nэлементом конечного множества классов {1, 2, ..., C}, вещественным числом или \\nболее сложной структурой, такой как вектор, матрица, дерево или граф. В этой \\nкниге, если явно не оговаривается иное, под yi будет подразумеваться элемент \\nконечного множества классов или вещественное число1. Класс можно представить \\nкак категорию, которой принадлежит образец. Например, если роль данных играют \\nэлектронные письма и вы решаете задачу определения спама, тогда вы могли бы \\nопределить два класса: {спам, не_спам}.\\nЦель алгоритма обучения с учителем — на основе набора данных создать модель, \\nкоторая принимает вектор признаков x на входе и возвращает информацию, которая \\nпозволяет определить метку для этого вектора признаков. Например, модель, создан-\\nная с использованием набора данных людей, могла бы принимать вектор признаков, \\nописывающих человека, и возвращать вероятность, что этот человек болен раком.\\n1.2.2. Обучение без учителя\\nВ обучении без учителя набор данных представлен коллекцией неразмеченных \\nобразцов \\n . И снова, x — это вектор признаков, а цель алгоритма обучения \\nбез учителя — создать модель, которая принимает вектор признаков x на входе \\nи преобразует его в другой вектор или в значение, которое можно использовать для \\nрешения практической задачи. Например, в задачах кластеризации модель воз-\\nвращает идентификатор кластера для каждого вектора признаков в наборе данных. \\nВ задачах уменьшения размерности модель возвращает вектор признаков, который \\nимеет меньше элементов, чем входной вектор x. В задачах выявления аномалий \\nвозвращается действительное число, которое указывает, насколько x отличается \\nот «типичного» образца в наборе данных.\\n1.2.3. Обучение с частичным привлечением учителя\\nВ обучении с частичным привлечением учителя (semi-supervised learning) набор \\nданных содержит как размеченные, так и неразмеченные образцы. Обычно не -\\nразмеченных образцов намного больше, чем размеченных. Алгоритм обучения  \\n1 Вещественное число — это величина, которую можно представить как расстояние на \\nчисловой прямой. Примеры вещественных чисел: 0, –256.34, 1000, 1000.2.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='20   Глава 1. Введение\\nс частичным привлечением учителя преследует ту же цель, что и алгоритм обу-\\nчения с учителем. В данном случае предполагается, что использование множества \\nнеразмеченных данных поможет алгоритму обучения найти (можно также сказать \\n«произвести» или «вычислить») лучшую модель.\\nПредположение о выигрыше от добавления большего количества неразмеченных \\nданных может показаться нелогичным. На первый взгляд кажется, что мы, на -\\nоборот, добавляем больше неопределенности. Однако добавляя неразмеченные \\nданные, вы вносите больше информации о задаче: б\\ue088ольшая выборка лучше отра-\\nжает распределение вероятностей в данных, откуда взяты размеченные образцы. \\nТеоретически, алгоритм обучения должен уметь воспользоваться этой дополни -\\nтельной информацией.\\n1.2.4. Обучение с подкреплением\\nОбучение с подкреплением — это раздел машинного обучения, где предполага -\\nется, что машина «живет» в определенном окружении и способна воспринимать \\nсостояние этого окружения как вектор характеристик. Машина может выполнять \\nнекоторые действия в каждом состоянии. Разные действия приносят разные возна\\xad\\nграждения, а также могут перевести машину в другое состояние окружения. Цель \\nалгоритма обучения с подкреплением — выучить линию поведения.\\nЛиния поведения — это стратегия (похожая на модель в обу-\\nчении с учителем), которая принимает вектор признаков, опи-\\nсывающий состояние, и возвращает оптимальное действие для \\nвыполнения в этом состоянии. Действие является оптималь -\\nным, если приводит к максимальному ожидаемому среднему \\nвознаграждению.\\nОбучение с подкреплением решает особый класс задач, когда решения принима-\\nются последовательно, а цель является долгосрочной, например игра в видеоигру, \\nроботизация производства, управление ресурсами или логистика. В этой книге \\nосновное внимание будет уделяться принятию единовременных решений, когда \\nисходные данные не зависят друг от друга, и решений, принятых в прошлом. Обу-\\nчение с подкреплением я оставлю за рамками этой книги.\\n1.3. Как работает обучение с учителем\\nВ этом разделе я кратко объясню, как работает обучение с учителем, чтобы дать \\nвам общую картину процесса, прежде чем углубиться в детали. В качестве примера'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='1.3. Как работает обучение с учителем   21\\nя выбрал обучение с учителем, так как этот тип машинного обучения чаще других \\nиспользуется на практике.\\nПроцесс обучения с учителем начинается со сбора данных. Данные для этого вида \\nобучения — это коллекция пар (вход, выход). Входными данными может быть все \\nчто угодно, например электронные письма, изображения или замеры, полученные \\nот датчика. Выходными данными обычно являются действительные числа или \\nметки (например, «спам», «не_спам», «кошка», «собака», «мышь» и т. д.). В неко-\\nторых случаях выходные данные могут быть представлены векторами (например, \\nчетырьмя координатами углов прямоугольника вокруг человека на картинке), \\nпоследовательностями (например, [«прилагательное», «прилагательное», «су -\\nществительное»] для входа «большая красивая машина») или иметь какую-то \\nдругую структуру.\\nДопустим, вы решили использовать обучение с учителем для решения задачи \\nопределения спама. Вы собираете данные, например, 10 000 электронных писем, \\nкаждое из которых снабжается меткой «спам» или «не_спам» (вы можете добавить \\nэти метки вручную или отдать эту работу на аутсорсинг). Затем вы должны пре -\\nобразовать каждое электронное письмо в вектор признаков.\\nНа основе своего опыта специалист по анализу данных решает, как преобразовать \\nсущность реального мира, такую как электронное письмо, в вектор признаков. \\nЧасто для преобразования текста в вектор признаков используется метод, назы -\\nваемый мешком слов. Его суть заключается в том, чтобы взять словарь (допустим, \\nчто он содержит 20 000 слов, отсортированных по алфавиту) и условиться, что \\nв векторе признаков:\\n  первый признак равен 1, если электронное письмо содержит слово «а» (союз), \\nи 0 в другом случае;\\n  второй признак равен 1, если электронное письмо содержит слово «аарон» \\n(имя), и 0 в другом случае;\\n  ...;\\n  признак в позиции 20 000 равен 1, если электронное письмо содержит слово \\n«ящур» (болезнь), и 0 в другом случае.\\nВы повторяете описанную процедуру для каждого электронного письма в вашей \\nколлекции и получаете 10 000 векторов признаков (каждый вектор имеет размер-\\nность 20 000) и меток («спам»/«не_спам»).\\nТеперь у вас есть машиночитаемые входные данные, но выходные метки по-\\nпрежнему имеют вид простого текста. Некоторые алгоритмы обучения требуют \\nпреобразования меток в числа. Например, некоторые алгоритмы требуют исполь-'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='22   Глава 1. Введение\\nзовать числа 0 (для представления метки «не_спам») и 1 (для представления метки \\n«спам»). Модель машинного обучения, которую я использую для иллюстрации \\nобучения с учителем, называется методом опорных векторов  (Support Vector \\nMachine, SVM) . Она требует, чтобы положительная метка (в данном случае \\n«спам») имела числовое значение +1 (один), а отрицательная метка («не_спам») \\nимела значение –1 (минус один).\\nТеперь у вас есть набор данных  и алгоритм обучения  и вы готовы применить \\nалгоритм обучения к набору данных, чтобы получить модель.\\nSVM рассматривает каждый вектор признаков как точку в многомерном про -\\nстранстве (в данном случае пространство имеет 20 000 измерений). Алгоритм по-\\nмещает все векторы признаков на воображаемый 20 000-мерный график и рисует \\nвоображаемую 19 999-мерную линию (гиперплоскость), которая отделяет данные \\nс положительными метками от данных с отрицательными метками. Граница, раз-\\nделяющая данные разных классов, в машинном обучении называется границей \\nпринятия решения.\\nУравнение гиперплоскости задается двумя параметрами: вещественным векто -\\nром w той же размерности, что и входной вектор признаков x, и действительным \\nчислом b, например:\\nwx – b = 0,\\nгде выражение wx означает w(1)x(1)+ w(2)x(2)+…+ w(D)x(D), а D — число измерений \\nв векторе признаков x.\\n(Сейчас некоторые уравнения могут показаться вам сложными, но в главе 2 мы \\nрассмотрим необходимые математические и статистические понятия. А пока про-\\nсто попробуйте понять происходящее в меру своих знаний. Многое прояснится, \\nкогда вы прочитаете следующую главу.)\\nТеперь прогнозируемую метку для некоторого входного вектора признаков x \\nможно выразить так:\\ny = sign(wx – b),\\nгде sign — это математический оператор, принимающий произвольное значение \\nи возвращающий +1, если входное значение является положительным числом, \\nи –1, если входное значение является отрицательным числом.\\nЦель алгоритма обучения, в данном случае SVM, используя набор данных, \\nнайти оптимальные значения w* и b* для параметров w и b. После того как'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='1.3. Как работает обучение с учителем   23\\nалгоритм обучения найдет эти оптимальные значения, модель f(x) будет опре -\\nделяться как:\\nf(x) = sign(w*x – b*).\\nЧтобы с помощью модели SVM предсказать, является ли электронное письмо \\nспамом или нет, вы должны взять текст письма, преобразовать его в вектор при-\\nзнаков, затем умножить этот вектор на w*, вычесть b* и взять знак результата. Это \\nдаст нам прогноз (+1 означает «спам», а –1 означает «не_спам»).\\nНо как машина находит w* и b*? Она решает задачу оптимизации. Машины хорошо \\nсправляются с оптимизацией функций в условиях ограничений.\\nИтак, какие ограничения должны удовлетворяться здесь? Прежде всего, модель \\nдолжна правильно предсказывать метки имеющихся 10 000 данных. Напомню, что \\nкаждый образец i = 1, ..., 10 000 задается парой (xi, yi), где xi — вектор признаков \\ni-го образца, а yi — его метка, которая принимает значение –1 или +1. Ограничения \\nвыглядят следующим образом:\\nwxi – b ≥ +1, если yi = +1,\\nwxi – b ≤  –1, если yi = –1.\\nЖелательно также, чтобы гиперплоскость отделяла положительные данные от \\nотрицательных с максимальным зазором. Зазор — это расстояние между ближай-\\nшими образцами двух классов, отделяемых границей принятия решения. Большой \\nзазор способствует лучшему обобщению, то есть тому, насколько хорошо модель \\nбудет классифицировать новые данные. Для максимизации зазора нужно мини -\\nмизировать евклидову норму w, которая обозначается как || w || и определяется \\nвыражением \\n .\\nМашина должна решить задачу оптимизации, которая формулируется так:\\nМинимизировать  || w || с учетом y i(wxi – b) ≥ 1  для i = 1, ..., N. Выражение \\nyi(wxi – b) ≥ 1 — это всего лишь компактная запись двух ограничений выше.\\nРешение этой задачи оптимизации, обозначенной параметрами w* и b*, называ-\\nется статистической моделью, или просто моделью. Процесс построения модели \\nназывается обучением.\\nДля двумерных векторов задачу и решение можно представить визуально, как \\nпоказано на рис. 1.1. Синие и оранжевые точки представляют положительные и от-\\nрицательные образцы соответственно, а линия, заданная уравнением wx – b = 0, \\nпредставляет границу принятия решения.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='24   Глава 1. Введение\\nx(2)\\nx(1)\\nwx — \\nb = 0\\nwx — \\nb = 1\\nwx\\n — \\nb = —1\\nb ||w|| \\n2 ||w|| \\nРис. 1.1. Пример модели SVM для двумерных векторов признаков\\nПочему минимизация нормы w дает в результате наибольший зазор между дву -\\nмя классами? Геометрически уравнения wx – b = 1 и wx – b = –1 определяют две \\nпараллельные гиперплоскости, как показано на рис. 1.1. Расстояние между этими \\nгиперплоскостями равно \\n , поэтому чем меньше норма || w ||, тем больше рас -\\nстояние между этими двумя гиперплоскостями.\\nТак работает метод опорных векторов (SVM). Эта конкретная версия алгоритма \\nстроит так называемую линейную модель. Она называется линейной, потому что гра-\\nница принятия решения — это прямая линия (или плоскость, или гиперплоскость). \\nМетод опорных векторов также может включать ядра, способные сделать границу \\nрешения произвольно нелинейной. В некоторых случаях невозможно полностью'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='1.4. Почему модель способна работать с новыми данными   25\\nразделить две группы точек из-за шума в данных, ошибок разметки или аномалий \\n(данных, сильно отличающихся от «типичного» образца в наборе данных). Для \\nтаких случаев есть версия алгоритма SVM, способная включать гиперпараметр \\nштрафа1 за неправильную классификацию обучающих данных конкретных классов. \\nБолее подробно алгоритм SVM мы рассмотрим в главе 3.\\nСейчас вы должны усвоить следующее: любой алгоритм решения задачи клас -\\nсификации при построении модели явно или неявно создает границу решения. \\nГраница решения может быть прямой, изогнутой, иметь сложную форму или \\nобразовываться наложением некоторых геометрических фигур. Форма границы \\nрешения определяет точность модели (то есть долю образцов, метки которых \\nпредсказываются моделью правильно). Форма границы решения и то, как она \\nалгоритмически или математически вычисляется на основе обучающих данных, \\nотличают один алгоритм обучения от другого.\\nНа практике необходимо учитывать также две другие важные характеристики \\nалгоритма обучения: скорость построения модели и время получения прогноза. Во \\nмногих практических ситуациях предпочтение отдается более быстрым алгорит-\\nмам, которые строят менее точные модели. Кроме того, иногда предпочтительнее \\nиметь менее точную модель, но быстро вычисляющую прогнозы.\\n1.4. Почему модель способна работать \\nс новыми данными\\nПочему модель, полученная в результате машинного обучения, способна правильно \\nпредсказывать метки для новых, ранее не встречавшихся ей данных? Чтобы по -\\nнять это, посмотрите на график на рис. 1.1. Если два класса можно отделить друг \\nот друга границей решения, то, очевидно, данные, принадлежащие каждому классу, \\nрасположены в двух разных подпространствах, которые создает граница решения.\\nЕсли данные, использованные для обучения, были выбраны случайным образом, \\nнезависимо друг от друга и  с использованием одной и  той же процедуры, тогда \\nстатистически весьма вероятно, что новый отрицательный образец окажется на \\nграфике где-то не очень далеко от других отрицательных данных. То же касается \\nнового положительного образца: он, скорее всего, окажется где-то среди других \\nположительных данных. В таком случае наша граница решения с высокой вероят-\\n1 Гиперпараметр — это свойство алгоритма обучения, обычно (но не всегда) имеющее чис-\\nловое значение. Это значение влияет на работу алгоритма. Значения гиперпараметров не \\nопределяются самим алгоритмом из данных. Они должны задаваться аналитиком перед \\nзапуском алгоритма.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='26   Глава 1. Введение\\nностью будет надежно отделять друг от друга новые положительные и отрицатель-\\nные данные. В других менее вероятных ситуациях наша модель будет совершать \\nошибки, но, поскольку такие ситуации менее вероятны, число ошибок, скорее \\nвсего, будет меньше числа правильных прогнозов.\\nОчевидно, что чем больше набор обучающих данных, тем менее \\nвероятно, что новые данные будут отличаться (и лежать на гра-\\nфике далеко) от данных, использованных для обучения.\\nДля минимизации вероятности ошибок прогнозирования на \\nновых образцах алгоритм SVM в поисках наибольшего зазора, \\nявным образом пытается провести границу решения так, чтобы она лежала как \\nможно дальше от данных обоих классов.\\nЧитателю, желающему узнать больше об обучаемости и понять связь между ошиб-\\nкой модели, размером обучающего набора, формой математического уравнения, \\nопределяющего модель, и временем построения модели, рекомендуется прочитать \\nо вероятностном приблизительно корректном обучении (Probably Approximately \\nCorrect, P AC). Теория вероятностно-приблизительного корректного обучения \\nпоможет проанализировать и понять, сможет ли и при каких условиях алгоритм \\nобучения получить приблизительно корректный классификатор.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='2\\nОбозначения \\nи определения\\n2.1. Обозначения\\nНачнем с того, что повторим математические обозначения, которые мы все учили \\nв школе, но некоторые, вероятно, забыли их сразу после выпускного.\\n2.1.1. Структуры данных\\nСкаляр — это простое числовое значение, например, 15 или –3.25. Переменные \\nили константы, принимающие скалярные значения, обозначаются наклонным \\nшрифтом, например x или a.\\nВектор — это упорядоченный список скалярных значений, называемых атрибута-\\nми. Мы будем обозначать векторы жирным шрифтом, например, x или w. Векторы \\nможно изобразить в виде стрелок, указывающих в некоторых направлениях, а также \\nв виде точек в многомерном пространстве. Для примера на рис. 2.1 показаны три \\nдвумерных вектора, a = [2, 3], b = [–2, 5] и c = [1, 0]. Атрибуты вектора мы будем \\nобозначать наклонным шрифтом с индексом, например: w(j) или x(j). Индекс j обо-\\nзначает конкретное измерение вектора — позицию атрибута в списке. Например, \\nв векторе a, изображенном на рис. 2.1 в виде красной стрелки, a(1) = 2 и a(2) = 3.\\nОбозначение x(j) не следует путать с выражением степени, например x2 (x в квадра-\\nте) или x3 (x в кубе). Если нам понадобится возвести в степень, например в квадрат, \\nатрибут с индексом, мы запишем это так: \\n .\\nПеременная может иметь два или более индексов: \\n  или \\n . Например, обсуж-\\nдая нейронные сети, мы будем использовать запись \\n  для обозначения входного \\nпризнака j узла u в слое l.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='28   Глава 2. Обозначения и определения\\nРис. 2.1. Три вектора, изображенные как стрелки и точки\\nМатрица — это прямоугольный массив чисел, расположенных в строках и столбцах. \\nНиже приводится пример матрицы с двумя строками и тремя столбцами:'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='2.1. Обозначения   29\\nМатрицы будут обозначаться заглавными буквами и жирным шрифтом, напри -\\nмер: A или W.\\nМножество — это неупорядоченная коллекция уникальных элементов. Мы будем \\nобозначать множества заглавными буквами, например S. Множества чисел могут \\nбыть конечными (содержать фиксированное количество значений). В этом случае \\nмы будем обозначать их с использованием фигурных скобок, например {1, 3, 18, 23, \\n235} или {x1, x2, x3, x4, ..., xn}. Множество может быть бесконечным и содержать все \\nзначения, принадлежащие некоторому интервалу. Если множество включает все \\nзначения между a и b, в том числе a и b, мы будем обозначать его с использованием \\nквадратных скобок: [a, b]. Если множество не включает значения a и b, такое мно-\\nжество мы будем обозначать с использованием круглых скобок: (a, b). Например, \\nмножество [0, 1] включает в себя такие значения, как 0, 0.0001, 0.25, 0.784, 0.9995 \\nи 1.0. Специальное множество, обозначаемое как R, включает все числа от минус \\nбесконечности до плюс бесконечности.\\nЕсли элемент x принадлежит множеству S, мы выражаем это как x ϵ S. Мы можем \\nполучить новое множество S3 как пересечение двух множеств S1 и S2. Это вы -\\nражается как \\n . Например, \\n  дает в результате новое \\nмножество {1, 8}.\\nНовое множество S3 можно получить как объединение двух множеств S1 и S2. Мы \\nбудем выражать это так: \\n . Например, \\n  дает в резуль-\\nтате новое множество {1, 3, 4, 5, 8}.\\n2.1.2. Обозначения со знаком суммы\\nСуммирование элементов коллекции \\n или атрибутов век-\\nтора \\n обозначается так:\\n или так: \\n .\\nОператор \\n  обозначает «определен как».\\n2.1.3. Обозначения со знаком произведения\\nПо аналогии с суммированием существует обозначение, выражающее произведение. \\nОно обозначает произведение элементов коллекции или атрибутов вектора:'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='30   Глава 2. Обозначения и определения\\nгде \\n  означает умножение a на b. Там, где это возможно, мы будем опускать опе-\\nратор умножения (·), упрощая запись произведения до ab, также обозначающего \\nумножение a на b.\\n2.1.4. Операции с множествами\\nОператор создания производного множества выглядит следующим образом: \\n. Это выражение означает, что создается новое множество \\n, в которое помещаются квадраты тех элементов x, принадлежащих S, значения \\nкоторых больше 3.\\nОператор мощности \\n  возвращает число элементов в множестве S.\\n2.1.5. Операции с векторами\\nСумма двух векторов x + z определяется как вектор\\n .\\nРазность двух векторов x – z определяется как вектор\\n.\\nПроизведение вектора на скаляр — это вектор. Например, \\n .\\nСкалярное произведение двух векторов — это скаляр. Например, \\n . \\nВ некоторых книгах скалярное произведение записывается как w ∙ x. Два вектора \\nдолжны иметь одинаковую размерность. Иначе результат скалярного произведе-\\nния не определен.\\nПроизведение матрицы W на вектор x дает в результате новый вектор. Допустим, \\nу нас есть матрица\\nКогда в операциях с матрицами участвуют векторы, по умолчанию вектор представ-\\nляется в виде матрицы с одним столбцом. Когда в выражении умножения вектор \\nнаходится справа от матрицы, он остается вектором-столбцом. Умножить матрицу'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='2.1. Обозначения   31\\nна вектор можно, только если количество строк в векторе совпадает с количеством \\nстолбцов в матрице. Пусть у нас есть вектор \\n . Тогда результатом \\nпроизведения Wx будет двумерный вектор:\\nЕсли бы матрица имела, скажем, пять строк, в результате умножения получился \\nбы пятимерный вектор.\\nКогда в выражении умножения вектор находится слева от матрицы, его нужно \\nтранспонировать (повернуть) перед умножением. Транспонирование вектора x \\nобозначается как xТ и преобразует вектор-столбец в вектор-строку. Допустим,\\n.\\nУмножение вектора x на матрицу W обозначается как x\\n┬\\nW,\\n \\nКак видите, умножить вектор на матрицу можно только в том случае, если число \\nизмерений в векторе совпадает с числом строк в матрице.\\n2.1.6. Функции\\nФункция — это отношение, связывающее каждый элемент x из множества X (об\\xad\\nласти определения функции) с единственным элементом y из другого множества Y'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='32   Глава 2. Обозначения и определения\\n(области значений функции). Функция обычно имеет имя. Если функция назы-\\nвается f, тогда отношение обозначается как y = f(x) (читается как «эф от икс»), \\nгде элемент x является аргументом, или входом, функции, а y — значением, или \\nвыходом, функции.\\nСимвол, представляющий аргумент, — это переменная функции (мы часто будем \\nговорить, что f — это функция от переменной x).\\nМы говорим, что f(x) имеет локальный минимум  при x = c, если f(x) ≥ f(c) для \\nкаждого значения x в некотором открытом интервале вокруг x = c. Интервал — \\nэто множество действительных чисел, такое, что любое число, которое находится \\nмежду двумя числами в множестве, также входит в это множество. Открытый \\nинтервал не включает конечные точки и обозначается круглыми скобками. \\n Например, (0, 1) означает «все числа больше 0 и меньше 1». Минимальное зна -\\nчение среди всех локальных минимумов называется глобальным минимумом  \\n(рис. 2.2).\\nлокальный миним ум\\nглобальный миним ум\\nx\\nf (x)\\n6\\n4\\n2\\n0\\n–2\\n–4\\n–6\\n0 0.2 0.4 0.6 0.8 1 1.2\\nРис. 2.2. Локальный и глобальный минимумы функции\\nВекторная функция, обозначаемая как y = f(x), — это функция, возвращающая \\nвектор y. Аргумент такой функции может быть вектором или скаляром.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='2.1. Обозначения   33\\n2.1.7. Операторы max и arg max\\nПусть дано множество значений A = {a1, a2, …an}, тогда оператор \\n  вернет \\nнаибольшее значение f(a) из всех элементов в множестве A. С другой стороны, опе-\\nратор \\n  вернет элемент из множества A, который максимизирует f(а).\\nИногда, когда множество задано неявно или бесконечно, запись этих операторов \\nможно сократить до \\n  или \\n .\\nСуществуют также аналогичные операторы min и arg min.\\n2.1.8. Оператор присваивания\\nВыражение a ← f(x) означает, что переменная a получает новое значение: результат \\nf (x). Мы говорим, что переменной a присваивается новое значение. Аналогично, \\na ← [a1, a2] означает, что векторная переменная a получает значение двумерного \\nвектора [a1, a2].\\n2.1.9. Производная и градиент\\nПроизводная f ′ функции f — это функция или значение, которое описывает, как \\nбыстро f растет (или уменьшается). Если производная имеет постоянное значение, \\nнапример 5 или –3, значит, функция постоянно растет (или уменьшается) в лю-\\nбой точке x области определения. Если производная f ′ является функцией, тогда \\nфункция f может расти с разной скоростью в разных точках в области определения. \\nЕсли производная f ′ положительна в некоторой точке x, значит, функция f растет \\nв этой точке. Если производная от f отрицательна в некоторой точке x, значит, \\nфункция уменьшается в этой точке. Производная, равная нулю в точке x, означает, \\nчто функция f в этой точке не растет и не уменьшается (то есть это точка минимума \\nили максимума функции f).\\nПоиск производной называется дифференцированием дифференцированием.\\nПроизводные для основных функций известны. Например, для f(x) = x2 произ-\\nводная имеет вид f ′(x) = 2x; для  f(x) = 2x производная имеет вид f ′(x) = 2; для \\nf(x) = 2 производная имеет вид f ′(x) = 0 (производная любой функции f(x) = c, где \\nc — константа, равна нулю).\\nЕсли функция, которую нужно дифференцировать, не относится к числу ос -\\nновных, ее производную можно найти, используя правило дифференциро \\xad\\nвания сложной функции . Например, если F(x) = f(g(x)), где f и g — некото -\\nрые функции, тогда F ′(x) = f ′(g(x))g ′(x). Например, если F(x) = (5x +1)2, тогда'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='34   Глава 2. Обозначения и определения\\ng(x) = 5x + 1 и f (g(x)) = (g(x))2. Применяя правило выше, находим F ′(x) = 2(5x + 1)\\ng ′(x) = 2(5x + 1)5 = 50x + 10.\\nГрадиент — это обобщение производной для функций нескольких аргументов (или \\nодного аргумента, представленного вектором или какой-либо другой сложной \\nструктурой). Градиент функции — это вектор частных производных. Поиск част-\\nной производной функции можно рассматривать как процесс поиска производной, \\nкогда изменяется только один из входов, а остальные имеют постоянные значения.\\nНапример, если функция определена как \\n , тогда \\nчастная производная функции f относительно x(1), обозначаемая как \\n , будет \\nопределяться формулой\\nгде а — производная функции ax(1); два нуля соответствуют производным от bx(2) \\nи c, потому что когда вычисляется производная по x(1), x(2) считается константой, \\nа производная любой константы равна нулю.\\nАналогично, частная производная функции f относительно x(2), \\n , будет опре-\\nделяться формулой\\nГрадиент функции f обозначается как ∇f и задается вектором \\n .\\nПравило дифференцирования сложной функции применимо и к частным произ-\\nводным, как я покажу в главе 4.\\n2.2. Случайная величина\\nСлучайная величина, которая обычно обозначается курсивной заглавной буквой, \\nнапример X, — это величина, возможные значения которой являются числовыми \\nрезультатами случайного явления. Примерами случайных явлений с числовым \\nрезультатом могут служить бросок монеты (0 для решки и  1 для орла), бросок \\nигрального кубика или рост первого незнакомца, встретившегося на улице. Су -\\nществует два типа случайных величин: дискретные и непрерывные.\\nДискретная случайная величина  принимает конечное или счетное множество \\nзначений, например: красный, желтый, синий или 1, 2, 3,  ...'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='2.2. Случайная величина   35\\nРаспределение вероятностей  дискретной случайной величины описывается \\nсписком вероятностей, связанных с каждым из возможных значений. Этот список \\nвероятностей называется функцией распределения дискретной случайной вели\\xad\\nчины (probability mass function, pmf). Например: Pr(X = красный) = 0.3, Pr(X = жел-\\nтый) = 0.45, Pr(X = синий) = 0.25. Каждая вероятность в функции распределения \\nдискретной случайной величины — это значение, большее или равное 0. Сумма \\nвероятностей равна 1 (рис. 2.3a).\\nФункция распределения\\nдискретной случайной величины\\n           \\n(а)\\nПлощадь\\nФункция плотности\\nраспределения вероятностей\\n           \\n(б)\\nРис. 2.3. Функция распределения дискретной случайной величины (а) и функция \\nплотности распределения вероятностей (б)'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='36   Глава 2. Обозначения и определения\\nНепрерывная случайная величина (continuous random variable, CRV) может прини-\\nмать бесконечное число возможных значений в некотором интервале. Примерами \\nмогут служить рост, вес и время. Поскольку число значений непрерывной случай-\\nной величины X бесконечно, вероятность Pr(X = c) для любого c равна 0. Поэтому \\nраспределение вероятностей CRV (непрерывное распределение вероятностей) \\nописывается не списком, а функцией плотности вероятности (probability density \\nfunction, pdf). Функция плотности вероятности — это функция с неотрицательной \\nобластью значений, а площадь под кривой этой функции равна 1 (рис. 2.3б).\\nПусть дискретная случайная величина X имеет k возможных значений \\n . \\nОжидание X, обозначаемое как E[X], определяется формулой\\n \\n   (2.1)\\nгде Pr(X = xi) — вероятность, что X имеет значение xi в соответствии с pmf. Ожида-\\nние случайной величины также называется средним, или ожидаемым, значением \\nи часто обозначается буквой μ. Ожидание является одной из наиболее важных \\nстатистических характеристик случайной величины.\\nЕще одной важной статистической характеристикой является стандартное от \\xad\\nклонение, которое определяется как\\nДисперсия, обозначаемая как σ2 или var(X), определяется формулой\\nДля дискретной случайной величины стандартное отклонение определяется как:\\n,\\nгде \\n .\\nОжидание непрерывной случайной величины X определяется формулой\\n \\n ,  (2.2)'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='2.4. Правило Байеса   37\\nгде fX — это функция плотности вероятности (pdf) величины X, а \\n  — интеграл \\nот функции xfX.\\nИнтеграл является эквивалентом суммы всех значений функции, когда функция \\nимеет непрерывную область определения. Он равен площади под кривой функции. \\nФункция плотности вероятности обладает замечательным свойством: площадь под \\nее кривой всегда равна 1, то есть математически это означает, что \\n .\\nВ большинстве случаев fX неизвестна, но мы можем наблюдать некоторые значе-\\nния X. В машинном обучении мы называем эти значения образцами, а набор этих \\nданных — выборкой или набором данных.\\n2.3. Несмещенные оценки\\nТак как обычно fX неизвестна, но имеется выборка \\n , мы часто доволь-\\nствуемся не истинными значениями статистических характеристик распределения \\nвероятностей, такими как ожидание, а их несмещенными оценками.\\nМы говорим, что \\n  — это несмещенная оценка некоторой статистической \\nхарактеристики θ, вычисленной по выборке SX с неизвестным распределением \\nвероятностей, если \\n  обладает следующим свойством:\\n,\\nгде \\n  — статистическая характеристика выборки, полученная по выборке SX, а не \\nреальная статистическая характеристика, которую можно получить, только зная X; \\nожидание определяется по всем возможным выборкам из X. Это означает, что при \\nналичии неограниченного количества выборок, таких как SX, вычислив некоторую \\nнесмещенную оценку, такую как \\n , для каждой выборки и взяв среднее значение \\nдля всех этих \\n , вы получите значение реальной статистической характеристики μ, \\nкоторую вычислили бы по X.\\nМожно показать, что несмещенная оценка неизвестного ожидания E[X] (заданно-\\nго уравнением 2.1 или 2.2) равна \\n  (в статистике называется выборочное \\nсреднее).\\n2.4. Правило Байеса\\nУ словная вероятность Pr(X = x | Y = y) — это вероятность того, что случайная ве-\\nличина X будет иметь конкретное значение x при условии, что другая случайная'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='38   Глава 2. Обозначения и определения\\nвеличина Y имеет конкретное значение y. Правило Байеса (также известное как \\nтеорема Байеса) гласит:\\n.\\n2.5. Оценка параметров\\nПравило Байеса удобно использовать, когда есть модель распределения X и эта \\nмодель \\n  является функцией, имеющей некоторые параметры в форме вектора θ. \\nПримером такой функции может служить функция Гаусса с двумя параметрами, \\nμ и σ, которая определяется как\\n,\\nгде \\n .\\nЭта функция имеет все свойства функции плотности распределения вероятно -\\nстей (pdf)1. Следовательно, ее можно использовать как модель неизвестного рас-\\nпределения X. Мы можем получить значения параметров в векторе θ из данных, \\nиспользуя правило Байеса:\\n.  (2.3)\\nгде \\n .\\nЕсли есть выборка S из X и множество возможных значений для θ конечно, мы \\nлегко сможем оценить \\n , итеративно применив правило Байеса к каж-\\nдому образцу \\n . Начальное значение \\n  можно выбрать таким, что \\n. Это предположение о вероятностях для различных \\n  называется \\nаприорной вероятностью.\\nСначала вычислим \\n  для всех возможных значений \\n . Затем, перед \\nобновлением \\n , на этот раз для \\n  с использованием уравне-\\n1 На самом деле уравнение 2.3 определяет pdf одного из наиболее часто используемых \\nна практике распределений вероятности, называемого гауссовым распределением, или \\nнормальным распределением, и обозначаемого как N (μ, σ2).'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='2.7. Классификация и регрессия   39\\nния 2.3, заменим априорную вероятность \\n  в уравнении 2.3 новой оценкой \\n.\\nЛучшие значения параметров θ* в данном примере получаются с использованием \\nпринципа максимума апостериорной вероятности (maximum a posteriori, MAP):\\n \\n .  (2.4)\\nЕсли множество возможных значений для θ бесконечно, то уравнение 2.4 нужно \\nоптимизировать путем применения процедуры численной оптимизации, такой как \\nградиентный спуск, который мы рассмотрим в главе 4. Обычно оптимизируется \\nнатуральный логарифм выражения в правой части уравнения 2.4, потому что ло-\\nгарифм произведения превращается в сумму логарифмов, а компьютерам проще \\nработать с суммой, чем с произведением1.\\n2.6. Параметры и гиперпараметры\\nГиперпараметр — это свойство алгоритма обучения, обычно (но не всегда) имеющее \\nчисловое значение. Это значение влияет на работу алгоритма. Гиперпараметры не \\nвычисляются алгоритмом. Они должны задаваться аналитиком перед запуском \\nалгоритма. Как это сделать, я покажу в главе 5.\\nПараметры — это переменные, которые определяют модель, обучаемую алгорит -\\nмом обучения. Параметры напрямую изменяются алгоритмом обучения на основе \\nобучающих данных. Цель обучения — найти такие значения параметров, которые \\nделают модель оптимальной в определенном смысле.\\n2.7. Классификация и регрессия\\nКлассификация — это задача автоматического определения метки для неразме\\xad\\nченного образца. Определение спама — один из ярких примеров классификации.\\nВ машинном обучении задача классификации решается с помощью алгоритма обу\\xad\\nчения классификации, который на входе принимает набор размеченных данных \\n1 Умножение большого количества чисел может дать очень маленький или очень большой \\nрезультат. Это часто приводит к проблеме переполнения, когда компьютер оказывается \\nне в состоянии сохранить в памяти такое экстремально маленькое или экстремально \\nбольшое число.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='40   Глава 2. Обозначения и определения\\nи создает модель, которая принимает неразмеченный образец и возвращает либо \\nего метку непосредственно, либо число, на основании которого аналитик сможет \\nопределить метку. Примером такого числа является вероятность.\\nВ задаче классификации метка является членом конечного множества клас\\xad\\nсов. Если размер множества классов равен двум («больной»/«здоровый», \\n«спам»/«не_спам»), мы называем такую классификацию бинарной классифика\\xad\\nцией (в некоторых источниках ее также называют биномиальной). Классификация \\nс несколькими классами (также называемая мультиномиальной, или многоклас\\xad\\nсовой) — это задача классификации с тремя или более классами1.\\nНекоторые алгоритмы обучения допускают наличие более двух классов, но есть \\nтакие, которые по своей природе являются алгоритмами бинарной классификации. \\nСуществуют стратегии, позволяющие преобразовать алгоритм обучения бинарной \\nклассификации в алгоритм многоклассовой классификации. Об одной из них \\nя расскажу в главе 7.\\nРегрессия — это задача прогнозирования метки с действительным значением \\n(часто называют также целевым значением) для образца без метки. Оценка сто -\\nимости дома на основе таких его характеристик, как площадь, количество спален, \\nрасположение и т. д., — вот один из примеров регрессии.\\nЗадача регрессии решается с помощью алгоритма обучения регрессии, который \\nпринимает на входе набор размеченных данных и создает модель, которая может \\nпо неразмеченному образцу предсказать его целевое значение.\\n2.8. Обучение на основе моделей \\nи на основе примеров\\nБольшинство алгоритмов обучения с учителем основаны на моделях. Мы уже ви-\\nдели один такой алгоритм: метод опорных векторов (SVM). Алгоритмы обучения \\nна основе моделей анализируют обучающие данные и создают модель, параметры \\nкоторой определяются в ходе анализа обучающих данных. В SVM мы видели два \\nпараметра: w* и b*. После создания модели обучающие данные можно отбросить.\\nАлгоритмы обучения на основе примеров используют весь набор данных в качестве \\nмодели. Одним из наиболее часто используемых на практике алгоритмов обучения \\nна основе примеров является метод k ближайших соседей (k\\xadNearest Neighbors, \\nkNN). В проблеме классификации, для того чтобы спрогнозировать метку для \\n1 При этом каждому образцу соответствует единственная метка.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='2.9. Поверхностное и глубокое обучение   41\\nвходного образца, алгоритм kNN просматривает ближайшие окрестности этого \\nобразца в пространстве векторов признаков и возвращает метку, которая чаще \\nвсего встречается в этой окрестности.\\n2.9. Поверхностное и глубокое обучение\\nАлгоритм поверхностного обучения выводит параметры модели непосредственно \\nиз признаков обучающих данных. Большинство алгоритмов обучения с учителем \\nявляются поверхностными. Известными исключениями являются алгоритмы обу-\\nчения нейронных сетей, особенно те, что строят нейронные сети с несколькими \\nслоями между входом и выходом. Такие нейронные сети называются глубокими \\nнейронными сетями. В глубоком обучении нейронной сети (или просто глубоком \\nобучении), в отличие от поверхностного обучения, большинство параметров моде-\\nли выводится не из признаков обучающих данных непосредственно, а из значений, \\nвозвращаемых предыдущими слоями.\\nНе переживайте, если что-то пока остается неясным. Мы подробно рассмотрим \\nнейронные сети в главе 6.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='3\\nФундаментальные \\nалгоритмы\\nВ этой главе я опишу пять самых известных алгоритмов, которые являются либо \\nочень эффективными сами по себе, либо используются как строительные блоки \\nв других эффективных алгоритмах обучения.\\n3.1. Линейная регрессия\\nЛинейная регрессия — это популярный алгоритм обучения регрессии, который \\nстроит модель, являющуюся линейной комбинацией признаков входного образца.\\n3.1.1. Задача\\nДано: коллекция размеченных данных \\n , где N — размер коллекции, \\nxi — D-мерный вектор признаков образца i = 1, ..., N, yi — действительное целевое \\nзначение1, и каждый признак \\n , j = 1, ..., D также является действительным числом.\\nТребуется: сконструировать модель fw, b (x), являющуюся линейной комбинацией \\nпризнаков образца x:\\n \\n ,  (3.1)\\nгде w — D-мерный вектор параметров, а b — действительное число. Запись \\n  \\nозначает, что модель f параметризуется двумя значениями: w и b.\\n1 Чтобы показать, что yi является действительным целевым значением, мы пишем yi ∈ R, \\nгде R обозначает множество всех действительных чисел, бесконечное множество чисел \\nот минус бесконечности до плюс бесконечности.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='3.1. Линейная регрессия   43\\nМодель будет использоваться для предсказания неизвестного целевого зна -\\nчения y для данного x: y ← fw, b (x). Разные модели, параметризованные раз -\\nными  парами ( w, b), могут давать разные предсказания для одного и того же \\nобразца. Нужно найти оптимальные значения (w*, b*). Очевидно, что оптималь-\\nные значения параметров определяют модель, которая дает наиболее точные \\nпрогнозы.\\nОбратите внимание, что линейная модель в уравнении. 3.1 очень похожа на модель \\nSVM. Единственное отличие — отсутствие оператора sign. Модели действитель -\\nно очень похожи. Однако в SVM гиперплоскость играет роль границы принятия \\nрешения: она используется для отделения двух групп данных друг от друга. Как \\nследствие, она должна проходить как можно дальше от каждой группы.\\nВ линейной регрессии, напротив, гиперплоскость проводится так, чтобы оказаться \\nкак можно ближе ко всем обучающим образцам.\\nЧтобы понять, почему это последнее требование является обязательным, взгля -\\nните на рис. 3.1. Здесь изображена линия регрессии (красным цветом) для \\nодномерных данных (синие точки). Эту линию можно использовать для про -\\nгнозирования целевого значения цели yнов. нового образца без метки xнов.. Если \\nбы данные были представлены D-мерными векторами признаков ( D > 1), тогда \\nрешение отличалось бы от одномерного случая тем, что регрессионная модель \\nбыла бы не линией, а плоскостью (в случае двух измерений) или гиперплоско -\\nстью (в случае D > 2).\\nлинейная регрессия\\nобучающие данные\\nyнов.\\nxнов.\\nРис. 3.1. Линейная регрессия для одномерных данных'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='44   Глава 3. Фундаментальные алгоритмы\\nТеперь должно быть понятно, почему так важно требование к расположению ги-\\nперплоскости регрессии как можно ближе к обучающим образцам: если бы красная \\nлиния на рис. 3.1 была далека от синих точек, прогноз yнов. имел бы меньше шансов \\nоказаться верным.\\n3.1.2. Решение\\nЧтобы удовлетворить это последнее требование, процедура оптимизации, ис -\\nпользуемая для поиска оптимальных значений w* и b*, должна минимизировать \\nследующее выражение:\\n \\n .  (3.2)\\nВыражение, которое требуется минимизировать или максимизировать, в матема-\\nтике называется целевой функцией, или просто целью. Выражение (fw, b (xi) – yi)2 \\nв целевой функции выше называется функцией потерь . Она определяет ве -\\nличину штрафа за неправильную классификацию образца i. Эта конкретная \\nфункция потерь называется квадратичной функцией потерь  (squared error \\nloss). Все алгоритмы обучения, основанные на моделях, используют функцию \\nпотерь, и в поисках лучшей модели мы пытаемся минимизировать цель, извест -\\nную как функция стоимости  (cost function). В  линейной регрессии функция \\nстоимости определяется как средняя потеря, также называемая эмпирическим \\nриском (empirical risk). Средняя потеря, или эмпирический риск, для модели  — \\nэто среднее всех штрафов, полученных при применении модели к обучающим \\nданным.\\nПочему в линейной регрессии используется квадратичная функция потерь? И мож-\\nно ли взять абсолютное значение разности между истинным целевым значением yi \\nи прогнозируемым значением f (xi) и использовать его в качестве штрафа? Можно. \\nБолее того, можно использовать любую четную степень вместо квадрата.\\nТеперь, возможно, вы начинаете понимать, сколько решений, на первый взгляд \\nпроизвольных, принимается при разработке алгоритма машинного обучения: \\nв данном примере мы решили использовать линейную комбинацию признаков \\nдля прогнозирования целевого значения. Однако для объединения значений при-\\nзнаков мы могли бы использовать квадрат или другой многочлен. Мы могли бы \\nтакже использовать другую функцию потерь, не лишенную смысла: абсолютная \\nразность между f (xi) и yi имеет смысл, куб разности — тоже; бинарная функция \\nпотерь (возвращающая 1, когда f (xi) и yi различны, и 0 — когда они одинаковы) \\nтоже имеет смысл, верно?'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='3.1. Линейная регрессия   45\\nПриняв другое решение о форме модели, форме функции потерь и о выборе алго-\\nритма минимизации средней потери, чтобы найти лучшие значения параметров, мы \\nв итоге изобрели бы другой алгоритм машинного обучения. Кажется, все просто, \\nне правда ли? Но не спешите изобретать новый алгоритм обучения. Тот факт, что \\nон отличается от имеющихся, не означает, что он будет работать лучше.\\nНовые алгоритмы обучения изобретают по одной из двух основных причин:\\n1. Новый алгоритм решает конкретную практическую задачу лучше существу -\\nющих.\\n2. Новый алгоритм имеет более надежные теоретические гарантии качества про-\\nизводимой им модели.\\nОдним из практических обоснований выбора модели линейной формы является \\nее простота. Зачем использовать сложную модель, если можно использовать про-\\nстую? Другое обоснование: линейные модели в меньшей степени подвержены \\nэффекту переобучения. Переобучение (overfitting) — это свойство модели очень \\nхорошо предсказывать метки данных, использовавшихся для обучения, но часто \\nдопускать ошибки при применении к образцам, которые алгоритм обучения не \\nвидел прежде.\\nрегрессия с полиномом \\nстепени 10\\nобучающие данные\\nРис. 3.2. Переобучение\\nНа рис. 3.2 показан пример переобучения в регрессии. Для построения красной ли-\\nнии регрессии использовались те же данные, что и для линии регрессии на рис. 3.1. \\nРазница лишь в том, что на этот раз выполнялась полиномиальная регрессия с по-'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='46   Глава 3. Фундаментальные алгоритмы\\nлиномом степени 101. Линия регрессии почти идеально предсказывает целевые \\nзначения для большинства обучающих данных, но, скорее всего, будет допускать \\nзначительные ошибки на новых данных, как показано на рис. 3.1 для xнов.. Мы еще \\nвернемся к проблеме переобучения в главе 5 и поговорим о том, как его избежать.\\nТеперь вы знаете одно из преимуществ линейной регрессии: она мало подвержена \\nпереобучению. А что можно сказать в отношении выбора квадратичной функции \\nпотерь? Почему мы решили, что потери нужно возводить в квадрат? В 1805 году \\nфранцузский математик Адриен-Мари Лежандр (Adrien-Marie Legendre), который \\nпервым опубликовал метод подсчета суммы квадратов для оценки качества моделей, \\nзаявил, что возведение ошибки в квадрат до суммирования — это удобно. Почему \\nон так сказал? Абсолютное значение неудобно, потому что не имеет непрерывной \\nпроизводной, что делает функцию негладкой. Негладкие функции создают ненуж-\\nные сложности, когда для поиска аналитических решений оптимизационных задач \\nиспользуются методы линейной алгебры. Аналитические решения для нахождения \\nоптимума функции — это простые алгебраические выражения, и они часто предпо-\\nчтительнее использования сложных численных методов оптимизации, таких как гра\\xad\\nдиентный спуск (используется для обучения нейронных сетей, кроме всего прочего).\\nОчевидно, что квадраты штрафов выгодны еще и потому, что преувеличивают раз-\\nность между истинным и прогнозируемым целевыми значениями, в соответствии \\nс величиной этой разности. Также можно использовать другие четные степени, \\nтакие как 4 или 6,, но работать с их производными сложнее.\\nНаконец, зачем нам нужна производная средней потери? Вычислив градиент функ-\\nции в уравнении 3.2, мы сможем затем установить этот градиент в ноль2 и найти \\nрешение системы уравнений, которое даст нам оптимальные значения w* и b*.\\n3.2. Логистическая регрессия\\nСразу должен сказать, что логистическая регрессия — это не регрессия, а алгоритм \\nобучения классификации. Название происходит из статистики и связано с тем, что \\nматематическая формулировка логистической регрессии аналогична линейной \\nрегрессии.\\n1 В полиномиальной регрессии степени n, f(x) имеет дополнительный параметр для ар -\\nгумента x, возведенного в каждую из степеней от 1 до 10, то есть f(x) =def w1x1 + w2x2 +  \\n+ … + wnxn + b″.\\n2 Чтобы найти минимум или максимум функции, мы устанавливаем градиент в ноль, по-\\nтому в точках экстремума функции значение градиента всегда равно нулю. В двумерном \\nслучае градиент экстремума — это горизонтальная линия.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='3.2. Логистическая регрессия   47\\nЯ объясняю суть логистической регрессии на примере бинарной классификации. \\nОднако его можно естественным образом распространить на многоклассовую \\nклассификацию.\\n3.2.1. Задача\\nЦель логистической регрессии все та же: смоделировать yi как линейную функцию \\nот xi, однако для бинарных значений yi это не так просто. Линейная комбинация \\nпризнаков, такая как \\n , — это функция, простирающаяся от минус бесконеч-\\nности до плюс бесконечности, тогда как yi имеет только два возможных значения.\\nВо времена, когда не было компьютеров и все вычисления приходилось выполнять \\nвручную, ученые отдавали предпочтение моделям линейной классификации. В ту \\nпору они подметили, что если определить отрицательную метку как 0, а положи-\\nтельную метку как 1, достаточно найти простую непрерывную функцию с областью \\nзначений (0, 1). В этом случае, если значение, возвращаемое моделью для образца x, \\nближе к 0, ему присваивается отрицательная метка; иначе образец маркируется как \\nположительный. Одной из функций, обладающих таким свойством, является стан\\xad\\nдартная логистическая функция (также известная как логистический сигмоид):\\n,\\nгде e — основание натурального логарифма (также называется числом Эйлера ; \\nзначение ex в языках программирования также известно как функция exp(x)). Ее \\nграфик изображен на рис. 3.3.\\nВот как выглядит модель логистической регрессии:\\n \\n .  (3.3)\\nКак видите, здесь присутствует уже знакомый нам член wx + b из линейной ре -\\nгрессии.\\nВзглянув на график стандартной логистической функции, можно заметить, \\nнасколько хорошо она соответствует нашей цели классификации: если соот -\\nветствующим образом оптимизировать значения w и b, результат f(x) можно \\nинтерпретировать как вероятность, что yi будет иметь положительное значение. \\nНапример, если она выше или равна пороговому значению 0.5, мы бы сказали, что \\nкласс x положителен; иначе — отрицателен. На практике могут выбираться другие \\nпороговые значения, в зависимости от решаемой задачи. Мы вернемся к этой теме \\nв главе 5, когда будем говорить об оценке эффективности модели.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='48   Глава 3. Фундаментальные алгоритмы\\nРис. 3.3. Стандартная логистическая функция\\nКак теперь найти оптимальные оценки w* и b*? В линейной регрессии мы минимизи-\\nровали эмпирический риск, который определялся как среднее квадратичной функции \\nпотерь, также известное как среднеквадратичная ошибка (mean squared error, MSE).\\n3.2.2. Решение\\nВ логистической регрессии, в отличие от линейной регрессии, максимизируется \\nправдоподобие  (вероятность) обучающего набора в соответствии с моделью. \\nВ статистике функция правдоподобия определяет, насколько правдоподобным \\nвыглядит наблюдение (образец) в соответствии с нашей моделью.\\nНапример, допустим, что в нашем обучающем наборе имеется размеченный об -\\nразец (xi, yi). Предположим также, что мы нашли (выбрали) некоторые конкрет -\\nные значения \\n  и \\n  для наших параметров. Если теперь применить модель \\n  \\nк xi, используя уравнение 3.3, мы получим некоторое значение 0 < p < 1. Если yi \\nявляется положительным классом, вероятность, что yi является положительным \\nклассом, согласно нашей модели, определяется как p. Аналогично, если yi является \\nотрицательным классом, вероятность, что он является отрицательным классом, \\nопределяется как 1 – p.\\nКритерий оптимизации в логистической регрессии называется максимальным \\nправдоподобием (maximum likelihood). Вместо того чтобы минимизировать сред-\\nнюю потерю, как в линейной регрессии, мы теперь максимизируем правдоподобие \\nобучающих данных в соответствии с моделью:'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='3.3. Обучение дерева решений   49\\n \\n .  (3.4)\\nВыражение \\n  может показаться пугающим, но это всего лишь \\nпричудливый математический способ сказать: «f w, b (x), когда yi = 1, и (1 – f w, b (x)) \\nиначе». Действительно, если yi = 1, тогда \\n равно 1, потому что \\n(1 – yi) = 0, а как мы знаем, любое число в степени 0 равно 1. С другой стороны, \\nесли yi = 0, тогда \\n  равно 1 по той же причине.\\nВозможно, вы обратили внимание, что в целевой функции мы использовали опера-\\nтор произведения \\n  вместо оператора суммы \\n , который применялся в линейной \\nрегрессии. Это связано с тем, что вероятность наблюдения N меток в N образцах \\nявляется произведением вероятностей каждого наблюдения (при условии, что все \\nнаблюдения независимы друг от друга, что в нашем случае действительно так). \\nМожно провести параллель с  умножением вероятностей исходов в  серии неза-\\nвисимых экспериментов в теории вероятностей.\\nПоскольку в модели используется функция exp, на практике удобнее максимизи-\\nровать логарифм правдоподобия, а не правдоподобие. Логарифм правдоподобия \\nопределяется следующим образом:\\n.\\nПоскольку ln — строго возрастающая функция , ее максимизация равносильна \\nмаксимизации ее аргумента, а решение этой новой задачи оптимизации равно -\\nсильно решению исходной задачи.\\nВ отличие от линейной регрессии, задача оптимизации выше не имеет аналитиче-\\nского решения. Поэтому в таких случаях обычно используется процедура числен-\\nной оптимизации — градиентный спуск. Но об этом мы поговорим в следующей \\nглаве.\\n3.3. Обучение дерева решений\\nДерево решений — это ациклический граф, который можно использовать для \\nпринятия решений. В каждом ветвящемся узле графа исследуется j-й признак из \\nвектора признаков. Если значение признака ниже определенного порога, выби -\\nрается левая ветвь; иначе — правая. По достижении листового узла принимается \\nрешение о классе, к которому относится образец.\\nКак следует из заголовка раздела, дерево решений можно получить из данных.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='50   Глава 3. Фундаментальные алгоритмы\\n3.3.1. Задача\\nКак и прежде, дано: коллекция размеченных данных; метки принадлежат множе-\\nству {0, 1}. Нужно построить дерево решений, которое позволило бы предсказать \\nкласс по заданному вектору признаков.\\n3.3.2. Решение\\nСуществуют различные формулировки алгоритма обучения дерева решений. \\nВ этой книге мы рассмотрим только один, который называется ID3.\\nКритерием оптимизации в данном случае является среднее логарифмическое \\nправдоподобие:\\n \\n ,  (3.5)\\nгде fID3 — дерево решений.\\nПока все выглядит похожим на логистическую регрессию. Однако, в отличие от \\nалгоритма обучения логистической регрессии, который строит параметрическую \\nмодель \\n  путем поиска оптимального решения критерия оптимизации, алго -\\nритм ID3 оптимизирует его приблизительно, конструируя непараметрическую \\nмодель \\n .\\nАлгоритм обучения ID3 работает следующим образом. Пусть S обозначает мно-\\nжество размеченных данных. В начале дерево решений имеет только начальный \\nузел, который содержит все данные: \\n . Начнем с постоянной модели \\n, которая определяется как\\n \\n .  (3.6)\\nВышеупомянутая модель \\n  будет возвращать один и тот же прогноз для \\nлюбого входа x. Соответствующее дерево решений, построенное на основе нашего \\nфиктивного набора данных из 12 размеченных данных, показано на рис. 3.4a.\\nЗатем мы ищем все признаки j = 1, ..., D и все пороги t и разбиваем множество S \\nна два подмножества: \\n  и \\n . \\nДва новых подмножества образуют два новых листовых узла, и мы оцениваем для'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='3.3. Обучение дерева решений   51\\nвсех возможных пар (j, t), насколько хорошим получилось расщепление на части \\nS– и S+. Наконец, выбираем наилучшие значения ( j, t), разбиваем S на S– и S+, \\nформируем два новых листовых узла и продолжаем рекурсивно разбивать на \\nS– и S+ (или завершаем работу, если ни одно разбиение не дает модели, которая \\nпозволяет получить лучший прогноз, чем текущая). Дерево решений после одного \\nрасщепления показано на рис. 3.4б.\\nS={(x1, y1), (x2, y2), (x3, y3),\\n(x4, y4), (x5, y5), (x6, y6),\\n(x7, y7), (x8, y8), (x9, y9),\\n(x10, y10), (x11, y11), (x12, y12)}\\nx\\nPr(y = 1|x) = (y1+y2+y3+y4+y5 \\n+y6+y7+y8+y9+y10+y11+y12)/12\\nPr(y = 1|x)\\n(a)\\nx\\nPr(y = 1|x) = (y1+y2+y4 \\n+y6+y7+y8+y9)/7\\nPr(y = 1|x)\\nx(3) < 18.3?\\nS- = {(x1, y1), (x2, y2),\\n(x4, y4), (x6, y6), (x7, y7),\\n(x8, y8), (x9, y9)} \\nPr(y = 1|x) =\\n(y3+y5+y10+y11+y12)/5\\nPr(y = 1|x)\\nS+ = {(x3, y3), (x5, y5), (x10, y10),\\n(x11, y11), (x12, y12)} \\nДа Нет\\n(б)\\n+ +\\n=\\nРис. 3.4. Иллюстрация алгоритма построения дерева решений. Множество S содержит \\n12 размеченных данных. (a) Вначале дерево решений содержит только начальный узел; он \\nдает один и тот же прогноз для любого входа. (б) Дерево решений после первого расщеп-\\nления; оно проверяет, является ли признак 3 меньше 18.3, и, в зависимости от результата, \\nпрогноз выполняется одним из двух листовых узлов\\nТеперь у вас наверняка возник вопрос, что означают слова «оценить, насколько \\nхорошим получилось расщепление». В ID3 качество расщепления оценивается \\nс использованием критерия, называемого энтропией. Энтропия — это мера не -\\nопределенности случайной величины. Она достигает своего максимума, когда все \\nзначения случайной величины равновероятны. Энтропия достигает своего мини-\\nмума, когда случайная величина может иметь только одно значение. Энтропия \\nмножества данных S определяется как\\n.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='52   Глава 3. Фундаментальные алгоритмы\\nКогда мы разбиваем множество данных по некоторому признаку j и порогу t, эн-\\nтропия разбиения \\n  определяется как простая взвешенная сумма двух \\nэнтропий:\\n \\n .  (3.7)\\nИтак, в ID3, на каждом шаге, в каждом листовом узле мы находим расщепление, \\nминимизирующее энтропию, заданную уравнением 3.7, или останавливаемся на \\nэтом листовом узле.\\nАлгоритм останавливается на листовом узле в любой из следующих ситуаций:\\n  Все примеры в листовом узле правильно классифицируются моделью (урав -\\nнение 3.6).\\n  Невозможно найти атрибут для расщепления.\\n  Расщепление уменьшает энтропию ниже некоторого значения ε (которое нуж-\\nно определить экспериментально1).\\n  Дерево достигает некоторой максимальной глубины d (также должна опреде-\\nляться экспериментально).\\nПоскольку в ID3 решение о расщеплении набора данных в каждой итерации явля-\\nется локальным (не зависит от будущих расщеплений), алгоритм не гарантирует \\nоптимального решения. Модель можно улучшить, использовав в процессе поиска \\nоптимального дерева решений такие методы, как возврат (backtracking), хотя и за \\nсчет увеличения времени построения модели.\\nНаиболее широко используемая версия алгоритма обучения дерева решений на -\\nзывается C4.5. Она имеет несколько дополнительных особенностей по сравнению \\nс ID3:\\n  принимает непрерывные и дискретные признаки;\\n  поддерживает возможность обработки неполных данных;\\n  решает проблему переобучения с использованием восходящего метода, из -\\nвестного как «подрезка» (отсечение ветвей).\\nПодрезка заключается в том, чтобы выполнить обратный обход только что создан-\\nного дерева и удалить ветви, которые не вносят существенного вклада в уменьше-\\nние ошибки, заменив их листовыми узлами.\\n1 Я покажу, как это сделать, в главе 5, в разделе, посвященном настройке гиперпараметров.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='3.4. Метод опорных векторов   53\\nКогда мы разбиваем множество данных по некоторому признаку j и порогу t, эн-\\nтропия разбиения  определяется как простая взвешенная сумма двух \\nэнтропий:\\n .  (3.7)\\nИтак, в ID3, на каждом шаге, в каждом листовом узле мы находим расщепление, \\nминимизирующее энтропию, заданную уравнением 3.7, или останавливаемся на \\nэтом листовом узле.\\nАлгоритм останавливается на листовом узле в любой из следующих ситуаций:\\n  Все примеры в листовом узле правильно классифицируются моделью (урав -\\nнение 3.6).\\n  Невозможно найти атрибут для расщепления.\\n  Расщепление уменьшает энтропию ниже некоторого значения ε (которое нуж-\\nно определить экспериментально1).\\n  Дерево достигает некоторой максимальной глубины d (также должна опреде-\\nляться экспериментально).\\nПоскольку в ID3 решение о расщеплении набора данных в каждой итерации явля-\\nется локальным (не зависит от будущих расщеплений), алгоритм не гарантирует \\nоптимального решения. Модель можно улучшить, использовав в процессе поиска \\nоптимального дерева решений такие методы, как возврат (backtracking), хотя и за \\nсчет увеличения времени построения модели.\\nНаиболее широко используемая версия алгоритма обучения дерева решений на -\\nзывается C4.5. Она имеет несколько дополнительных особенностей по сравнению \\nс ID3:\\n  принимает непрерывные и дискретные признаки;\\n  поддерживает возможность обработки неполных данных;\\n  решает проблему переобучения с использованием восходящего метода, из -\\nвестного как «подрезка» (отсечение ветвей).\\nПодрезка заключается в том, чтобы выполнить обратный обход только что создан-\\nного дерева и удалить ветви, которые не вносят существенного вклада в уменьше-\\nние ошибки, заменив их листовыми узлами.\\n1 Я покажу, как это сделать, в главе 5, в разделе, посвященном настройке гиперпараметров.\\nСмысл критерия расщепления на основе энтропии очевиден: эн -\\nтропия достигает минимальной величины 0, когда все данные в S \\nимеют одинаковую метку; с другой стороны, энтропия достигает \\nмаксимальной величины 1, когда ровно половина примеров в S \\nимеет метку 1, что делает такой лист бесполезным для классифи-\\nкации. Единственный оставшийся вопрос — как этот алгоритм \\nприблизительно максимизирует средний логарифм правдоподобия. Я предлагаю \\nчитателям выяснить это самостоятельно.\\n3.4. Метод опорных векторов\\nЯ уже представлял метод опорных векторов (SVM) во введении, поэтому здесь \\nвосполню лишь несколько пробелов. Вот два важных вопроса, которые мы должны \\nзадать:\\n1. Как быть, если исходные данные настолько искажены помехами, что невоз -\\nможно найти гиперплоскость, четко разделяющую положительные и отрица-\\nтельные данные?\\n2. Что если данные нельзя разделить с помощью плоскости, но можно с помощью \\nполинома более высокого порядка?\\nОбе эти ситуации изображены на рис. 3.5. Слева показан случай, когда данные \\nнельзя разделить прямой линией из-за шума (аномальных выбросов или непра -\\nвильно размеченных данных). Справа границей решения является окружность, \\nа не прямая линия.\\nНапомню, что, используя метод опорных векторов, мы должны удовлетворить \\nследующие ограничения:\\n wxi – b ≥ + 1, если yi  = +1,  \\n wxi – b ≤ –1, если yi  = –1.  \\n(3.8)\\nТакже мы должны минимизировать || w||, чтобы гиперплоскость была одинаково \\nудалена от ближайших данных каждого класса. Минимизация || w|| эквивалентна \\nминимизации \\n , и использование этого члена позволит нам в дальнейшем \\nвыполнять оптимизацию квадратичного программирования. Соответственно, за-\\nдача оптимизации в SVM выглядит следующим образом:\\n \\n .  (3.9)'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='54   Глава 3. Фундаментальные алгоритмы\\nРис. 3.5. Случаи, неразделимые линейно. Сверху: присутствует шум.  \\nСнизу: естественная нелинейность\\n3.4.1. Работа с шумом\\nЧтобы распространить SVM на случаи, когда данные невозможно разделить \\nлинейно, введем кусочно\\xadлинейную функцию потерь  (hinge loss function): \\nmax (0,1 – yi (wxi – b)).\\nКусочно-линейная функция потерь равна нулю, если выполнены условия 3.8, то \\nесть если wxi лежит с правильной стороны от границы решения. Для данных, ле-\\nжащих с неправильной стороны, значение функции пропорционально расстоянию \\nот границы решения.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='3.4. Метод опорных векторов   55\\nЗатем минимизируем следующую функцию стоимости:\\n,\\nгде гиперпараметр C определяет компромисс между увеличением размера грани-\\nцы решения и гарантией местонахождения каждого xi с правильной стороны от \\nграницы решения. Значение C обычно выбирается экспериментально, как и ги-\\nперпараметры ϵ и d в ID3.\\nАлгоритм SVM, оптимизирующий кусочно-линейную функцию потерь, называ -\\nют алгоритмом SVM с мягким зазором (soft-margin SVM), тогда как алгоритм \\nв оригинальной формулировке называют алгоритмом SVM с жестким зазором \\n(hard-margin SVM).\\nКак нетрудно заметить, при достаточно высоких значениях C второй член в функ-\\nции стоимости становится пренебрежимо малым, поэтому алгоритм SVM будет \\nпытаться найти наибольший зазор, полностью игнорируя ошибочную классифи-\\nкацию. По мере уменьшения значения C ошибки классификации становятся более \\nдорогостоящими, поэтому алгоритм SVM будет пытаться делать меньше ошибок, \\nжертвуя размером зазора. Как уже говорилось, больший зазор дает лучшее обоб-\\nщение. Следовательно, C регулирует компромисс между хорошей классификацией \\nобучающих данных (минимальный эмпирический риск) и хорошей классифика-\\nцией данных в будущем (обобщение).\\n3.4.2. Работа с естественной нелинейностью\\nSVM можно адаптировать для работы с наборами данных, которые нельзя раз -\\nделить гиперплоскостью в исходном пространстве. Действительно, если удастся \\nпреобразовать исходное пространство в пространство более высокой размерности, \\nможно надеяться, что данные станут линейно разделимыми в этом преобразован-\\nном пространстве. Использование функции для неявного преобразования исход-\\nного пространства в пространство более высокой размерности в ходе оптимизации \\nфункции стоимости в SVM называется ядерным трюком (kernel trick).\\nНа рис. 3.6 показан эффект применения ядерного трюка. Как видите, двумерные \\nданные, не разделимые линейно, можно преобразовать в линейно разделимые \\nтрехмерные данные, используя специальное отображение \\n , где \\n — вектор с более высокой размерностью, чем x. Например, к двумерным \\nданным, изображенным на рис. 3.5 (справа), можно применить отображение, \\nпроеци рующее двумерные данные x = [q, p] в трехмерное пространство (рис. 3.6), \\nко торое выглядит т ак: \\n , где \\n  — это возведение в ква-'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='56   Глава 3. Фундаментальные алгоритмы\\nдрат. После преобразования данные становятся линейно разделимыми в новом \\nпространстве.\\nРис. 3.6. Данные, представленные на рис. 3.5 (снизу), становятся линейно разделимыми \\nпосле преобразования в трехмерное пространство\\nОднако заранее неизвестно, какое отображение подойдет для наших данных. \\nЕсли преобразовывать все входные данные в векторы с более высокой размер -\\nностью и применять к ним SVM, опробуя все возможные функции отображения, \\nвычисления могут стать очень неэффективными и мы никогда не решим задачу \\nклассификации.\\nК счастью, ученые выяснили, как использовать функции ядр\\ue088а (или просто \\ue088ядра) \\nдля эффективной работы в многомерных пространствах без явного преобразова-\\nния. Чтобы понять, как работают ядра, прежде нужно посмотреть, как алгоритм \\nоптимизации для SVM находит оптимальные значения для w и b.\\nДля решения задачи оптимизации в уравнении 3.9 традиционно используется ме\\xad\\nтод множителей Лагранжа. Вместо оригинальной задачи из уравнения 3.9 проще \\nрешить эквивалентную задачу, сформулированную так:\\nгде αi называются множителями Лагранжа. В такой формулировке задача \\nоптимизации превращается в выпуклую задачу квадратичной оптимизации, \\nкоторая эффективно решается применением алгоритмов квадратичного про -\\nграммирования.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='3.5. Метод k ближайших соседей   57\\nОбратите внимание, что в формулировке выше присутствует член xi xk, это един-\\nственное место, где используются векторы признаков. Чтобы преобразовать ис -\\nходное векторное пространство в пространство с большим числом измерений, \\nнужно преобразовать xi в ϕ(xi) и xk в ϕ(xk), а затем перемножить ϕ(xi) и ϕ(xk). Эти \\nвычисления могут оказаться очень дорогостоящими.\\nС другой стороны, нас интересует только результат скалярного произведения xixk, \\nкоторый, как мы знаем, является действительным числом. Нам все равно, как будет \\nполучено это число, лишь бы оно было верным. Используя функцию ядра, можно \\nизбавиться от дорогостоящего преобразования исходных векторов признаков \\nв векторы с более высокой размерностью и избежать необходимости вычислять \\nих скалярное произведение. Мы заменим эти вычисления простой операцией с ис-\\nходными векторами признаков, которая даст тот же результат. Например, вместо \\nпреобразования \\n  в \\n  и \\n  в \\n  и последу-\\nющего вычисления скалярного произведения \\n  и \\n , \\nчтобы получить \\n , можно найти скалярное произведение \\n и \\n , чтобы получить \\n , а затем возвести в квадрат, чтобы \\nполучить тот же результат \\n .\\nЭто был пример функции ядра, и мы использовали квадратичное ядро \\n. Существует несколько функций ядра, из которых наиболее \\nшироко используется ядро RBF:\\n,\\nгде \\n  — квадрат евклидова расстояния между двумя векторами признаков. \\nЕвклидово расстояние определяется следующим уравнением:\\nМожно показать, что пространство признаков ядра RBF (Radial Basis Function — \\nрадиальная базисная функция) имеет бесконечное число измерений. Изменяя \\nгиперпараметр σ, аналитик может выбирать между гладкой или изогнутой границей \\nрешения в исходном пространстве.\\n3.5. Метод k ближайших соседей\\nМетод k ближайших соседей (k-Nearest Neighbors, kNN) — это непараметрический \\nалгоритм обучения. В отличие от других алгоритмов обучения, позволяющих от-'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='58   Глава 3. Фундаментальные алгоритмы\\nбрасывать обучающие данные после построения модели, метод kNN сохраняет все \\nобучающие примеры в памяти. Когда появляется новый, ранее не встречавшийся \\nобразец x, алгоритм kNN находит k обучающих данных, наиболее близких к x, \\nи возвращает наиболее часто встречающуюся метку в случае классификации или \\nсреднее значение метки в случае регрессии.\\nБлизость двух данных определяется функцией расстояния. Например, на практике \\nчасто используется евклидово расстояние, показанное выше. Также нередко ис -\\nпользуется еще одна функция расстояния — отрицательное косинусное сходство. \\nКосинусное сходство, которое определяется как\\nявляется мерой сходства направлений двух векторов. Если угол между двумя век-\\nторами равен 0 градусов, значит, они указывают в одном направлении и косинусное \\nсходство равно 1. Если векторы ортогональны, косинусное сходство равно 0. Для \\nвекторов, указывающих в противоположных направлениях, косинусное сходство \\nравно –1. Чтобы использовать косинусное сходство в качестве меры расстояния, \\nего значение нужно умножить на –1. В числе других популярных мер расстояния \\nможно назвать расстояние Чебышева, расстояние Махаланобиса и расстояние \\nХемминга. Выбор меры, а также значения для k должен сделать аналитик перед \\nзапуском алгоритма. То есть все это — гиперпараметры. Меру расстояния также \\nможно вывести из данных. Мы поговорим об этом в главе 10.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='4\\nАнатомия алгоритмов \\nобучения\\n4.1. Строительные блоки \\nалгоритмов обучения\\nЧитая предыдущую главу, вы могли заметить, что все рассмотренные там методы \\nсостоят из трех частей:\\n1. Функция потерь.\\n2. Критерий оптимизации, основанный на функции потерь (например, функция \\nстоимости).\\n3. Процедура оптимизации, использующая обучающие данные для поиска реше-\\nния критерия оптимизации.\\nЭти строительные блоки присутствуют во всех методах обучения. В предыдущей \\nглаве вы видели, что одни методы предполагают явную оптимизацию определен-\\nного критерия (линейная и логистическая регрессия, SVM). Другие, включая об-\\nучение дерева решений и kNN, оптимизируют критерий неявно. Обу чение дерева \\nрешений и kNN являются одними из самых старых методов машинного обучения \\nи были изобретены экспериментально на основе интуитивных представлений, \\nбез наличия конкретных глобальных критериев оптимизации, которые (как это \\nчасто случалось в истории науки) были разработаны позже, чтобы объяснить, как \\nработают эти методы.\\nВ современной литературе по машинному обучению часто можно встретить по -\\nнятия градиентный спуск или стохастический градиентный спуск. Это два наи-\\nболее часто используемых метода оптимизации, которые применяются в случаях \\nиспользования дифференцируемого критерия оптимизации.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='60   Глава 4. Анатомия алгоритмов обучения\\nГрадиентный спуск — это метод итеративной оптимизации для поиска минимума \\nфункции. Чтобы найти локальный минимум функции с использованием градиент-\\nного спуска, нужно выбрать некоторую случайную точку и шагать в направлении \\nотрицательных значений градиента (или аппроксимации градиента) функции \\nв текущей точке.\\nГрадиентный спуск можно использовать для поиска оптимальных параметров \\nлинейной и логистической регрессии, SVM, а также нейронных сетей, которые \\nмы рассмотрим позже. Для многих моделей, таких как логистическая регрессия \\nи SVM, критерий оптимизации является выпуклым. Выпуклые функции имеют \\nтолько один минимум, который является глобальным. Критерии оптимизации \\nдля нейронных сетей не являются выпуклыми, но на практике часто достаточно \\nнайти хотя бы локальный минимум.\\nДавайте посмотрим, как работает градиентный спуск.\\n4.2. Градиентный спуск\\nВ этом разделе я покажу, как градиентный спуск находит решение задачи линейной \\nрегрессии1. Свое описание я проиллюстрирую с помощью кода на Python, а также \\nграфиков, показывающих, как решение улучшается после нескольких итераций \\nградиентного спуска. В примере я использую набор данных с единственным при-\\nзнаком. Однако критерий оптимизации будет иметь два параметра: w и b. Распро-\\nстранение примера на многомерные обучающие данные делается просто: нужно \\nиспользовать переменные w(1), w(2) и b в случае с двумерными данными, w(1), w(2), \\nw(3) и b в случае с трехмерными данными и т. д.\\nЧтобы придать примеру практический характер, я  использую реальный набор \\nданных (его можно найти в вики для книги) со следующими столбцами: ежегод-\\nные расходы различных компаний на рекламу по радио и их ежегодные объемы \\nпродаж в пересчете на проданные штуки. Нам нужно построить регрессионную \\nмодель, которую можно использовать для прогнозирования продаж в зависимо-\\nсти от расходов на рекламу. Каждая строка в наборе данных представляет одну \\nконкретную компанию.\\nВ наборе содержатся данные по 200 компаниям, соответственно, у нас имеется \\n200 обучающих данных в форме (xi, yi) = (Затратыi, Продажиi). На рис. 4.1 по-\\nказана двумерная диаграмма со всеми образцами.\\n1 Как известно, линейная регрессия имеет аналитическое решение. То есть для решения за-\\nдач этого конкретного типа градиентный спуск не требуется. Однако линейная регрессия \\nявляется идеальным примером для объяснения градиентного спуска.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='4.2. Градиентный спуск   61\\nОб ъем продаж, в штуках\\nЗатраты, млн долл.\\nОб ъем продаж как функция от затрат на рекламу по радио\\nРис. 4.1. Исходные данные. Ось Y соответствует объему продаж в штуках  \\n(который мы должны предсказать), ось X соответствует признаку:  \\nзатратам на рекламу по радио в млн долл.\\nКомпания Затраты, M$ Продажи, в штуках\\n1 37.8 22.1\\n2 39.3 10.4\\n3 45.9 9.3\\n4 41.3 18.5\\n... ... ...\\nНапомню, что модель линейной регрессии выглядит следующим образом: \\nf(x) = wx + b. Мы не знаем оптимальных значений w и b и должны определить их \\nиз данных. Для этого мы найдем такие значения w и b, которые минимизируют \\nсреднеквадратичную ошибку:\\nГрадиентный спуск начинается с вычисления частной производной для каждого \\nпараметра:'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='62   Глава 4. Анатомия алгоритмов обучения\\n \\n   (4.1)\\nЧтобы найти частную производную члена (yi – (wx + b))2 относительно w, я при-\\nменил правило дифференцирования сложной функции. Здесь мы имеем составную \\nфункцию f = f2 (f1), где  f1 = yi – (wx + b) и  f2  = f1\\n2. Чтобы найти частную производ-\\nную f относительно w, нужно сначала найти частную производную f относительно \\nf2, которая равна 2(yi – (wx + b)) (из теории вычислений мы знаем, что производная \\n), а затем умножить ее на частную производную yi – (wx + b) относи-\\nтельно w, равную – x. То есть в целом получаем \\n . \\nАналогично вычисляется частная производная l относительно b, \\n .\\nГрадиентный спуск выполняется этапами, или эпохами. В каждой эпохе произво-\\nдится уточнение каждого параметра с использованием всего обучающего набора. \\nВ начале, в первую эпоху, мы инициализируем1 w ← 0 и b ← 0. Частные производ-\\nные, \\n  и \\n , заданные уравнениями 4.1, равны соответственно \\n  и \\n. В каждую эпоху с использованием частных производных производится \\nуточнение w и b. Скорость обучения α контролирует размер уточнения:\\n \\n   (4.2)\\nМы вычитаем частные производные из значений параметров (а не прибавляем), \\nпотому что производные являются индикаторами роста функции. Если производ-\\nная положительна в некоторой точке2, значит, функция возрастает в этой точке. \\n1 В сложных моделях, таких как нейронные сети, имеющих тысячи параметров, инициа -\\nлизация параметров может существенно повлиять на решение, найденное градиентным \\nспуском. Существуют разные методы инициализации (случайными значениями, нулями, \\nнебольшими значениями, близкими к нулю, и т. д.), и этот важный выбор должен сделать \\nаналитик.\\n2 Точка задается текущими значениями параметров.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='4.2. Градиентный спуск   63\\nПоскольку мы минимизируем целевую функцию, для положительного значения \\nпроизводной мы должны скорректировать параметр в противоположном направ-\\nлении (сместить влево на оси координат). Для отрицательного значения производ-\\nной (функция убывает) мы должны сместить параметр вправо, чтобы еще больше \\nуменьшить значение функции. Вычитание отрицательного значения из параметра \\nсмещает его вправо.\\nВ следующую эпоху мы повторно вычисляем производные, используя уравне -\\nние 4.1 с измененными значениями w и b; процесс продолжается до схождения. \\nОбычно требуется пройти много эпох, пока не обнаружится, что значения w и b \\nмало меняются после каждой эпохи; после этого процесс останавливается.\\nТрудно представить инженера по машинному обучению, который не использует \\nязык программирования Python. Поэтому, если вы ждали удобного момента для \\nизучения Python, он настал. Ниже я покажу, как запрограммировать градиентный \\nспуск на Python.\\nНиже показана функция, корректирующая параметры w и b в ходе одной эпохи:\\n 1 def update_w_and_b(spendings, sales, w, b, alpha):\\n 2     dl_dw = 0.0\\n 3     dl_db = 0.0\\n 4     N = len(spendings)\\n 5\\n 6     for i in range(N):\\n 7         dl_dw += -2*spendings[i]*(sales[i] - (w*spendings[i] + b))\\n 8         dl_db += -2*(sales[i] - (w*spendings[i] + b))\\n 9\\n10     # скорректировать w и b\\n11     w = w - (1/float(N))*dl_dw*alpha\\n12     b = b - (1/float(N))*dl_db*alpha\\n13\\n14     return w, b\\nДалее показана функция, которая в цикле выполняет множество эпох:\\n15 def train(spendings, sales, w, b, alpha, epochs):\\n16     for e in range(epochs):\\n17         w, b = update_w_and_b(spendings, sales, w, b, alpha)\\n18\\n19         # вывести информацию о продвижении вперед\\n20         if e % 400 == 0:\\n21             print(\"epoch:\", e, \"loss: \", avg_loss(spendings, sales, w, b))\\n22\\n23     return w, b'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='64   Глава 4. Анатомия алгоритмов обучения\\n       \\nЭпоха 0                                                                                 Эпоха 400\\n       \\nЭпоха 800                                                                             Эпоха 1200\\n         \\nЭпоха 1600                                                                 Эпоха 3000\\nРис. 4.2. Эволюция линии регрессии с течением эпох градиентного спуска'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='4.2. Градиентный спуск   65\\nФункция avg_loss, используемая в листинге выше, вычисляет среднеквадратичную \\nошибку. Вот как она определяется:\\n25 def avg_loss(spendings, sales, w, b):\\n26     N = len(spendings)\\n27     total_error = 0.0\\n28     for i in range(N):\\n29         total_error += (sales[i] - (w*spendings[i] + b))**2\\n30     return total_error / float(N)\\nЕсли вызвать функцию train  с параметрами alpha  = 0.001, w = 0.0, b = 0.0 \\nи epochs = 15000, мы увидим следующие результаты (показана лишь часть из них):\\nepoch: 0 loss: 92.32078294903626\\nepoch: 400 loss: 33.79131790081576\\nepoch: 800 loss: 27.9918542960729\\nepoch: 1200 loss: 24.33481690722147\\nepoch: 1600 loss: 22.028754937538633\\n...\\nepoch: 2800 loss: 19.07940244306619\\nКак видите, средняя потеря уменьшается по мере прохождения функции train \\nчерез эпохи. На рис. 4.2 показано, как эволюционировала линия регрессии с те-\\nчением эпох.\\nНаконец, после получения оптимальных значений параметров w и b нам недостает \\nтолько функции, выполняющей предсказание:\\n31 def predict(x, w, b):\\n32     return w*x + b\\nПопробуйте выполнить следующий код:\\n33 w, b = train(x, y, 0.0, 0.0, 0.001, 15000)\\n34 x_new = 23.0\\n35 y_new = predict(x_new, w, b)\\n36 print(y_new)\\nОн должен вывести 13.97.\\nГрадиентный спуск чувствителен к выбору скорости обучения α. Кроме того, он \\nмедленно сходится на больших наборах данных. К счастью, было предложено не-\\nсколько существенных улучшений этого алгоритма.\\nМини\\xadпакетный стохастический градиентный спуск (Minibatch Stochastic Gradient \\nDescent, minibatch SGD) — это версия алгоритма, ускоряющая вычисления за счет \\nаппроксимации градиента с использованием небольших пакетов (подмножеств) \\nобучающих данных. Сам алгоритм SGD тоже включает различные «усовершенство-'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='66   Глава 4. Анатомия алгоритмов обучения\\nвания». Метод адаптивного градиента (adagrad) — это версия SGD, которая масшта-\\nбирует α для каждого параметра в соответствии с историей градиентов. В результате \\nα уменьшается при очень больших градиентах и наоборот. Метод моментов — это \\nметод, позволяющий ускорить SGD за счет ориентации градиентного спуска в соот-\\nветствующем направлении и уменьшения колебаний. В обучении нейронных сетей \\nтакже часто используются такие варианты SGD, как RMSprop и Adam.\\nОбратите внимание, что градиентный спуск и его варианты не являются алго -\\nритмами машинного обучения. Они решают задачи минимизации, в которых \\nминимизируемая функция имеет градиент (в большинстве точек в своей области \\nопределения).\\n4.3. Как работают инженеры, занимающиеся \\nмашинным обучением\\nЕсли вы не научный сотрудник и не работаете в крупной компании с большим \\nбюджетом, выделяемым на научные исследования и разработки, вам едва ли при-\\nдется самим заниматься реализацией алгоритмов машинного обучения. Вам не \\nпридется заниматься реализацией градиентного спуска или любого другого метода \\nоптимизации. Вы, скорее всего, будете использовать библиотеки, большинство из \\nкоторых распространяется с открытым исходным кодом. Библиотека — это кол-\\nлекция алгоритмов и вспомогательных инструментов, отличающаяся надежностью \\nи эффективностью. На практике чаще всего используется библиотека машинного \\nобучения с открытым исходным кодом — scikit-learn. Она написана на Python и C. \\nВот как можно реализовать линейную регрессию с использованием scikit-learn:\\n 1 def train(x, y):\\n 2     from sklearn.linear_model import LinearRegression\\n 3     model = LinearRegression().fit(x,y)\\n 4     return model\\n 5\\n 6 model = train(x,y)\\n 7\\n 8 x_new = 23.0\\n 9 y_new = model.predict(x_new)\\n10 print(y_new)\\nВ результате вы получите тот же результат 13.97. Легко, да? При желании вы мо-\\nжете заменить LinearRegression другим алгоритмом обучения регрессии, ничего \\nне меняя в остальном коде. Все просто. То же можно сказать о классификации. Вы \\nлегко сможете заменить алгоритм LogisticRegression алгоритмом SVC (именно \\nтак называется реализация метода опорных векторов в библиотеке scikit-learn),'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='4.4. Особенности алгоритмов обучения   67\\nDecisionTreeClassifier, NearestNeighbors и многими другими алгоритмами клас-\\nсификации, реализованными в scikit-learn.\\n4.4. Особенности алгоритмов обучения\\nЗдесь я отмечу некоторые практические особенности, отличающие один алгоритм \\nобучения от другого. Вы уже знаете, что разные алгоритмы обучения могут иметь \\nразные гиперпараметры (C в SVM, ϵ и d в ID3). Алгоритмы оптимизации, такие \\nкак градиентный спуск, тоже могут иметь гиперпараметры, например α.\\nНекоторые алгоритмы, такие как обучение дерева решений, могут принимать ка-\\nчественные признаки. Например, если в наборе данных имеется признак «цвет», \\nпринимающий такие значения, как «красный», «желтый» или «зеленый», вы мо-\\nжете оставить его как есть. Но SVM, логистическая и линейная регрессия, а также \\nkNN (с метриками косинусного сходства или евклидова расстояния) ожидают, \\nчто все признаки будут иметь числовые значения. Все алгоритмы, реализованные \\nв scikit-learn, работают только с числовыми признаками. В следующей главе я по-\\nкажу, как преобразовать качественные признаки в числовые.\\nНекоторые алгоритмы, такие как SVM, позволяют аналитикам добавлять весовые \\nкоэффициенты для каждого класса. Эти весовые коэффициенты влияют на опре-\\nделение границы решения. Если какой-либо класс имеет большой вес, алгоритм \\nобучения постарается не допускать ошибок в классификации обучающих данных, \\nпринадлежащих этому классу (обычно за счет ошибок в других данных). Это может \\nбыть важно, если представители какого-то класса находятся в меньшинстве в обу-\\nчающих данных и вам нужно избежать, насколько это возможно, неправильной \\nих классификации.\\nНекоторые модели классификации, такие как SVM и kNN, выводят для заданного \\nвектора признаков только класс. Другие, такие как логистическая регрессия или \\nдеревья решений, также могут возвращать оценку от 0 до 1, которую можно ин -\\nтерпретировать как степень уверенности модели в прогнозе или вероятность, что \\nвходной образец принадлежит определенному классу1.\\nНекоторые алгоритмы классификации (например, обучения дерева решений, \\nлогистической регрессии или SVM) строят модель, используя сразу весь набор \\nданных. При появлении дополнительных размеченных данных вам придется \\nпересобрать модель заново. Другие алгоритмы (такие как наивный байесов -\\n1 При необходимости оценку для прогнозов SVM и kNN можно сгенерировать искусственно, \\nиспользовав несложные методы.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='68   Глава 4. Анатомия алгоритмов обучения\\nский классификатор, многослойный персептрон, SGDClassifier/SGDRegressor, \\nPassiveAggressiveClassifier/PassiveAggressiveRegressor в scikit-learn) могут \\nобучаться итеративно, принимая обучающие данные пакетами. При появлении \\nновых обучающих данных вы можете обновить модель, использовав только новые \\nданные.\\nНаконец, некоторые алгоритмы, такие как обучение дерева решений, SVM и kNN, \\nмогут использоваться как для классификации, так и для регрессии, в то время как \\nдругие способны решать только задачи одного вида: либо классификацию, либо \\nрегрессию, но не обе.\\nОбычно каждая библиотека сопровождается документацией, где объясняется, ка-\\nкую задачу решает каждый алгоритм, какие входные значения допустимы и что воз-\\nвращает модель. Документация также содержит информацию о гиперпараметрах.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='5 Практические основы\\nДо сих пор я лишь мимоходом упомянул некоторые проблемы, которые аналитик \\nдолжен учитывать, работая над задачей машинного обучения: проектирование при-\\nзнаков, переобучение и настройка гиперпараметров. В этой главе мы поговорим об \\nэтих и других проблемах, которые необходимо разрешить, прежде чем вы сможете \\nввести инструкцию model = LogisticRegression().fit(x, y).\\n5.1. Проектирование признаков\\nКогда менеджер по продукту говорит вам: «Нужно предсказать, останется ли у нас \\nконкретный клиент. Вот вам журналы, фиксирующие взаимодействия клиента \\nс нашим продуктом за пять лет», — вы не сможете просто взять эти данные, пере-\\nдать их библиотеке и получить прогноз. Вы должны сначала сконструировать \\nнабор данных.\\nКак рассказывалось в первой главе, набор данных — это коллекция размеченных \\nобразцов \\n . Каждый элемент xi из N называется вектором признаков. \\nВектор признаков — это вектор, в котором каждое измерение j = 1, ..., D содержит \\nзначение, которое как-то описывает образец. Это значение называется признаком \\nи обозначается как x(j).\\nПроблема преобразования исходной информации в набор данных называется \\nпроектированием признаков . В большинстве случаев проектирование призна -\\nков — трудоемкий процесс, требующий от аналитика творческого подхода и, пред-\\nпочтительно, знания предметной области.\\nНапример, для преобразования журналов, фиксирующих взаимодействия пользо-\\nвателя с компьютерной системой, можно создать признаки, содержащие различную \\nстатистическую информацию о пользователе, извлеченную из журналов. К при -'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='70   Глава 5. Практические основы\\nмеру, один признак мог бы содержать цену подписки; другие признаки — частоту \\nсоединений в день, неделю и год. Еще один признак мог бы содержать среднюю \\nпродолжительность сеанса в секундах или среднее время ответа на один запрос \\nи т. д. Все, что доступно для измерения, можно использовать как признак. Задача \\nаналитика — создать информативные  признаки, которые позволят алгоритму \\nобучения построить модель, хорошо предсказывающую метки в обучающих дан-\\nных. Высокоинформативные признаки также называют признаками с  большой \\nпрогнозирующей способностью. Например, средняя продолжительность сеанса \\nпользователя имеет высокую прогнозирующую способность для предсказания — \\nбудет ли пользователь продолжать использовать приложение в будущем.\\nМы говорим, что модель имеет малое смещение, если она дает хорошие результаты на \\nобучающих данных. То есть модель делает немногочисленные ошибки, когда приме-\\nняется для прогнозирования меток данных, использованных для построения модели.\\n5.1.1. Унитарное кодирование\\nНекоторые алгоритмы обучения работают только с векторами числовых признаков. \\nЕсли какой-то признак в наборе данных является качественным, например «цвет» \\nили «день недели», его можно преобразовать в несколько бинарных признаков.\\nЕсли образец имеет качественный признак «цвет» с тремя возможными значени-\\nями: «красный», «желтый», «зеленый», его можно преобразовать в вектор с тремя \\nчисловыми значениями с помощью унитарного кодирования (известного также \\nкак кодирование с одним активным состоянием, one-hot encoding):\\n красный = [1, 0, 0]  \\n желтый = [0, 1, 0]  \\n зеленый = [0, 0, 1].  \\n(5.1)\\nТакой подход увеличивает размерность векторов признаков. Не следует пытать -\\nся уменьшить размерность, преобразовав значение «красный» в 1, «желтый» в 2 \\nи «зеленый» в 3, потому что это будет означать наличие упорядоченности в этой \\nкатегории и важность этого конкретного порядка для принятия решений. Если \\nпорядок значений признака неважен, использование упорядоченных чисел в ка-\\nчестве значений может запутать алгоритм обучения1, потому что алгоритм будет \\n1 Когда порядок значений некоторого качественного признака действительно имеет значе-\\nние, тогда можно заменить эти значения порядковыми числами, оставив единственный \\nпризнак. Например, если признак представляет качество статьи и имеет значения {плохо, \\nудовлетворительно, хорошо, отлично}, тогда можно заменить эти качественные значения \\nчислами, например {1, 2, 3, 4}.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='5.1. Проектирование признаков   71\\nпытаться найти упорядоченность там, где ее нет, что потенциально может привести \\nк переобучению.\\n5.1.2. Биннинг\\nПротивоположная ситуация, реже встречающаяся на практике, — когда имеется чис-\\nловой признак, но его хотелось бы преобразовать в качественный. Биннинг (binning, \\nв литературе также встречается bucketing или просто дискретизация) — это про-\\nцесс преобразования признака с непрерывным диапазоном значений в несколько \\nбинарных признаков, которые иногда называют корзинами (или категориями), \\nобычно с разбивкой по диапазонам. Например, вместо представления возраста, \\nкак единственного действительного признака, аналитик мог бы разбить возраст на \\nдискретные диапазоны: все возрасты от 0 до 5 лет могут быть объединены в одну \\nкатегорию, от 6 до 10 лет — во вторую категорию, от 11 до 15 лет — в третью, и т. д.\\nНапример, пусть признак j = 4 представляет возраст. Применяя биннинг, признак \\nможно заменить соответствующими категориями. Допустим, мы добавили три \\nновые категории, «age_bin1», «age_bin2» и «age_bin3», с индексами j = 123, j = 124 \\nи j = 125 соответственно. Теперь, если для некоторого образца xi признак \\n , \\nтогда мы можем установить признак \\n ; если \\n  — установить признак \\n и т. д.\\nВ некоторых случаях хорошо продуманная дискретизация может помочь алгоритму \\nобучиться на меньшем количестве данных, потому что, используя такой подход, \\nмы «подсказываем» алгоритму обучения, что если значение признака попадает \\nв определенный диапазон, точное значение этого признака не имеет значения.\\n5.1.3. Нормализация\\nНормализация — это процесс преобразования фактического диапазона значений \\nчислового признака в стандартный диапазон значений, обычно в интервале [–1, 1] \\nили [0, 1].\\nНапример, предположим, что естественные значения некоторого признака изме-\\nняются в диапазоне от 350 до 1450. Вычитая 350 из каждого значения признака \\nи деля результат на 1100, можно нормализовать эти значения, преобразовав их \\nв диапазон [0, 1].\\nВ общем случае формула нормализации выглядит так:'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='72   Глава 5. Практические основы\\nгде min(j) и max(j) — минимальное и максимальное значения признака j в наборе \\nданных соответственно.\\nЗачем нужна нормализация? Нормализация данных не является строгим тре -\\nбованием. Однако на практике она может способствовать увеличению скорости \\nобучения. Вспомните пример градиентного спуска из предыдущей главы. Пред -\\nставьте, что у вас есть двумерный вектор признаков. Корректируя параметры w(1) \\nи w(2), вы используете частные производные среднеквадратичной ошибки отно -\\nсительно w(1) и w(2). Если x(1) находится в диапазоне [0, 1000], а x(2) — в диапазоне \\n[0, 0.0001], то при корректировке будет преобладать производная по признаку \\nс большим значением.\\nКроме того, часто полезно гарантировать относительно небольшой диапазон и при-\\nмерно одинаковые изменения входных данных, чтобы избежать проблем, которые \\nвозникают у компьютеров при работе с очень маленькими или очень большими \\nчислами (так называемое числовое переполнение).\\n5.1.4. Стандартизация\\nСтандартизация (или нормализация z\\xadоценки) — это процедура, в ходе которой \\nзначения признаков масштабируются таким образом, что приобретают свойства \\nстандартного нормального распределения с μ = 0 и σ = 1, где μ — среднее значение \\nпризнака (усредняется по всем образцам в наборе данных), а σ — стандартное от-\\nклонение от среднего. \\nСтандартные оценки (или z-оценки) признаков вычисляются следующим образом:\\nВозникает вопрос, когда следует использовать нормализацию, а когда стандарти-\\nзацию. На этот вопрос нет однозначного ответа. Обычно, если набор данных не \\nслишком большой и есть время, можно попробовать оба варианта и посмотреть, \\nкакой лучше подходит для решаемой задачи.\\nЕсли нет времени на эксперименты, используйте следующие эмпирические пра -\\nвила:\\n  в алгоритмах обучения без учителя на практике чаще выгоднее использовать \\nстандартизацию, а не нормализацию;\\n  стандартизация также предпочтительнее для признаков, распределение зна -\\nчений которых близко к нормальному распределению (то есть если график \\nраспределения имеет колоколообразную форму);'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='5.1. Проектирование признаков   73\\n  и снова стандартизация предпочтительнее для признаков, которые иногда мо-\\nгут иметь экстремально большие или экстремально малые (аномальные) зна -\\nчения; предпочтительность стандартизации объясняется тем, что нормализа -\\nция «втискивает» нормальные значения в очень узкий диапазон;\\n  во всех остальных случаях предпочтительнее нормализация.\\nМасштабирование признаков обычно хорошо сказывается на большинстве алго -\\nритмов обучения. Однако современные реализации алгоритмов, которые можно \\nнайти в популярных библиотеках, вполне устойчивы к признакам с разными диа-\\nпазонами значений.\\n5.1.5. Работа с отсутствующими значениями признаков\\nИногда аналитик получает данные в виде набора с уже определенными признаками. \\nВ некоторых образцах значения отдельных признаков могут отсутствовать. Это \\nчасто случается, когда набор данных создавался вручную, и человек, работавший \\nс ним, забывал заполнять некоторые значения или вообще не измерял их.\\nВот несколько типичных способов работы с отсутствующими значениями при -\\nзнаков:\\n  удалить данные с отсутствующими значениями признаков из набора дан -\\nных (этот способ можно использовать, если набор данных достаточно велик \\nи можно пожертвовать несколькими обучающими образцами);\\n  использовать алгоритм обучения, умеющий работать с отсутствующими зна-\\nчениями (зависит от библиотеки и конкретной реализации алгоритма);\\n  использовать вычислительные методы восстановления данных.\\n5.1.6. Методы восстановления данных\\nОдин из методов восстановления данных заключается в замене отсутствующего \\nзначения признака средним значением, вычисленным по всему набору данных:\\nДругой метод заключается в замене отсутствующего значения значением, выхо -\\nдящим за пределы диапазона нормальных значений. Например, если нормальные \\nзначения находятся в диапазоне [0, 1], отсутствующее значение можно установить \\nравным 2 или –1. Идея состоит в том, чтобы позволить алгоритму обучения само-\\nму решить, как лучше поступить, если значение признака значительно отличается'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='74   Глава 5. Практические основы\\nот типичных значений. Как вариант, отсутствующее значение можно заменить \\nзначением середины диапазона. Например, если значения признака находятся \\nв диапазоне [–1, 1], отсутствующее значение можно установить равным 0. В дан-\\nном случае идея заключается в том, что значение середины диапазона не окажет \\nзначительного влияния на прогноз.\\nБолее продвинутый метод — решить задачу регрессии, использовав отсутствую -\\nщее значение в качестве целевой переменной. Используя все остальные признаки \\n, можно сформировать вектор признаков \\n , \\nустановить \\n , где j — признак с отсутствующим значением. Затем построить \\nрегрессионную модель для прогнозирования \\n  по \\n . Разумеется, для построения \\nобучающих данных \\n  должны использоваться только те данные из исходного \\nнабора данных, в которых присутствует значение признака j.\\nНаконец, если имеется достаточно большой набор данных и значения отсутствуют \\nлишь в нескольких признаках, можно увеличить размерность векторов признаков, \\nдобавив бинарный признак для каждого признака с отсутствующими значениями. \\nНапример, пусть в D-мерном наборе данных признак j = 12 имеет отсутствующие \\nзначения. Для каждого вектора признаков x тогда можно добавить признак j = D + 1 \\nсо значением 1, если значение 12-го признака присутствует в x, и 0 в противном \\nслучае. Тогда недостающее значение можно заменить нулем или любым другим \\nчислом по вашему выбору.\\nНа этапе прогнозирования, если образец имеет отсутствующее значение, следует \\nиспользовать тот же метод восстановления данных, который применялся к обуча-\\nющим данным, чтобы заполнить недостающие значения признаков.\\nЗаранее нельзя сказать, какой метод восстановления данных окажется лучшим \\nв конкретной ситуации. Попробуйте применить несколько методов, постройте \\nнесколько моделей и выберите ту, которая показывает лучшие результаты.\\n5.2. Выбор алгоритма обучения\\nВыбор алгоритма машинного обучения иногда может оказаться сложной задачей. \\nПри наличии времени можно попробовать их все. Но обычно на решение задачи \\nотводится ограниченное время. Попробуйте задать себе несколько вопросов, пре-\\nжде чем приступить к работе над задачей. В зависимости от ответов вы сможете \\nсузить круг алгоритмов и опробовать их на своих данных.\\n  Объяснимость.\\nНужно ли объяснять вашу модель нетехническим специалистам? Большинство \\nточных алгоритмов обучения — это так называемые «черные ящики». Они'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='5.2. Выбор алгоритма обучения   75\\nобу чают модели, допускающие очень мало ошибок, но иногда очень трудно \\nпонять и еще сложнее объяснить, почему модель сделала тот или иной прогноз. \\nПримерами таких моделей являются нейронные сети и ансамблевые модели.\\nС другой стороны, алгоритмы обучения kNN, линейной регрессии или дерева \\nрешений создают модели, которые дают пусть не всегда самые точные, зато \\nлегко объяснимые результаты.\\n  Возможность сохранения набора данных в оперативной памяти.\\nМожно ли набор данных целиком загрузить в оперативную память сервера или \\nперсонального компьютера? Если да, тогда появляется возможность выбора из \\nширокого спектра алгоритмов. В противном случае предпочтение следует от-\\nдавать инкрементальным алгоритмам обучения, способным совершенствовать \\nмодель постепенно, по мере добавления новых данных.\\n  Число признаков и данных.\\nСколько обучающих данных присутствует в  наборе данных? Сколько при -\\nзнаков имеет каждый образец? Некоторые алгоритмы, включая нейронные \\nсети и градиентный бустинг (мы рассмотрим их позже), могут обрабатывать \\nогромное количество данных с миллионами признаков. Другие, такие как SVM, \\nмогут быть очень ограниченными в этом отношении.\\n  Качественные и количественные признаки.\\nСостоят ли данные только из качественных или только из числовых признаков \\nлибо имеют признаки обоих видов? В зависимости от ответа некоторые алго-\\nритмы могут быть неспособны обработать набор данных непосредственно, и вам \\nпридется преобразовать качественные признаки в числовые.\\n  Нелинейность данных.\\nЯвляются ли данные линейно разделимыми или их можно моделировать с по-\\nмощью линейной модели? Если да, тогда хорошим выбором могут оказаться \\nSVM с линейным ядром, логистическая или линейная регрессия. Иначе более \\nпредпочтительными могут оказаться глубокие нейронные сети или ансамблевые \\nалгоритмы, рассматриваемые в главах 6 и 7.\\n  Скорость обучения.\\nСколько времени можно отпустить алгоритму обучения для построения моде-\\nли? Как известно, нейронные сети обучаются очень долго. Простые алгоритмы, \\nтакие как логистическая и линейная регрессия или деревья решений, действуют \\nнамного быстрее. Специализированные библиотеки содержат очень эффектив-\\nные реализации некоторых алгоритмов; возможно, вы предпочтете поискать'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='76   Глава 5. Практические основы\\nв интернете, чтобы найти такие библиотеки. Некоторые алгоритмы, такие как \\nслучайные леса, при выполнении на многоядерных процессорах могут произ-\\nводить вычисления параллельно, поэтому при наличии десятков ядер способны \\nстроить модели намного быстрее.\\n  Скорость прогнозирования.\\nКак быстро обученная модель должна генерировать прогнозы? Будет ли модель \\nиспользоваться в окружении, где требуется очень высокая пропускная способ-\\nность? Одни алгоритмы, такие как SVM, линейная и логистическая регрессия \\nи нейронные сети (некоторых типов), чрезвычайно быстро генерируют прогноз. \\nДругие, такие как kNN, ансамблевые алгоритмы и очень глубокие или рекур-\\nрентные нейронные сети, работают медленнее1.\\nЧтобы не надеяться на удачу в выборе лучшего алгоритма для ваших данных, мож-\\nно воспользоваться популярным способом: протестировать несколько алгоритмов \\nна контрольном наборе. Мы поговорим об этом далее. В качестве альтернативы \\nпри использовании библиотеки scikit-learn можно попробовать схему выбора \\nалгоритма, показанную на рис. 5.1.\\n5.3. Три набора\\nДо сих пор я использовал выражения «набор данных» и «обучающий набор» \\nвзаимозаменяемо. Однако на практике аналитики работают с тремя наборами \\nразмеченных данных:\\n1. Обучающий набор.\\n2. Контрольный набор.\\n3. Тестовый набор.\\nПосле получения набора размеченных данных первое, что следует сделать, — пере-\\nмешать данные и разбить их на три выборки: обучающую, контрольную и тестовую. \\nОбучающая выборка обычно самая большая; она используется для построения \\nмодели. Выборки для проверки и тестирования имеют примерно одинаковые \\nразмеры и намного меньше обучающей выборки. Алгоритм обучения не должен \\nиспользовать данные из этих двух выборок для построения модели. Вот почему \\nэти две выборки часто называют отложенными выборками (holdout sets).\\n1 Скорость прогнозирования kNN и ансамблевых методов, реализованных в современных \\nбиблиотеках, достаточно высока, поэтому не бойтесь использовать эти алгоритмы в своей \\nпрактике.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='Памятка по выбору \\nалгоритма в scikit-lear n\\nКлассификация\\nРегрессия\\nСниж ение\\nразмерности\\nКластеризация\\nАнсамблевые\\nклассификаторы\\nЯдерная\\nаппроксимация\\nЯдерная\\nаппроксимация\\nНЕ ПОД ХО ДИТ\\nНЕ ПОД ХО ДИТ\\nНЕ ПОД ХО ДИТ\\nНЕ ПОД ХО ДИТ\\nНЕ ПОД ХО ДИТ\\nНЕ ПОД ХО ДИТ\\nНЕ ПО ДХ ОД ИТ\\nНаивный\\nБайес\\nКлассификатор\\nпо k б лижайшим\\nсоседям\\nТекстовые данные\\nДА\\nДА\\nДА\\nДА\\nДА\\nДА\\nДА\\nДА\\nДА\\nДА\\nДА\\nДАДА\\nНЕТ\\nНЕТ\\nНЕТ\\nНЕТ\\nНЕТ\\nНЕТ\\nНЕТ\\nНЕТ\\nНЕТ\\nНЕТ\\nНЕТ\\nНЕТ\\nНЕТ\\nЛинейный\\nМОВ\\n<100К данных\\nСобрать\\nбольше\\nданных\\nНА ЧАЛО\\n>50 данных\\nПредсказание\\nкатегории\\nЕсть размеченные\\nданные\\nПредсказание\\nколичественного\\nзначения\\nТолько\\nдля обзора\\nПрогнозирование\\nструктуры\\nНеудача\\nСпектральная\\nкластеризация Ме тод k\\nсреднихGMM\\nVBGMM\\n<10 данных\\n<10 данных\\n<10 данных\\n<100 данны х\\nМини-пак етный\\nметод k сре дних Сдвиг среднего\\nЧисло категорий\\nизвестно\\nРегрессор СГС\\nЛассо\\nЭластичная сеть\\nАнсамблевые регрессоры\\nГребневая регрессия\\nНекоторые признаки\\nважнее других\\nРандомизиро-\\nванный МГ К\\nСпектральное\\nвложение\\nSVR(kernel=’liner ’)\\nSVR(kernel=’rbf ’)\\nLLE\\nIsomap\\nКлассифика-\\nтор СГ С\\nМОВ\\nРис. 5.1. Диаграмма выбора машинного алгоритма из имеющихся  \\nв библиотеке scikit-learn'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='78   Глава 5. Практические основы\\nНе существует оптимальной пропорции деления исходного набора данных на \\nтри выборки. В прошлом широко применялось эмпирическое правило, согласно \\nкоторому 70 % исходных данных использовались для обучения, 15 % для проверки \\nи 15 % для тестирования. Однако в эпоху больших данных наборы часто включают \\nмиллионы образцов. В таких случаях разумнее оставить 95 % для обучения и по \\n2.5 % выделить для контроля/тестирования.\\nВозможно, вам интересно, почему нужно использовать три выборки, а не одну. \\nОтвет прост: нежелательно, чтобы модель давала хорошие прогнозы только для \\nданных, которые алгоритм видел в процессе обучения. Тривиальный алгоритм, \\nпросто запоминающий все обучающие данные, а затем использующий память, \\nчтобы «предсказать» их метки, не будет ошибаться, предсказывая метки обучаю-\\nщих данных, но такой алгоритм бесполезен на практике. В действительности нам \\nнужно, чтобы модель давала достаточно точные прогнозы для данных, которые \\nалгоритм обучения не видел: нам нужна высокая эффективность на отложенной  \\nвыборке.\\nЗачем же нужны две контрольные выборки, а не одна? Контрольная выборка ис-\\nпользуется для: 1) выбора алгоритма обучения и 2) поиска оптимальных значений \\nгиперпараметров. Тестовая выборка используется для оценки модели перед пере-\\nдачей ее клиенту или запуском в продакшн.\\n5.4. Недообучение и переобучение\\nВыше я упомянул понятие смещения. Я говорил, что модель имеет малое смещение, \\nесли дает хорошие результаты на обучающих данных. Если модель допускает много \\nошибок на обучающих данных, мы говорим, что модель имеет большое смещение \\nили что модель недообучена. Недообученность — это неспособность модели более \\nили менее точно предсказывать метки данных, на которых она обучалась. Причин \\nнедообучения может быть несколько, наиболее важными из них являются:\\n  модель слишком проста для данных (например, линейные модели часто стра-\\nдают недообученностью);\\n  спроектированные вами признаки недостаточно информативны.\\nПервую причину легко показать на примере одномерной регрессии: набор дан -\\nных может напоминать изогнутую линию, а модель описывает прямую линию. \\nВторую причину можно проиллюстрировать так: допустим, требуется пред -\\nсказать наличие у пациента рака; в вашем распоряжении есть такие признаки, \\nкак рост, кровяное давление и  частота сердечных сокращений. Очевидно, что \\nэти три признака не являются хорошими прогностическими признаками рака,'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='5.4. Недообучение и переобучение   79\\nпоэтому модель, использующая их, не сможет выявить значимые связи между \\nэтими признаками и метками.\\nЧтобы решить проблему недообучения, можно попробовать использовать более \\nсложную модель или спроектировать признаки с более высокой прогнозирующей \\nспособностью.\\nПереобучение — другая проблема, которой может страдать модель. Переобученная \\nмодель слишком хорошо предсказывает обучающие данные, но плохо — данные из \\nобеих контрольных выборок или хотя бы из одной из них. Я уже приводил пример \\nпереобучения в главе 3. Причин переобучения может быть несколько, наиболее \\nважными из них являются:\\n  модель слишком сложна для данных (например, очень высокое дерево реше -\\nний или очень глубокая или широкая нейронная сеть часто бывают переобу-\\nчены);\\n  слишком много признаков, но мало обучающих данных.\\nВ литературе можно встретить другое название проблемы переобучения: про -\\nблема высокой дисперсии. Этот термин происходит из статистики. Дисперсия — \\nэто ошибка модели, вызванная ее чувствительностью к небольшим колебаниям \\nв обучающем наборе. Если обучающие данные отобрать чуть иначе, в результате \\nможет получиться совершенно другая модель. Вот почему переобученная модель \\nпоказывает плохие результаты на тестовых данных: тестовые и обучающие данные \\nвыбираются из исходного набора данных независимо друг от друга.\\nДаже самую простую линейную модель можно переобучить. Обычно такое проис-\\nходит, когда данные многомерны, а количество обучающих данных относительно \\nневелико. Фактически, когда векторы признаков слишком многомерны, линейный \\nалгоритм обучения может построить модель, которая присваивает ненулевые зна-\\nчения большинству элементов w(j) в векторе параметров w, пытаясь учесть очень \\nсложные взаимосвязи между всеми доступными признаками, чтобы предсказать \\nметки обучающих данных максимально точно.\\nТакая сложная модель, скорее всего, будет плохо предсказывать метки контрольных \\nданных. Это связано с тем, что, пытаясь точно предсказать метки всех обучающих \\nданных, модель также изучит специфические особенности обучающего набора: \\nшум в значениях признаков обучающих данных, несовершенство выборки из-за \\nмалого размера набора данных и другие артефакты, не свойственные решаемой \\nзадаче, но присутствующие в обучающем наборе.\\nНа рис. 5.2 изображен набор одномерных данных, для которого созданы недообу-\\nченная, хорошо обученная и переобученная регрессионные модели.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='80   Глава 5. Практические основы\\nстепень 1 (недообучение)\\nтрениров очные образцы\\n        \\nстепень 2 (обучение)\\nтрениров очные образцы\\nНедообучение                                                       Хорошее обучение\\nстепень 15 (переобучение)\\nтрениров очные образцы\\nПереобучение\\nРис. 5.2. Примеры недообучения (линейная модель), хорошего обучения  \\n(квадратичная модель) и переобучения (полином степени 15)\\nВот некоторые методы борьбы с переобучением:\\n1. Попробовать более простую модель (линейную регрессию вместо полиноми -\\nальной, метод опорных векторов (SVM) с линейным ядром вместо радиальных \\nбазисных функций (RBF), нейронную сеть с меньшим числом слоев/узлов).\\n2. Уменьшить размерность данных в наборе данных (например, с помощью одного \\nиз методов уменьшения размерности, рассматриваемых в главе 9).\\n3. Добавить больше обучающих данных, если возможно.\\n4. Применить регуляризацию к модели.\\nРегуляризация — один из самых широко используемых приемов в борьбе с пере-\\nобучением.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='5.5. Регуляризация   81\\n5.5. Регуляризация\\nРегуляризация — это собирательный термин, охватывающий методы, позволяю-\\nщие алгоритмам обучения строить менее сложные модели. На практике это часто \\nприводит к небольшому увеличению смещения, но значительно уменьшает дис -\\nперсию. Эта проблема известна в литературе как дилемма смещения\\xadдисперсии.\\nНа практике наиболее широко используются L1\\xad и L2\\xadрегуляризация. Идея до-\\nвольно проста. Чтобы создать регуляризованную модель, нужно модифицировать \\nцелевую функцию, добавив штрафной член, значение которого увеличивается \\nс ростом сложности модели.\\nЯ покажу регуляризацию на примере линейной регрессии. Но тот же принцип \\nс успехом можно применить к широкому спектру моделей.\\nНапомню, как выглядит целевая функция регрессии:\\n \\n   (5.2)\\nL1-регуляризованная целевая функция имеет вид\\n \\n   (5.3)\\nгде \\n , а C является гиперпараметром, определяющим важность регу-\\nляризации. Если установить C равным нулю, модель превратится в стандартную \\nнерегуляризованную модель линейной регрессии. С другой стороны, если при -\\nсвоить гиперпараметру C большое положительное значение, алгоритм обучения \\nпостарается присвоить большинству элементов w(j) очень маленькие значения \\nили ноль, чтобы минимизировать целевую функцию. В результате модель сильно \\nупростится, что может привести к недообучению. Ваша роль как аналитика состоит \\nв том, чтобы найти такое значение гиперпараметра C, которое не слишком увели-\\nчивает смещение и уменьшает дисперсию до приемлемого уровня. В следующем \\nразделе я покажу, как это сделать.\\nL2-регуляризованная целевая функция имеет вид\\n \\n   (5.4)\\nС практической точки зрения L1-регуляризация создает разреженную модель — \\nмодель, большинство параметров которой (в случае линейной модели — боль-'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='82   Глава 5. Практические основы\\nшинство значений w(j)) равно нулю, при условии что гиперпараметр C достаточно \\nвелик. Таким образом, L1 производит отбор признаков , решая, какие признаки \\nважны для прогнозирования, а какие нет. Это может пригодиться, когда требуется \\nупростить объяснение модели. Однако если единственная цель — увеличение \\nкачества прогнозирования на контрольных данных, то обычно лучшие резуль -\\nтаты дает L2. \\nМетоды регуляризации L1 и L2 также объединяются в так называемую модель \\nрегуляризации эластичных сетей , в которой L1- и L2-регуляризация являются \\nчастными случаями. В литературе также можно встретить название гребневая \\nрегуляризация (ridge regularization), подразумевающее L2-регуляризацию, и лассо \\n(lasso), соответствующее L1-регуляризации.\\nМетоды регуляризации L1 и L2 широко используются с линейными моделями, \\nа также часто применяются к нейронным сетям и моделям многих других типов, \\nкоторые напрямую минимизируют целевую функцию.\\nПри создании нейронных сетей также нередко используются два других метода \\nрегуляризации: прореживание (dropout) и пакетная нормализация. Существуют \\nтакже нематематические методы, имеющие эффект регуляризации: расширение \\nданных (data augmentation) и ранняя остановка. Мы поговорим об этих методах \\nв главе 8.\\n5.6. Оценка эффективности модели\\nПосле того как алгоритм построит модель на основе обучающих данных, как мы \\nможем узнать, насколько хорошей получилась эта модель? Для оценки модели \\nиспользуется тестовый набор данных.\\nТестовый набор содержит данные, которые алгоритм обучения не видел прежде, \\nпоэтому, если модель покажет хорошие результаты при прогнозировании меток \\nданных из тестового набора, можно сказать, что модель имеет хорошую обобщаю-\\nщую способность, или просто хороша.\\nСтрого говоря, для оценки эффективности моделей специалисты по машинному \\nобучению используют разные формальные метрики и инструменты. В случае ре-\\nгрессии модель оценивается довольно просто. Хорошо обученная модель регрессии \\nдает прогнозные значения, близкие к наблюдаемым. В отсутствие информативных \\nпризнаков обычно используется модель средних  (mean model), которая всегда \\nпрогнозирует средние значения меток в обучающих данных. Соответственно, \\nоцениваемая регрессионная модель должна быть лучше модели средних. Если это'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='5.6. Оценка эффективности модели   83\\nтак, тогда на следующем шаге сравнивается эффективность модели на обучающих \\nи тестовых данных.\\nДля этого вычисляется среднеквадратичная ошибка1 (Mean Squared Error, MSE) \\nотдельно для обучающих и тестовых данных. Если среднеквадратичная ошибка \\nмодели на тестовых данных существенно выше среднеквадратичной ошибки на \\nобучающих данных, это явный признак переобучения. Проблему могут решить \\nрегуляризация или более тщательный подбор гиперпараметров. Смысл слов «суще-\\nственно выше» зависит от решаемой задачи и определяется аналитиком совместно \\nс лицом, принимающим решение, заказавшим модель.\\nВ случае с классификацией все немного сложнее. Вот метрики и инструменты, \\nнаиболее широко используемые для оценки моделей классификации:\\n  матрица ошибок;\\n  правильность;\\n  правильность с учетом цены (cost-sensitive accuracy);\\n  точность/полнота;\\n  площадь под кривой рабочей характеристики приемника (Receiver Operating \\nCharacteristic, ROC).\\nДля простоты иллюстрации я использую задачу бинарной классификации. А там, \\nгде это необходимо, я покажу, как распространить решение на случай многоклас-\\nсовой классификации.\\n5.6.1. Матрица ошибок\\nМатрица ошибок  — это таблица, описывающая успешность классификации \\nданных, принадлежащих разным классам. Одна ось матрицы ошибок — метка, \\nпредсказанная моделью, а другая ось — фактическая метка. В задаче бинарной \\nклассификации есть два класса. Допустим, модель делает выбор из двух классов: \\n«спам» и «не_спам»:\\nспам (предсказание) не_спам (предсказание)\\nспам (факт) 23 (TP) 1 (FN)\\nне_спам (факт) 12 (FP) 556 (TN)\\n1 Или функция средней потери любого другого типа, имеющего смысл.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='84   Глава 5. Практические основы\\nПриведенная выше матрица ошибок показывает, что из 24 данных «спам» мо -\\nдель правильно классифицировала 23. В этом случае мы говорим, что у нас есть \\n23 истинно положительных (true positives, TP) результата, или TP = 23. Модель \\nнеправильно классифицировала 1 образец как не_спам. То есть мы имеем 1 лож\\xad\\nноотрицательный  (false negative, FN) результат, или FN = 1. Аналогично, из \\n568 данных, фактически не являющихся спамом, 556 были классифицированы \\nправильно. То есть мы имеем 556 истинно отрицательных  (true negatives, TN), \\nили TN = 556. Наконец, 12 данных, фактически не являющихся спамом, были \\nклассифицированы неверно, а значит, мы имеем 12 ложноположительных (false \\npositives, FP), или FP = 12.\\nМатрица ошибок для случая многоклассовой классификации имеет число строк \\nи столбцов по числу разных классов. Она может помочь вам определить тенденции \\nв распределении ошибок. Например, матрица ошибок может показать, что модель, \\nобученная распознаванию видов животных, имеет тенденцию ошибочно распоз -\\nнавать «пантеру» как «кошку» или «крысу» как «мышь». В таком случае можно \\nпопробовать добавить больше размеченных данных этих видов животных, чтобы \\nпомочь алгоритму обучения «увидеть» разницу между ними. Также можно попро-\\nбовать добавить дополнительные признаки, которые алгоритм обучения сможет ис-\\nпользовать для построения модели, способной лучше различать эти виды животных.\\nМатрица ошибок используется для вычисления двух других метрик: точность \\nи полнота.\\n5.6.2. Точность/полнота\\nДля оценки эффективности модели часто используются две метрики — точность \\nи полнота. Точность — это отношение истинно положительных прогнозов к обще-\\nму количеству положительных прогнозов:\\nПолнота — это отношение истинно положительных прогнозов к общему количе-\\nству положительных данных:\\nЧтобы понять значимость и важность точности и полноты для оценки модели, ча-\\nсто полезно рассматривать задачу прогнозирования как задачу поиска документов \\nв базе данных с помощью запросов. Точность — это доля релевантных документов'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='5.6. Оценка эффективности модели   85\\nв списке, возвращаемом запросом. Полнота — это доля релевантных документов, \\nвозвращаемых поисковым механизмом, в  общем количестве релевантных доку -\\nментов, которые могли бы быть возвращены.\\nВ случае с задачей классификации спама нам нужна высокая точность (желательно \\nисключить ошибочную классификацию допустимого сообщения как спам), и мы \\nготовы поступиться полнотой (то есть мы допускаем, что некоторые сообщения, \\nявляющиеся спамом, окажутся в папке для входящих сообщений).\\nНа практике почти всегда приходится выбирать между высокой точностью или \\nвысокой полнотой. Добиться высоких значений обеих метрик одновременно \\nобычно невозможно. Мы можем повысить тот или другой показатель разными \\nспособами:\\n  назначая более высокие весовые коэффициенты образцам (к примеру, алго -\\nритм SVM принимает на вход весовые коэффициенты для классов);\\n  настраивая гиперпараметры для получения более высокого значения точно -\\nсти или полноты на контрольном наборе;\\n  изменяя порог принятия решения для алгоритмов, возвращающих вероятно -\\nсти классов; например, при использовании логистической регрессии или де -\\nрева решений, для того чтобы повысить точность (за счет снижения полноты), \\nможно считать прогноз положительным, только если вероятность, возвраща -\\nемая моделью, выше 0.9.\\nДаже притом, что точность и полнота определены для случая бинарной класси -\\nфикации, эти оценки всегда можно распространить на модель многоклассовой \\nклассификации. Для этого сначала нужно выбрать класс для оценивания. И затем \\nсчитать все данные, принадлежащие выбранному классу, положительными, а все \\nостальные данные — отрицательными.\\n5.6.3. Правильность\\nПравильность определяется количеством правильно классифицированных дан -\\nных, деленным на общее количество классифицированных примеров. В терминах \\nматрицы ошибок она определяется как\\n \\n  (5.5)\\nОценка правильности может пригодиться, когда одинаково важны ошибки в про-\\nгнозировании всех классов. Это не относится к задаче классификации спам/'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='86   Глава 5. Практические основы\\nне_спам. Например, вы терпимее будете относиться к ложноотрицательным ре-\\nзультатам, чем к ложноположительным. Ложноположительный результат в класси-\\nфикации спама — это когда ваш друг отправил вам электронное письмо, но модель \\nраспознала его как спам и спрятала от вас. С другой стороны, ложноотрицательный \\nрезультат — намного меньшая проблема: если ваша модель не распознает неболь-\\nшой процент спама, это не будет иметь большого значения.\\nПлощадь\\nПлощадьПлощадь\\nПлощадь\\nДо ля истинно полож ительных\\n результатов\\nДо ля истинно полож ительных\\n результатов\\nДо ля истинно полож ительных\\n результатов\\nДо ля истинно полож ительных\\n результатов\\nДо ля ложнопол ож ительных\\nрезультатов\\nДо ля ложнопол ож ительных\\nрезультатов\\nДо ля ложнопол ож ительных\\nрезультатов\\nДо ля ложнопол ож ительных\\nрезультатов\\n11\\n11\\n11\\n11 00\\n00\\nРис. 5.3. Площадь под кривой рабочей характеристики (окрашена в серый цвет)'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='5.6. Оценка эффективности модели   87\\n5.6.4. Правильность с учетом цены\\nВ случаях, когда разные классы имеют разную важность, может пригодиться \\nметрика правильность с учетом цены (cost-sensitive accuracy). Чтобы получить \\nоценку правильности с учетом цены, нужно присвоить цену (положительное \\nчисло) обоим типам ошибок: FP и FN. Затем вычислить значения TP , TN, FP , FN, \\nкак обычно, умножить значения FP и FN на соответствующие цены и определить \\nправильность с помощью уравнения 5.5.\\n5.6.5. Площадь под ROC-кривой (AUC)\\nROC-кривая (термин receiver operating characteristic — рабочая характеристика \\nприемника — происходит из радиолокации) — это широко используемый метод \\nоценки эффективности классификационных моделей. Чтобы создать общую \\nкартину эффективности классификации, ROC-кривые используют комбинацию \\nдоли истинно положительных результатов (определяется в точности как полнота) \\nи доли ложноположительных результатов (доля отрицательных данных, класси-\\nфицированных неправильно).\\nДоли истинно положительных (True Positive Rate, TPR) и ложноположительных \\n(False Positive Rate, FPR) результатов определяются как\\nROC-кривые можно использовать только для оценки классификаторов, которые \\nвозвращают некоторую оценку достоверности (или вероятность) прогноза. На -\\nпример, с использованием ROC-кривых можно оценить логистическую регрессию, \\nнейронные сети и деревья решений (включая ансамблевые модели, основанные \\nна деревьях решений).\\nЧтобы начертить ROC-кривую, сначала нужно дискретизировать диапазон оценок \\nдостоверности. Если для данной модели диапазон равен [0, 1], его можно дискре-\\nтизировать следующим образом: [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]. Затем \\nкаждое дискретное значение используется в качестве порога при прогнозировании, \\nс использованием модели, меток данных в наборе данных. Например, чтобы вы -\\nчислить TPR и FPR для порога 0.7, нужно применить модель к каждому образцу, \\nполучить оценку достоверности, и, если оценка выше или равна 0.7, для этого об-\\nразца выбирается положительный класс; иначе — отрицательный.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='88   Глава 5. Практические основы\\nВзгляните на рис. 5.3. Легко заметить, что для порога 0 все прогнозы будут \\nположительными, поэтому обе метрики, TPR и FPR, будут равны 1 (верхний \\nправый угол). С другой стороны, для порога 1 положительные прогнозы невоз -\\nможны, поэтому оценки TPR и FPR будут равны 0, что соответствует левому \\nнижнему углу.\\nЧем больше площадь под ROC-кривой (area under ROC curve, AUC), тем эффек-\\nтивнее классификатор. Классификатор с AUC выше 0.5 лучше классификатора, \\nдействующего методом случайного выбора. Если AUC ниже 0.5, значит, с моделью \\nчто-то не так. Идеальный классификатор будет иметь AUC, равную 1. Обычно, \\nимея хорошую модель, можно получить эффективный классификатор, выбирая \\nзначение порога, который дает значение TPR, близкое к 1, и удерживает значение \\nFPR около 0.\\nROC-кривые пользуются большой популярностью, потому что относительно \\nпросты для понимания, способны охватывать несколько аспектов классификации \\n(с учетом ложных положительных и отрицательных результатов) и позволяют ви-\\nзуально и с минимальными усилиями сравнивать эффективность разных моделей.\\n5.7. Настройка гиперпараметров\\nКогда я знакомил вас с обучающими алгоритмами, то говорил, что вы, как аналитик, \\nдолжны выбирать правильные значения для гиперпараметров алгоритма, таких \\nкак ϵ и d для ID3, C для SVM или α для градиентного спуска. Но что понимается \\nпод «правильными значениями»? Какое значение является правильным и как его \\nнайти? В данном разделе я отвечаю на эти важные вопросы.\\nКак вы уже знаете, гиперпараметры не оптимизируются самим алгоритмом обуче-\\nния. Аналитик должен «настроить» гиперпараметры экспериментально, подобрав \\nлучшую комбинацию значений, по одному для каждого гиперпараметра.\\nОдин из типичных способов сделать это, если имеется достаточный объем данных, \\nчтобы выделить приличный контрольный набор (в котором каждый класс пред -\\nставлен как минимум парой десятков данных), а количество гиперпараметров и их \\nдиапазон не слишком велики, — использовать поиск по сетке.\\nПоиск по сетке — самый простой метод настройки гиперпараметров. Допустим, вы \\nобучаете SVM и у вас есть два гиперпараметра: параметр штрафа C (положительное \\nдействительное число) и ядро («linear» или «rbf»).\\nЕсли вы впервые работаете с конкретным набором данных, вы не знаете возможный \\nдиапазон значений для C. На практике часто применяется простой трюк — ис-'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='5.7. Настройка гиперпараметров   89\\nпользуется логарифмическая шкала. Например, вы можете попробовать следую-\\nщие значения для C: [0.001, 0.01, 0.1, 1, 10, 100, 1000]. В этом случае у вас есть 14 \\nкомбинаций гиперпараметров: [(0.001, «linear»), (0.01, «linear»), (0,1, «linear»), \\n(1, «linear»), (10, «linear» »), (100, «linear»), (1000, «linear»), (0.001, «rbf»), (0.01, \\n«rbf»), (0.1, «rbf»), (1, «rbf»), (10, «rbf»), (100, «rbf»), (1000, «rbf»)].\\nДалее вы обучаете 14 моделей на обучающем наборе, по одной для каждой ком -\\nбинации гиперпараметров. Затем оцениваете эффективность каждой модели на \\nконтрольных данных, используя одну из метрик, о которых мы говорили в пре-\\nдыдущем разделе (или какую-то другую метрику, важную для вас). И наконец, \\nсохраняете модель, обладающую лучшей эффективностью в соответствии с вы-\\nбранной метрикой.\\nОпределив лучшую пару гиперпараметров, вы можете попробовать другие значе-\\nния, близкие к лучшим. Иногда это позволяет получить еще более эффективную \\nмодель.\\nВ заключение вы оцениваете выбранную модель с использованием тестового на-\\nбора.\\nОчевидно, что проверка всех комбинаций гиперпараметров, особенно если их не-\\nсколько, может занять много времени, особенно для больших наборов данных. \\nСуществуют более эффективные методы, такие как случайный поиск и байесов\\xad\\nская оптимизация гиперпараметров.\\nСлучайный поиск отличается от поиска по сетке тем, что от \\nвас не требуется создавать дискретный набор значений для \\nкаждого гиперпараметра; вместо этого вы произвольно опреде-\\nляете статистическое распределение каждого гиперпараметра, \\nиз которого случайным образом выбираются значения для \\nопробования, и задаете общее количество комбинаций, которые \\nнужно опробовать.\\nБайесовские методы отличаются от случайного поиска или поиска по сетке тем, что \\nвыбор следующих значений для оценки они производят на основе результатов про-\\nшлых испытаний. Идея состоит в том, чтобы ограничить количество дорогостоящих \\nоптимизаций целевой функции, выбирая следующие значения гиперпараметра на \\nоснове тех, которые давали хороший результат в прошлом.\\nСуществуют также методы на основе градиента, методы эволюционной оптимиза\\xad\\nции и другие методы алгоритмической настройки гиперпараметров. Большинство \\nсовременных библиотек машинного обучения реализуют один или несколько таких \\nметодов. Существуют также специализированные библиотеки настроек гиперпа-'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='90   Глава 5. Практические основы\\nраметров, которые могут помочь в настройке гиперпараметров для практически \\nлюбого алгоритма обучения, включая созданные вами.\\n5.7.1. Перекрестная проверка\\nКогда нет возможности выделить приличного размера контрольный набор для \\nнастройки гиперпараметров, часто используется метод перекрестной проверки. \\nЕсли обучающих данных немного, затруднительно выделить два дополнительных \\nнабора данных, контрольный и тестовый. Вы наверняка предпочтете использовать \\nбольше данных для обучения модели. В таком случае вы можете разбить данные \\nтолько на два набора: обучающий и тестовый, а затем использовать прием пере -\\nкрестной проверки на обучающем наборе, чтобы сымитировать контрольный набор.\\nПерекрестная проверка выполняется следующим образом. Сначала фиксируются \\nзначения гиперпараметров для оценки. Затем обучающий набор разбивается на \\nнесколько выборок одинакового размера. Каждая выборка называется блоком. \\nНа практике обычно используется перекрестная проверка с пятью блоками. Для \\nперекрестной проверки с пятью блоками нужно случайным образом разбить обу-\\nчающие данные на пять блоков: {F1, F2, ..., F5}. Каждый Fk, k = 1, ..., 5 содержит 20 % \\nобучающих данных. Затем обучается пять отдельных моделей, как описывается \\nдалее. Для обучения первой модели, f1, используются все данные из блоков F2, F3, F4 \\nи F5, а данные из F1 играют роль контрольного набора. Для обучения второй модели, \\nf2, используются данные из блоков F1, F3, F4 и F5, а данные из F2 используются для \\nпроверки. Аналогично строятся остальные модели и для каждого контрольного \\nнабора, от F1 до F5, вычисляются значения метрики. Затем пять значений метрики \\nусредняются, чтобы получить окончательное значение.\\nДля поиска оптимальных значений гиперпараметров перекрестную проверку \\nможно совместить с поиском по сетке. Определив искомые значения, можно ис -\\nпользовать весь обучающий набор для построения модели с лучшими значениями \\nгиперпараметров, найденными путем перекрестной проверки. В завершение про-\\nизводится оценка модели с использованием тестового набора.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='6\\nНейронные сети \\nи глубокое обучение\\nНачнем с того, что вы уже знаете, что такое нейронная сеть, и знаете, как ее по -\\nстроить. Да, это логистическая регрессия! Фактически, модель логистической \\nрегрессии, или, скорее, ее обобщение для многоклассовой классификации, назы -\\nваемое моделью регрессии softmax, является стандартным узлом в нейронной сети.\\n6.1. Нейронные сети\\nПонимая, как работает линейная регрессия, логистическая регрессия и градиент-\\nный спуск, вы легко освоите нейронные сети.\\nНейронная сеть (neural network, NN), так же как модель регрессии или SVM, — это \\nвсего лишь математическая функция:\\ny = fNN(x).\\nФункция fNN имеет особую форму: это вложенная функция (вроде матрешки). \\nВы, наверное, уже слышали о слоях в нейронных сетях. Итак, для трехслойной \\nнейронной сети, возвращающей скаляр, fNN выглядит так:\\ny = fNN(x) = f3(f2(f1(x))).\\nf1 и f2 в уравнении выше — это векторные функции, которые определяются как\\n \\n   (6.1)\\nгде l — это индекс слоя и может охватывать от 1 до любого количества слоев. Функ-\\nция gl называется функцией активации. Это фиксированная, обычно нелинейная'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='92   Глава 6. Нейронные сети и глубокое обучение\\nфункция, выбранная аналитиком до начала обучения. Параметры Wl (матрица) \\nи bl (вектор) определяются для каждого слоя в ходе обучения, с использованием \\nуже знакомого вам градиентного спуска для оптимизации, в зависимости от ре-\\nшаемой задачи, конкретной функции стоимости (такой как среднеквадратичная \\nошибка — MSE). Сравните уравнение 6.1 с уравнением логистической регрессии, \\nзаменив gl сигмоидной функцией, и вы не увидите никакой разницы. Функция f3 \\nявляется скалярной функцией для задачи регрессии, но также может быть вектор-\\nной функцией, в зависимости от конкретной задачи.\\nВозможно, вам интересно, почему вместо вектора wl используется матрица Wl. \\nПричина в  том, что  gl — векторная функция. Каждая строка wl,u (u означает \\n«unit» — узел) в матрице Wl является вектором той же размерности, что и z. Пусть \\nal,u = wl,uz + bl,u. На выходе fl (z) возвращает вектор \\n , \\nгде gl — некоторая скалярная функция1, а sizel — количество узлов в слое l. Чтобы \\nсделать обсуждение более конкретным, рассмотрим одну из архитектур нейрон -\\nных сетей, называемую многослойным перцептроном и часто упоминаемую как \\nклассическая нейронная сеть.\\n6.1.1. Пример многослойного перцептрона\\nДалее мы подробно рассмотрим одну конкретную конфигурацию нейронных сетей, \\nназываемую нейронными сетями прямого распространения (Feedforward Neural \\nNetwork, FFNN), и еще более конкретно — архитектуру, называемую многослойным \\nперцептроном (Multilayer Perceptron, MLP). В качестве иллюстрации рассмотрим \\nMLP с тремя слоями. Наша сеть принимает на вход двумерный вектор признаков \\nи выводит число. Эта FFNN может быть моделью регрессии или классификации, \\nв зависимости от функции активации, используемой в третьем выходном слое.\\nНаш многослойный перцептрон изображен на рис. 6.1. Графически нейронную \\nсеть можно представить в виде комбинации связанных узлов, логически органи-\\nзованных в один или несколько слоев. Каждый узел представлен кружком или \\nпрямоугольником. Входящая стрелка представляет вход узла и указывает, откуда \\nпоступают данные на этот вход. Исходящая стрелка представляет выход узла.\\nВыход каждого узла является результатом математической операции, выполня -\\nемой внутри прямоугольника. Узлы, обозначенные кружками, ничего не делают \\nс входными данными; они просто пересылают их на свой выход.\\nВот что происходит в каждом узле, обозначенном прямоугольником. Сначала все \\nвходы узла объединяются, и из них формируется входной вектор. Затем узел при-\\n1 Скалярная функция возвращает скаляр — простое число, а не вектор.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='6.1. Нейронные сети   93\\nменяет линейное преобразование к входному вектору, точно так же, как это делает \\nмодель линейной регрессии со своим вектором входных признаков. И в заключе-\\nние применяет функцию активации g к результату линейного преобразования, \\nполучая выходное значение — действительное число. В классической нейронной \\nсети прямого распространения (FFNN) выходное значение узла в некотором слое \\nстановится входным значением для всех узлов в следующем слое.\\nНа рис. 6.1 функция активации gl имеет один индекс: l — индекс слоя, которому \\nпринадлежит узел. Обычно все узлы в одном слое уровня используют одну и ту же \\nфункцию активации, но это не обязательно. Каждый слой может иметь различное \\nколичество узлов. Каждый узел имеет свои параметры wl,u и bl,u, где u — индекс узла, \\nа l — индекс слоя. Вектор yl–1 в каждом узле определяется как \\n. \\nВектор x в первом слое определяется как \\n.\\nКак можно заметить на рис. 6.1, в многослойном перцептроне все выходы одного \\nслоя подключены к каждому входу последующего слоя. Такая архитектура назы-\\nвается полносвязанной. Нейронная сеть также может содержать полносвязанные \\nслои, то есть слои, чьи узлы получают на входе выходные данные от каждого из \\nузлов в предыдущем слое.\\n6.1.2. Архитектура нейронных сетей прямого \\nраспространения\\nДля решения задач регрессии или классификации, которые рассматривались в пре-\\nдыдущих главах, достаточно, чтобы последний (самый правый) слой нейронной \\nсети содержал единственный узел. Если функция активации glast последнего узла \\nявляется линейной, тогда нейронная сеть является регрессионной моделью. Если \\nglast является логистической функцией, тогда нейронная сеть является моделью \\nбинарной классификации.\\nАналитик данных может выбрать для gl,u любую дифференцируемую математи -\\nческую функцию 1. Последнее свойство существенно для градиентного спуска, \\nиспользуемого для поиска значений параметров wl,u и bl,u для всех l и u. Основная \\n1 Функция должна быть дифференцируемой по всей области значений или в большинстве \\nточек в этой области. Например, ReLU не дифференцируется в точке 0.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='x(1)\\nx(2)\\ny1(1) ← g 1(w1,1x + b1,1)\\nx(1)\\nx(2)\\ny1(2) ← g1(w1,2x + b1,2)\\ny1(3) ← g1(w1,3x + b1,3)\\ny1(4) ← g1(w1,4x + b1,4)\\ny2(1) ← g2(w2,1y1 + b2,1)\\ny2(2) ← g2(w2,2y1 + b2,2)\\ny2(3) ← g2(w2,3y1 + b2,3)\\ny2(4) ← g2(w2,4y1 + b2,4)\\ny ← g3(w3,1y2 + b3,1) y\\nслой 3 (f3) слой 2 (f2) слой 1 (f1) \\ny1(1)\\ny1(4)\\ny2(4)\\ny2(3)\\ny2(2)\\ny2(1)\\nРис. 6.1. Многослойный перцептрон с двумерным входом, двумя слоями по четыре узла в каждом и выходным слоем \\nс единственным узлом'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='6.2. Глубокое обучение   95\\nцель нелинейных компонентов в функции fNN состоит в том, чтобы позволить ней-\\nронной сети аппроксимировать нелинейные функции. В отсутствие нелинейных \\nкомпонентов fNN была бы линейной, независимо от количества слоев. Причина \\nв том, что Wl z + bl является линейной функцией, а линейная функция от линейной \\nфункции также является линейной.\\nВ роли функций активации часто используется уже известная вам логистическая \\nфункция, а также TanH и ReLU. Первая — это функция гиперболического тангенса, \\nнапоминающая логистическую функцию, но имеющая область определения в диа-\\nпазоне от –1 до 1 (не включая их). Последняя представляет собой спрямленную \\nлинейную единичную функцию, которая равна нулю, когда на входе получает \\nотрицательное значение z, и само значение z в противном случае:\\nКак я уже говорил выше, Wl в выражении Wlz + bl — это матрица, а bl — вектор. \\nЭтим оно отличается от линейной регрессии wz + b. Каждой строке u в матрице Wl \\nсоответствует вектор параметров wl,u. Размерность вектора wl,u равна количеству \\nузлов в слое l — 1. Операция Wlz дает вектор \\n . Тогда \\nсумма al + bl дает sizel-размерный вектор cl. Наконец, функция gl (cl) создает и воз-\\nвращает вектор \\n .\\n6.2. Глубокое обучение\\nПод глубоким обучением подразумевается обучение нейронных сетей, имеющих \\nбольше двух невыходных слоев. В прошлом обучение таких сетей усложнялось все \\nбольше с ростом количества слоев. В числе самых больших проблем назывались \\nвзрывной рост градиента  и затухание градиента , поскольку для определения \\nпараметров сети использовался градиентный спуск.\\nЕсли проблема взрывного роста градиента решалась относительно просто, с при-\\nменением таких простых методов, как ограничение градиента  и L1- или L2-\\nрегуляризация, то проблема затухания градиента оставалась неразрешимой \\nв течение десятилетий.\\nЧто такое затухание градиента и чем обусловлена эта проблема? Для обновления \\nзначений параметров в нейронных сетях обычно используется алгоритм, называе-'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='96   Глава 6. Нейронные сети и глубокое обучение\\nмый обратным распространением. Обратное распространение — это эффективный \\nалгоритм вычисления градиентов в нейронных сетях с использованием правила \\nдифференцирования сложных функций. В главе 4 мы уже видели, как это правило \\nиспользуется для вычисления частных производных составной функции. В каждой \\nитерации обучения, в процессе градиентного спуска, параметры нейронной сети \\nобновляются пропорционально частной производной функции стоимости для \\nтекущего параметра. Проблема в том, что иногда градиент оказывается исчезаю-\\nще малым, что фактически мешает изменению значений некоторых параметров. \\nВ худшем случае это может полностью остановить обучение нейронной сети.\\nТрадиционные функции активации, такие как функция гиперболического тангенса, \\nо которой я упоминал выше, имеют градиенты в диапазоне (0, 1), при этом гради-\\nенты вычисляются на этапе обратного распространения по правилу дифференци-\\nрования сложных функций. В результате для вычисления градиентов предыдущих \\nслоев (расположенных левее) в n-слойной сети производится перемножение n этих \\nнебольших чисел, из-за чего градиент экспоненциально уменьшается с увеличени-\\nем n. Это приводит к тому, что более ранние слои обучаются намного медленнее, \\nесли вообще обучаются.\\nОднако современные реализации алгоритмов обучения нейронных сетей позво -\\nляют эффективно обучать очень глубокие нейронные сети (до нескольких сотен \\nслоев). Это объясняется внедрением целого комплекса усовершенствований, вклю-\\nчая ReLU, LSTM (и другие вентильные узлы; мы рассмотрим их ниже), а также \\nтаких методов, как соединения с пропуском слоя (skip connections), используемые \\nв остаточных нейронных сетях (residual neural networks), а также усовершенство-\\nванные версии алгоритма градиентного спуска.\\nИтак, поскольку проблемы затухания и взрывного роста градиента в настоящее \\nвремя практически решены (или их влияние сведено к минимуму), под термином \\n«глубокое обучение» подразумевается обучение нейронных сетей с использова-\\nнием современного алгоритмического и математического инструментария, неза-\\nвисимо от глубины нейронной сети. На практике многие бизнес-задачи можно \\nрешить с помощью нейронных сетей, имеющих 2–3 слоя между входным и выход-\\nным слоями. Слои, не являющиеся ни входными, ни выходными, часто называют \\nскрытыми слоями.\\n6.2.1. Сверточная нейронная сеть\\nВозможно, вы заметили, что количество параметров, которые может иметь MLP \\n(многослойный перцептрон), быстро растет по мере увеличения сети. В частности, \\nпри добавлении одного слоя в сеть добавляется (sizel–1 +1) ⋅ sizel параметров (ма-\\nтрица Wl плюс вектор bl). То есть если в существующую нейронную сеть добавить'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='6.2. Глубокое обучение   97\\nеще один слой с 1000 узлов, в модель добавится более миллиона дополнительных \\nпараметров. Оптимизация таких больших моделей является очень сложной вы -\\nчислительной задачей.\\nКогда в роли обучающих данных используются изображения, входные данные \\nполучаются слишком многомерными 1. Если вы решите построить модель клас -\\nсификации изображений с использованием MLP , проблема оптимизации почти \\nнаверняка станет неразрешимой.\\nСверточная нейронная сеть (Convolutional Neural Network, CNN) — это особый \\nвид FFNN, который значительно сокращает количество параметров в глубокой \\nнейронной сети с большим количеством узлов практически без потери качества \\nмодели. Сверточные нейронные сети нашли применение в обработке изображений \\nи текста, где они побили многие ранее установленные рекорды.\\nТак как сверточные нейронные сети были изобретены для обработки изображений, \\nя объясню, как они работают, на примере классификации изображений.\\nВозможно, вы замечали, что пикселы, расположенные в изображениях близко \\nдруг от друга, обычно представляют информацию одного и  того же типа: небо, \\nвода, листья, мех, кирпичи и т. д. Исключением из правила являются края: части \\nизображения, где два разных объекта «касаются» друг друга.\\nЕсли обучить нейронную сеть распознаванию областей с одной и той же информа-\\nцией, а также краев, эти знания позволят нейронной сети распознавать объекты, \\nпредставленные на изображении. Например, если нейронная сеть обнаружит \\nнесколько областей кожи с краями, имеющими овальную форму, с цветом кожи \\nвнутри и голубым цветом снаружи, то, скорее всего, это лицо на фоне неба. Если \\nцелью является обнаружение людей на изображениях, нейронная сеть, скорее \\nвсего, преуспеет в этом.\\nУчитывая, что наиболее важная информация занимает на изображении ограничен-\\nную площадь, мы можем разделить изображение на квадратные фрагменты, исполь-\\nзуя метод скользящего окна2. Затем обучить несколько небольших регрессионных \\nмоделей одновременно, передавая каждой квадратный фрагмент. Цель каждой \\nнебольшой регрессионной модели — научиться обнаруживать определенный ша-\\nблон во фрагменте на входе. Например, одна небольшая модель может научиться \\nопределять небо; другая — траву, третья — края зданий и т. д.\\n1 Каждый пиксел в изображении — это отдельный признак. Изображение размером 100 на \\n100 пикселов имеет 10 000 признаков.\\n2 Представьте, что рассматриваете банкноту в микроскоп. Чтобы рассмотреть всю банкноту, \\nнужно постепенно перемещать ее слева направо и сверху вниз. В каждый момент времени \\nвы видите только часть банкноты. Этот подход называется методом скользящего окна.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='98   Глава 6. Нейронные сети и глубокое обучение\\nНебольшие регрессионные модели в CNN напоминают модель на рис. 6.1, но имеют \\nтолько по одному слою. Чтобы обнаружить какой-либо шаблон, модель регрессии \\nдолжна определить параметры матрицы F (от слова «filter» — фильтр) размером \\np × p, где p — размер фрагмента. Для простоты предположим, что входное изо -\\nбражение черно-белое, число 1 представляет черные, а число 0 — белые пикселы. \\nПредположим также, что фрагменты имеют размер 3 на 3 пиксела ( p = 3). Неко-\\nторый фрагмент может выглядеть как следующая матрица P (от слова «patch» — \\nфрагмент):\\nФрагмент выше представляет шаблон с изображением креста. Небольшая ре -\\nгрессионная модель, которая будет обнаруживать такие шаблоны (и только их), \\nдолжна обучить матрицу F размером 3 на 3, в которой параметры в позициях, со-\\nответствующих единицам во входном фрагменте, будут положительными числами, \\nа параметры в позициях, соответствующих нулям, будут иметь значения, близкие \\nк нулю. Если вычислить свертку матриц P и F, полученное значение будет тем \\nбольше, чем больше F похожа на P. Для иллюстрации свертки двух матриц пред-\\nположим, что F выглядит следующим образом:\\nОператор свертки conv определен только для матриц, имеющих одинаковое ко -\\nличество строк и столбцов. Для наших матриц P и F свертка вычисляется, как \\nпоказано на рис. 6.2.\\n0 1 0\\n111\\n00 1\\n0 2 3\\n241\\n00 3\\n0\\n11\\n0\\n1\\n1\\n01\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n3\\n21\\n00\\n0 2\\n4\\n3\\n00 11 00\\n11 11 11\\n00 0011\\nconv\\nPF\\noverlay\\n00 22 33\\n22 44 11\\n00 0033\\n0 . 0 0\\n11\\n0\\n000 1\\n1\\n01\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\nsum\\n1 . 2111 ... 0 . 3000 ...\\n1 . 2111 ... 1 . 4111 ... 1 . 1111 ...\\n0 . 0000 ... 1 . 3111 ... 0 . 0000 ...\\n3\\n21\\n00\\n02\\n4\\n3\\nсуммиро-\\nвание\\nPF\\nнало-\\nжение\\nсвертка 12\\nРис. 6.2. Свертка двух матриц'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='6.2. Глубокое обучение   99\\nЕсли на вход подать фрагмент P, имеющий другой шаблон, например изображение \\nбуквы L,\\nтогда свертка с F даст в результате меньшее значение: 5. То есть чем больше фрагмент \\n«похож» на фильтр, тем выше значение операции свертки. Для удобства имеется \\nтакже параметр смещения b, связанный с каждым фильтром F, который добавляется \\nк результату свертки перед применением нелинейности (функция активации).\\nОдин слой в CNN состоит из нескольких сверточных фильтров (каждый со своим \\nсобственным параметром смещения), в точности как один слой в классической \\nFFNN состоит из нескольких узлов. Каждый фильтр в первом (самом левом) слое \\nскользит — свертывает — по входному изображению слева направо, сверху вниз, \\nи в каждой итерации вычисляет значение свертки.\\nЭтот процесс изображен на рис. 6.3, где показаны шесть шагов перемещения одного \\nфильтра, выполняющего свертку изображения.\\nМатрица фильтра (по одной для каждого фильтра в  каждом слое) и значения \\nсмещения являются обучаемыми параметрами, которые оптимизируются с  ис-\\nпользованием градиентного спуска с обратным распространением.\\nНелинейность применяется к сумме свертки и  смещения. Как правило, во всех \\nскрытых слоях используется функция активации ReLU. Функция активации \\nв выходном слое зависит от решаемой задачи.\\nПоскольку в каждом слое l может иметься sizel фильтров, выходной слой l будет \\nсостоять из sizel матриц, по одной для каждого фильтра.\\nЕсли CNN имеет один сверточный слой, следующий за другим сверточным слоем, \\nто последующий слой l + 1 будет обрабатывать выходные данные предыдущего \\nслоя l, как коллекцию sizel матриц изображения. Такая коллекция называется \\nтомом. Размер коллекции называется глубиной тома. Каждый фильтр в слое l + 1 \\nвыполняет свертку всего тома. Свертка фрагмента тома — это просто сумма сверток \\nсоответствующих фрагментов отдельных матриц, из которых состоит том.\\nНа рис. 6.4 показан пример свертки фрагмента тома с глубиной 3. Значение свертки, \\n–3, было получено в результате вычисления выражения: \\n(–2 · 3 + 3 · 1 + 5 · 4 + (–1) · 1) + (–2 · 2 + 3 · (–1) + 5 · (–3) + (–1) · 1) + (–2 · 1 +  \\n+ 3 · (–1) + 5 · 2 + (–1) · (–1)) + (–2).'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\nИзображение\\nФильтр \\n4 \\nВыход перед\\nприменением \\nнелинейности \\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\n4 –1 \\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\n4 –1 7 \\nСвертка 1\\nСвертка 2\\nСвертка 3\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\n4 \\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\n4 –1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\n4 –1 7 \\n–1 7 \\n7 \\n2 Свертка 4\\n2 7 \\n2 7 0 \\nСвертка 5\\nСвертка 6\\n1\\nСмещение\\n1\\n1\\n1\\n1\\n1\\nРис. 6.3. Фильтр, свертывающий изображение'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='6.2. Глубокое обучение   101\\nФильтр Смещение\\nВых од перед применением\\nнелинейности\\nТом\\n–\\n–\\n––\\n––\\n–––\\n–\\n–\\n––\\n–\\n––\\n–\\nРис. 6.4. Свертка тома состоит из трех матриц\\nВ системах распознавания изображений сверточные нейронные сети часто получа-\\nют на входе тома, потому что изображения обычно представлены тремя каналами: \\nR, G и B, каждый из которых представляет монохромное изображение.\\nСвертки имеют два важных свойства — шаг и дополнение. Шаг — это величина \\nодного шага смещения окна. На рис. 6.3 шаг равен 1, то есть фильтр смещается \\nвправо и вниз на одну ячейку за раз. На рис. 6.5 показан пример свертки с шагом 2. \\nКак видите, чем больше шаг, тем меньше выходная матрица.\\nДополнение позволяет получить увеличенную выходную матри-\\nцу; это ширина рамки с дополнительными ячейками, которые \\nдобавляются вокруг изображения (или тома) перед сверткой \\nс помощью фильтра. Обычно дополнительные ячейки, формиру-\\nющие дополнение, содержат нули. На рис. 6.3 дополнение равно \\n0, поэтому дополнительные ячейки не добавляются в изображе-\\nние. На рис. 6.6 задан шаг, равный 2, и дополнение, равное 1, поэтому вокруг изо-\\nбражения добавляется рамка шириной в 1 ячейку. Как видите, выходная матрица \\nувеличилась с увеличением дополнения1.\\n1 Для экономии места на рис. 6.6 показаны только первые две из девяти сверток.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\nИзображение\\nФильтр\\n4 \\nВыход перед\\nприменением\\nнелинейности\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 -2 \\n4 7 \\nСвертка 1\\nСвертка 2\\n1\\nСмещение\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\n4 \\nСвертка 3\\n1\\n7 \\n0 \\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\n4 \\nСвертка 4\\n1\\n7 \\n0 –1 \\nРис. 6.5. Свертка с шагом 2'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='6.2. Глубокое обучение   103\\n0\\n0\\n0\\n0\\n0 0 0 0 0\\n0 0 0 0 0 0\\n0\\n0\\n0\\n0\\n0\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\nИзображение с дополнением 1\\nФильтр  \\n–1 \\nВыход перед\\nприменением\\nнелинейности\\n \\nСвертка 1\\n1\\nСмещение\\n0\\n0\\n0\\n0\\n0 0 0 0 0\\n0 0 0 0 0 0\\n0\\n0\\n0\\n0\\n0\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n–1 2 \\n4 –2 \\n–1 \\nСвертка 2\\n1\\n1\\nРис. 6.6. Свертка с шагом 2 и дополнением 1\\nНа рис. 6.7 показан пример изображения с дополнением 2. Дополнение может \\nпригодиться при использовании более крупных фильтров, позволяя им лучше \\n«сканировать» границы изображения.\\nЭтот раздел был бы неполным без описания приема подвыборки (pooling, в русско-\\nязычной литературе также встречаются термины «субдискретизация» и «пулинг»), \\nочень часто используемого в CNN. Подвыборка действует во многом подобно \\nсвертке, потому что фильтр применяется методом скользящего окна. Однако вместо \\nприменения обучаемого фильтра к входной матрице или т \\ue088ому слой подвыборки \\nприменяет фиксированный оператор, обычно max (возвращающий максимальное \\nзначение) или average (возвращающий среднее значение). Подобно свертке, опера-\\nция подвыборки имеет гиперпараметры: размер фильтра и шаг. Пример подвыборки \\nс оператором max с размером фильтра 2 и шагом 2 показан на рис. 6.8.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='104   Глава 6. Нейронные сети и глубокое обучение\\nРис. 6.7. Изображение с дополнением 2\\n3\\n5\\n–3\\n5\\n5\\n6\\n4\\n2\\n9 \\n–1 \\n1 \\n7 4 \\n2 \\n1 8 \\nИзображение\\n8 \\nВыход  \\n8 6 \\nПодвыборка 1\\nПодвыборка 2\\n8 \\nПодвыборка 3\\n6 \\n5 \\n8 \\nПодвыборка 4\\n6 \\n5 9 \\n3\\n5\\n–3\\n5\\n5\\n6\\n4\\n2\\n9 \\n–1 \\n1 \\n7 4 \\n2 \\n1 8 \\n3\\n5\\n–3\\n5\\n5\\n6\\n4\\n2\\n9 \\n–1 \\n1 \\n7 4 \\n2 \\n1 8 \\n3\\n5\\n–3\\n5\\n5\\n6\\n4\\n2\\n9 \\n–1 \\n1 \\n7 4 \\n2 \\n1 8 \\nРис. 6.8. Подвыборка с размером фильтра 2 и шагом 2\\nКак правило, слой подвыборки следует за сверточным слоем и получает на входе \\nвыходные данные свертки. Когда подвыборка применяется к т\\ue088ому, каждая матрица \\nв этом томе обрабатывается независимо от других. То есть в результате применения \\nподвыборки к т\\ue088ому получается том с той же глубиной.\\nКак видите, операция подвыборки имеет только гиперпараметры и не имеет обу-\\nчаемых параметров. На практике обычно используются фильтры с размером 2'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='6.2. Глубокое обучение   105\\nили 3 и с шагом 2. Подвыборка с определением максимального значения более \\nпопулярна, чем с определением среднего, и часто дает лучшие результаты.\\nОбычно подвыборка способствует повышению точности модели, а также повышает \\nскорость обучения за счет уменьшения количества вычислений требуемых для \\nприменения свертки. (Как показано на рис. 6.8, при размере фильтра 2 и шаге 2 \\nразмерность тома на входе следующего слоя уменьшается вдвое.) \\n6.2.2. Рекуррентная нейронная сеть\\nРекуррентные нейронные сети (Recurrent Neural Network, RNN) используются \\nдля маркировки, классификации или генерации последовательностей. Последо -\\nвательность — это матрица, каждая строка которой является вектором признаков \\nи в которой порядок строк имеет значение. Под маркировкой последовательности \\nподразумевается предсказание класса для каждого вектора признаков в последова-\\nтельности. Под классификацией последовательности — предсказание класса для \\nвсей последовательности. Сгенерировать последовательность означает вывести \\nдругую последовательность (возможно, другой длины), некоторым образом свя -\\nзанную с входной последовательностью.\\nРекуррентные нейронные сети часто используются для обработки текста, потому \\nчто предложения и тексты являются естественными последовательностями слов \\nи знаков препинания или последовательностями символов. По той же причине \\nрекуррентные нейронные сети также используются в обработке речи.\\nРекуррентная нейронная сеть не является сетью прямого распространения: она со-\\nдержит циклы. Идея состоит в том, что каждый узел u рекуррентного слоя l имеет ве-\\nщественное состояние hl,u. Состояние можно рассматривать как память узла. В RNN \\nкаждый узел u в каждом слое l имеет два входа: вектор состояний из предыдущего \\nслоя l — 1 и вектор состояний из этого же слоя l, но из предыдущего временного шага.\\nДля иллюстрации рассмотрим первый и второй рекуррентные слои в сети RNN. \\nПервый (самый левый) слой получает на входе вектор признаков. Второй слой \\nполучает на входе выходные данные из первого слоя.\\nЭта ситуация схематически изображена на рис. 6.9. Как я уже говорил, каждый \\nобучающий образец представлен матрицей, в которой каждая строка является \\nвектором признаков. Для простоты будем рассматривать эту матрицу как после -\\nдовательность векторов \\n , где lengthx — длина \\nвходной последовательности. Если входной образец X является текстовым пред-\\nложением, тогда вектор признаков xt для каждого t = 1, ..., lengthx представляет \\nслово в позиции t в предложении.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='xt ← [x (1),t,x(2),t]\\nx(2),t\\nht-1\\n1,1\\nht-1\\nl,2\\nht\\n1,1\\nht1,1 ← g 1(w1,1xt + u1,1ht-11 + b1,1)\\nyt\\n1 ← g 2(V1ht\\n1 + c1)\\nx(1),t\\nx(2),t\\nht-11,1\\nht-1\\n1,2\\nht\\n1,2\\nht1,2 ← g 1(w1,2xt + u1,2ht-1\\n1 + b1,2)\\nx(1),t\\nxt ← [ x(1),t,x(2),t]\\nслой 1\\nht1 ← [h t1,1,ht1,2]\\nht-1\\n2,1\\nht-1\\n2,2\\nht\\n2,1\\nht2,1 ←  g1(w2,1h1t + u2,1ht-12 + b2,1)\\nht-12,1\\nht-1\\n2,2\\nht\\n2,2\\nслой 2\\nht1 ← [h t1,1,ht1,2]\\nyt2 ←  g2(V2ht2 + c2)\\nht2 ←[h t2,1,ht2,2]\\nyt1 yt2\\nht\\n1 ← [h t\\n1,1,ht1,2]\\nht\\n2,2 ← g 1(w2,2ht\\n1 + u2,2ht-12 + b2,2)\\nРис. 6.9. Первые два слоя в рекуррентной нейронной сети.  \\nНа вход подается двумерный вектор признаков; каждый слой имеет два узла'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='6.2. Глубокое обучение   107\\nКак показано на рис. 6.9, в RNN векторы признаков из входного образца после -\\nдовательно «читаются» нейронной сетью в порядке временных шагов. Индекс t \\nобозначает временной шаг. Чтобы обновить состояние \\n  на каждом временном \\nшаге t в каждом узле u каждого слоя l, сначала вычисляется линейная комбинация \\nвходного вектора признаков с вектором состояния \\n  этого же слоя из предыдущего \\nвременного шага t — 1. Линейная комбинация двух векторов вычисляется с исполь-\\nзованием двух векторов параметров wl,u, ul,u и параметра bl,u. Значение\\n  получается \\nприменением функции активации g1 к результату линейной комбинации. Обычно \\nв роли функции g1 выступает tanh. Выход \\n  обычно является вектором, который \\nвычисляется сразу для всего слоя l. Чтобы получить \\n , используется функция ак-\\nтивации g2, которая на входе принимает вектор и возвращает другой вектор той же \\nразмерности. Функция g2 применяется к линейной комбинации вектора значений \\nсостояния \\n , вычисленных с использованием матрицы парамет ров Vl и вектора \\nпараметров cl. В классификации на роль g2 обычно выбирается функция softmax:\\nФункция softmax — это обобщение сигмоидной функции на многомерные выходы. \\nОна имеет свойство \\n  и \\n  для всех j.\\nРазмерность Vl выбирается аналитиком таким образом, чтобы произведение \\nматрицы Vl на вектор \\n  давало вектор той же размерности, что и вектор cl. Этот \\nвыбор зависит от размерности выходной метки y в данных обучения. (До сих пор \\nмы рассматривали только одномерные метки, но в следующих главах мы увидим, \\nчто метки могут быть многомерными.)\\nЗначения wl,u, ul,u, bl,u, Vl,u и cl,u определяются по обучающим данным с использова-\\nнием градиентного спуска с обратным распространением. Для обучения моделей \\nRNN используется специальная версия обратного распространения, называемая \\nобратным распространением во времени.\\nОбе функции, tanh и softmax, страдают проблемой затухания градиента. Даже если \\nнаша сеть RNN имеет только один или два рекуррентных слоя, из-за последова -\\nтельного характера входных данных обратное распространение «развертывает» \\nсеть с течением времени. С точки зрения вычисления градиента это означает, что \\nчем длиннее входная последовательность, тем глубже получается развернутая сеть.\\nДругая проблема, характерная для RNN, заключается в обработке долгосрочных \\nзависимостей. По мере увеличения длины входной последовательности векторы \\nпризнаков, находящиеся в начале последовательности, постепенно «забываются», \\nпотому что состояние всех узлов, которые играют роль памяти сети, в значительной'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='108   Глава 6. Нейронные сети и глубокое обучение\\nмере зависит от векторов признаков, прочитанных последними. Следовательно, \\nпри обработке текста или речи причинно-следственная связь между удаленными \\nсловами в длинном предложении может быть потеряна. Наиболее эффективными \\nрекуррентными моделями нейронных сетей, используемыми на практике, являются \\nвентильные RNN. К ним относятся сети с долгой краткосрочной памятью (Long \\nShort-Term Memory, LSTM) и сети с вентильными рекуррентными узлами (Gated \\nRecurrent Unit, GRU).\\nБлагодаря использованию вентильных узлов сети RNN получают способность хра-\\nнить информацию в своих узлах для будущего использования почти так же, как хра-\\nнятся биты в памяти компьютера. Разница лишь в том, что операции чтения, записи \\nи стирания информации, хранящейся в каждом узле, контролируются функциями \\nактивации, которые принимают значения в диапазоне (0, 1). Обученная нейронная \\nсеть может «прочитать» входную последовательность векторов признаков и  на \\nнекотором раннем временном шаге t решить сохранить конкретную информацию \\nо векторах признаков. Эта информация о более ранних векторах признаков может \\nпозже использоваться моделью для обработки векторов признаков в конце вход-\\nной последовательности. Например, если текст на входе начинается со слова она, \\nмодель RNN для обработки текстов может решить запомнить род местоимения, \\nчтобы правильно интерпретировать слово ее, следующее далее в предложении.\\nРешение о том, какую информацию хранить и когда разрешать чтение, запись \\nи удаление, принимают узлы. Эти решения принимаются на основе данных и ре-\\nализуются через идею вентилей (gates). Есть несколько архитектур управляемых \\nузлов. Простая, но эффективная называется минимальным вентильным узлом  \\nи состоит из ячейки памяти и вентиля забывания.\\nДавайте посмотрим, как действует узел GRU с математической точки зрения, \\nвзяв в качестве примера первый слой RNN (тот, который принимает входную по-\\nследовательность векторов признаков). Минимальный вентильный узел u в слое l \\nимеет два входа: вектор значений ячеек памяти из всех узлов в том же слое из \\nпредыдущего временного шага \\n  и вектор признаков xt. Он использует эти два \\nвектора следующим образом (все операции, представленные ниже, выполняются \\nузлом последовательно, друг за другом):'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='6.2. Глубокое обучение   109\\nгде g1 — функция активации tanh, g2 называется управляющей функцией и реали-\\nзуется как сигмоидная функция, принимающая значения в диапазоне (0, 1). Если \\nвентиль Γl,u близок к 0, тогда ячейка памяти сохраняет значение, полученное на \\nпредыдущем временном шаге \\n . Если вентиль Γl,u близок к 1, значение ячейки \\nпамяти затирается новым значением \\n  (см. третью сверху операцию). Как \\nи в стандартных сетях RNN, в роли g3 обычно используется функция softmax.\\nУправляемый узел принимает входные данные и хранит их \\nв течение некоторого времени. Это эквивалентно применению \\nк входу функции тождества (f (x) = x). Поскольку производная \\nфункции тождества является константой, когда сеть с управ-\\nляемыми узлами обучается с обратным распространением во \\nвремени, градиент не затухает.\\nК другим важным расширениям RNN относятся: двунаправленные RNN, RNN \\nс механизмом внимания и модели RNN преобразования последовательностей \\nв последовательности  (sequence-to-sequence). Последние, например, часто ис -\\nпользуются для реализации нейронных моделей машинного перевода и других \\nмоделей преобразования текста в текст. Обобщением RNN является рекурсивная \\nнейронная сеть.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='7 Проблемы и решения\\n7.1. Ядерная регрессия\\nРанее мы говорили о линейной регрессии, но что если исходные данные имеют \\nформу, отличную от прямой линии? В таких случаях может помочь полиноми -\\nальная регрессия. Допустим, у нас есть одномерные данные \\n . Мы мог-\\nли бы попытаться найти квадратичную линию y = w1xi + w2xi\\n2 + b, описывающую \\nнаши данные. Определив функцию стоимости как среднеквадратичную ошибку \\n(MSE), можно выполнить градиентный спуск и найти значения параметров w1, w2 \\nи b, минимизирующие эту функцию. В одно- или двумерном пространстве легко \\nувидеть, соответствует ли функция данным. Но если входные данные представ -\\nлены D-мерным вектором признаков с D > 3, тогда найти правильный полином \\nбудет сложно.\\nЯдерная регрессия (kernel regression) является непараметрическим методом. Это \\nозначает отсутствие параметров, которые должны определяться в процессе обуче-\\nния. Модель основана на самих данных (как kNN). В простейшем случае ядерная \\nрегрессия подбирает такую модель:\\n \\n .  (7.1)\\nФункция k(·) называется ядром (kernel). Ядро играет роль функции подобия: \\nзначения коэффициентов wi тем выше, чем ближе значение x к xi, и наоборот. Ядро'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='7.1. Ядерная регрессия   111\\nможет принимать разные формы. На практике наиболее часто используется ядро \\nГаусса:\\nЗначение b является гиперпараметром, который настраивается с использованием \\nконтрольного набора (путем применения модели, построенной с определенным \\nзначением b, к образцам в контрольном наборе и вычисления среднеквадратичной \\nошибки). На рис. 7.1 показано, как b влияет на форму линии регрессии.\\nтренировочные образцы\\nb\\n     \\nтренировочные образцы\\nb\\n Оптимальная модель Несколько переобученная модель\\nтренировочные образцы\\nb\\nСильно переобученная модель\\nРис. 7.1. Пример линий ядерной регрессии с ядром Гаусса для трех значений b\\nВ случае, когда входные данные являются многомерными векторами признаков, \\nчлены xi – x и xl – x в уравнении 7.1 следует заменить евклидовым расстоянием \\n|| xi –x || и || xl –x || соответственно.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='112   Глава 7. Проблемы и решения\\n7.2. Многоклассовая классификация\\nМногие задачи классификации можно определить с использованием двух классов, \\nно некоторые определены с использованием большего количества классов, что \\nтребует адаптации алгоритмов машинного обучения.\\nВ многоклассовой классификации метка может быть одним из C классов: \\n. Многие алгоритмы машинного обучения являются бинарными, на-\\nпример SVM. Некоторые алгоритмы можно модифицировать для решения задач \\nс множеством классов. ID3 и другие алгоритмы обучения деревьев решений можно \\nизменить, как показано ниже:\\nдля всех \\n , где S — листовой узел, в котором происходит прогнозиро-\\nвание.\\nЛогистическую регрессию можно естественным образом распространить на задачи \\nмногоклассового обучения, заменив сигмоидную функцию функцией softmax , \\nкоторую мы уже видели в главе 6.\\nАлгоритм kNN тоже легко распространить на случай многоклассовой классифи -\\nкации: отыскав k ближайших данных для входа x, нужно вернуть класс, которому \\nпринадлежит больше всего данных среди k.\\nАлгоритм SVM не получится естественным образом распространить на задачи \\nмногоклассовой классификации. Другие алгоритмы работают намного эффективнее, \\nкогда определены для двух классов. Что делать, если требуется решить задачу много-\\nклассовой классификации, но алгоритм обучения поддерживает только бинарную \\nклассификацию? В таких случаях часто используется стратегия, которая называется \\n«один против всех». Идея состоит в том, чтобы преобразовать задачу многоклас-\\nсовой классификации в C задач бинарной классификации и построить C бинарных \\nклассификаторов. Например, если есть три класса \\n , нужно создать копии \\nисходных наборов данных и модифицировать их. В первой копии заменить на 0 все \\nметки, не равные 1. Во второй копии заменить на 0 все метки, не равные 2. В третьей \\nкопии заменить на 0 все метки, не равные 3. После этого останется только решить три \\nзадачи бинарной классификации и обучить модели различать метки 1 и 0, 2 и 0 и 3 и 0.\\nПосле получения трех моделей для классификации нового входного вектора x, они \\nприменяются к входным данным и дают три прогноза. После этого остается только \\nвыбрать прогноз принадлежности к ненулевому классу, который является наиболее \\nдостоверным. Как вы помните, модель логистической регрессии возвращает  не \\nметку, а оценку (от 0 до 1), которую можно интерпретировать как вероятность, что'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='7.3. Одноклассовая классификация   113\\nметка является положительной. Этот показатель можно также интерпретировать \\nкак достоверность прогноза. В SVM аналогом достоверности является расстояние \\nd от входа x до границы решения:\\nЧем больше расстояние, тем достовернее прогноз. Большинство алгоритмов обуче-\\nния можно либо естественным путем преобразовать для многоклассового случая, \\nлибо с их помощью получить результат, который затем использовать в стратегии \\n«один против всех».\\n7.3. Одноклассовая классификация\\nИногда в наличии имеются только данные одного класса и нужно обучить модель, \\nкоторая будет отличать данные этого класса от всех остальных данных.\\nОдноклассовая классификация, также известная как унарная классификация, \\nили моделирование класса, решает задачу идентификации объектов определен -\\nного класса среди всех объектов через обучение на наборе, содержащем только \\nобъекты этого класса. Эта задача сложнее и отличается от традиционной задачи \\nклассификации, целью которой является выявление различий между двумя или \\nболее классами с помощью обучающего набора, содержащего объекты всех классов. \\nТипичным примером задачи одноклассовой классификации может служить клас-\\nсификация допустимого трафика в защищенной компьютерной сети. В этом сцена-\\nрии обычно имеется очень немного примеров трафика, порождаемого атакующим \\nзлоумышленником, если такие примеры вообще есть. Зато примеров допустимого \\nтрафика часто сколько угодно. Алгоритмы обучения одноклассовой классифика-\\nции используются для обнаружения выбросов, аномалий и новых данных.\\nЕсть несколько алгоритмов обучения одноклассовой классификации. На прак -\\nтике наиболее широко используются одноклассовые версии алгоритма Гаусса, \\nk средних, kNN и SVM.\\nИдея одноклассового алгоритма Гаусса состоит в моделировании данных, как если \\nбы они были получены из распределения Гаусса, точнее, из многомерного нормального \\nраспределения (Multivariate Normal Distribution, MND). Функция плотности вероят-\\nности (probability density unction, pdf) для MND задается следующим уравнением:'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='114   Глава 7. Проблемы и решения\\nгде fμ, Σ(x) возвращает плотность вероятности, соответствующую входному вектору \\nпризнаков x. Плотность вероятности можно интерпретировать как достоверность, \\nчто образец x был взят из распределения, которое мы смоделировали как MND. \\nЗначения μ (вектор) и Σ (матрица) являются параметрами, которые требуется опре-\\nделить по обучающим данным. Критерий максимального правдоподобия (анало-\\nгичный тому, что используется в задаче логистической регрессии) оптимизирован \\nдля поиска оптимальных значений этих двух параметров. \\n  — определитель \\nматрицы Σ; обозначение Σ–1 означает матрицу, обратную матрице Σ.\\nЕсли вы не знакомы с терминами определитель  и обратная матрица , не бес -\\nпокойтесь. Это стандартные операции над векторами и матрицами из области \\nматематики — теории матриц. Если у вас появится желание узнать, что это такое, \\nпочитайте «Википедию», где хорошо объясняются эти понятия.\\nНа практике числа в векторе μ определяют место, где находится центр кривой \\nгауссова распределения, а числа в Σ определяют форму кривой. На рис. 7.2 по-\\nказан пример гауссовой модели для случая с обучающим набором, состоящим из \\nдвумерных векторов признаков.\\nПосле построения модели и определения параметров μ и Σ по обучающим данным \\nспрогнозировать вероятность каждого входа x можно с помощью fμ, Σ(x). Если \\nполученная вероятность выше определенного порога, мы предсказываем, что об-\\nразец принадлежит нашему классу; иначе он классифицируется как аномальный. \\nЗначение порога определяется экспериментально или с использованием «обо -\\nснованного предположения».\\nКогда данные имеют более сложную форму, можно использовать более сложный \\nалгоритм, состоящий из нескольких гауссовых моделей (называется смесью гаус-\\nсовых распределений). В этом случае по данным определяется большее число \\nпараметров: по одному μ и Σ для каждого гауссова распределения, а также пара-\\nметры, управляющие объединением нескольких гауссовых моделей в одно значе-\\nние плотности распределения вероятности. В главе 9 мы рассмотрим применение \\nсмеси гауссовых распределений к задаче кластеризации.\\nОдноклассовые версии k средних и kNN основаны на принципах, \\nсхожих с  одноклассовой версией алгоритма Гаусса: создается \\nнекоторая модель данных и затем определяется порог принятия \\nрешения о сходстве нового вектора признаков с другими об -\\nразцами, согласно модели. В первом случае все обучающие при-\\nмеры группируются с использованием алгоритма кластеризации \\nk средних, и, когда появляется новый образец x, расстояние d(x) вычисляется как \\nминимальное расстояние между x и центром каждого кластера. Если d(x) меньше \\nопределенного порога, значит, x принадлежит этому классу.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='7.3. Одноклассовая классификация   115\\nРис. 7.2. Решение задачи одноклассовой классификации с использованием \\nодноклассовой версии метода Гаусса. Сверху: двумерные векторы признаков. \\nСнизу: кривая многомерного нормального распределения, которая максимизирует \\nправдоподобие данных сверху\\nОдноклассовая версия SVM, в зависимости от формулировки задачи, пытается \\nлибо 1) отделить гиперплоскостью все обучающие данные от начала координат \\n(в пространстве признаков) и максимизировать расстояние от этой гиперплоскости \\nдо начала координат, либо 2) определить сферическую границу вокруг данных, \\nминимизируя объем этой гиперсферы. Я оставляю изучение одноклассовых версий \\nалгоритмов kNN, k средних и SVM как самостоятельное упражнение.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='116   Глава 7. Проблемы и решения\\n7.4. Классификация с многими метками\\nИногда для описания образца из набора данных подходит более одной метки. \\nВ данном случае речь идет о классификации с многими метками.\\nНапример, для описания изображения на рис. 7.3 можем использовать одновре -\\nменно несколько меток: «хвойный лес», «горы», «дорога».\\nРис. 7.3. Изображение с метками «хвойный лес», «горы» и «дорога».  \\nФотограф Кейт Лагадия (Cate Lagadia)\\nЕсли число возможных значений для меток велико, но все они имеют одинаковую \\nприроду, как теги, каждый размеченный образец можно преобразовать в несколько \\nразмеченных данных, по одному для каждой метки. Все эти новые данные будут \\nиметь одинаковые векторы признаков и только одну метку. В результате задача \\nпревращается в  задачу многоклассовой классификации. Решить ее можно, ис -\\nпользуя стратегию «один против всех». Единственное отличие от обычной задачи \\nмногоклассовой классификации заключается в появлении нового гиперпараметра: \\nпорога. Если оценка подобия для какой-то метки выше порогового значения, эта \\nметка присваивается входному вектору признаков. В этом сценарии одному вектору \\nпризнаков может быть присвоено несколько меток. Значение порога выбирается \\nс использованием контрольного набора.\\nДля решения задачи классификации с многими метками аналогично можно при-\\nменять алгоритмы, которые естественным образом преобразуются в многоклас-\\nсовые (деревья решений, логистическая регрессия, нейронные сети и др.). Они \\nвозвращают оценку для каждого класса, поэтому мы можем определить порог'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='7.4. Классификация с многими метками   117\\nи затем присвоить одному вектору признаков несколько меток, для которых оценка \\nблизости превышает этот порог.\\nНейронные сети можно естественным образом обучить классификации с многими \\nметками, используя в качестве функции стоимости бинарную перекрестную энтро\\xad\\nпию (binary cross-entropy). Выходной слой нейронной сети в этом случае имеет по \\nодному узлу на метку. Каждый узел в выходном слое имеет сигмоидную функцию \\nактивации. Соответственно, каждая метка l является бинарной \\n , где \\nl = 1, ..., L и i = 1, ..., N. Бинарная перекрестная энтропия определяет вероятность \\n, что образец xi имеет метку l, определяется как \\nКритерий минимизации — простое среднее значение всех членов бинарной пере-\\nкрестной энтропии во всех обучающих образцах и всех их метках.\\nВ случаях, когда число возможных значений меток невелико, можно попробовать \\nпреобразовать задачу классификации с многими метками в задачу многоклассовой \\nклассификации. Представьте следующую задачу. Требуется присвоить изображе-\\nниям метки двух типов. Метки первого типа могут иметь два возможных значе -\\nния: {фото, живопись}; метки второго типа могут иметь три возможных значения: \\n{портрет, пейзаж, другое}. Для каждой комбинации двух исходных классов можно \\nсоздать новый фиктивный класс, например:\\nФиктивный \\nкласс Истинный класс 1 Истинный класс 2\\n1 фото портрет\\n2 фото пейзаж\\n3 фото другое\\n4 живопись портрет\\n5 живопись пейзаж\\n6 живопись другое\\nТеперь мы имеем те же самые размеченные данные, но заменили набор истинных \\nметок одной фиктивной меткой со значениями от 1 до 6. На практике такой под -\\nход дает хорошие результаты, когда возможных комбинаций классов не слишком \\nмного. В противном случае необходимо использовать гораздо больше данных для \\nобучения, чтобы компенсировать увеличение набора классов.\\nОсновное преимущество этого последнего подхода в том, что метки остаются коррели-\\nрованными, в отличие от методов, описанных выше, которые предсказывают каждую \\nметку независимо друг от друга. Во многих задачах корреляция между метками может \\nбыть существенным фактором. Например, представьте, что нужно классифицировать'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='118   Глава 7. Проблемы и решения\\nэлектронную почту как спам и не_спам, и одновременно как обычная и важная. Вы \\nнаверняка пожелали бы исключить такие прогнозы, как [спам, важная].\\n7.5. Обучение ансамбля\\nФундаментальные алгоритмы, которые мы рассмотрели в главе 3, имеют свои ограни-\\nчения. Из-за простоты иногда они не могут создать модель, достаточно эффективную \\nдля вашей задачи. В таких случаях можно попробовать использовать глубокие ней-\\nронные сети. Однако на практике глубокие нейронные сети требуют значительного \\nобъема размеченных данных, которых у вас может не быть. Другой способ повысить \\nэффективность простых алгоритмов обучения — использовать обучение ансамбля.\\nОбучение ансамбля — это парадигма обучения, которая основана на обучении не \\nодной сверхправильной модели, а большого числа моделей с низкой правильностью \\nи объединении прогнозов, данных этими слабыми моделями, для получения более \\nправильной метамодели.\\nМодели с низкой правильностью обычно обучаются слабыми алгоритмами об \\xad\\nучения, которые не способны обучать сложные модели и поэтому показывают \\nвысокую скорость работы на этапах обучения и прогнозирования. Наиболее часто \\nв роли слабого алгоритма используется алгоритм обучения дерева решений, кото-\\nрый обычно прекращает разбивать обучающий набор после нескольких итераций. \\nВ результате получаются мелкие и не очень правильные деревья, но, как гласит \\nидея обучения ансамбля, если деревья не идентичны и каждое дерево хотя бы не-\\nмного лучше случайного угадывания, мы можем получить высокую правильность, \\nобъединив большое количество таких деревьев.\\nЧтобы получить окончательный прогноз для входа x, прогнозы всех слабых моде-\\nлей объединяются с использованием некоторого метода взвешенного голосования. \\nКонкретная форма взвешивания голосов зависит от алгоритма, но сама суть не \\nзависит от него: если по совокупности слабые модели предсказывают, что электрон-\\nное письмо является спамом, мы присваиваем образцу x метку спам.\\nДвумя основными методами обучения ансамблей являются бустинг (boosting — \\nфорсирование) и бэггинг (bagging — агрегирование)1.\\n7.5.1. Бустинг и бэггинг\\nМетод бустинга заключается в использовании исходных обучающих данных \\nи итеративного создания нескольких моделей с применением слабого алгоритма. \\n1 Переводы терминов boosting и bagging неточные и не прижившиеся.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='7.5. Обучение ансамбля   119\\nКаждая новая модель отличается от предыдущих тем, что, конструируя ее, слабый \\nалгоритм пытается «исправить» ошибки, допускаемые предыдущими моделями. \\nОкончательная ансамблевая модель представляет собой комбинацию этих много-\\nчисленных слабых моделей, построенных итеративно.\\nСуть бэггинга заключается в создании множества «копий» обучающих данных \\n(каждая копия немного отличается от других) и последующем применении слабого \\nалгоритма к каждой копии с целью получить несколько слабых моделей, а затем \\nобъединить их. Широко используемым и эффективным алгоритмом машинного \\nобучения, основанным на идее бэггинга, является случайный лес.\\n7.5.2. Случайный лес\\n«Классический» алгоритм бэггинга работает следующим образом. Из имеющегося \\nобучающего набора создается B случайных выборок Sb (для каждого b = 1, ..., B) и на \\nоснове каждой выборки Sb строится модель fb дерева решений. Чтобы получить \\nвыборку Sb для некоторого b, производится выборка с заменой. То есть сначала \\nсоздается пустая выборка, а затем из обучающего набора выбирается случайный \\nобразец, и его точная копия помещается в Sb, при этом сам образец остается в ис-\\nходном обучающем наборе. Выбор данных продолжается, пока не выполнится \\nусловие | Sb | = N.\\nВ результате обучения получается B деревьев решений. Прогноз для нового об -\\nразца x, в случае регрессии, определяется как среднее из B прогнозов\\nили большинством голосов в случае классификации.\\nСлучайный лес имеет только одно отличие от классического бэггинга. Он ис -\\nпользует модифицированный алгоритм обучения дерева, который при каждом \\nрасщеплении в процессе обучения проверяет случайное подмножество признаков. \\nЭто делается с целью устранить корреляцию между деревьями: если один или не-\\nсколько признаков имеют большую прогнозирующую способность, многие деревья \\nбудут выбирать их для расщепления данных. Это приведет к появлению в «лесу» \\nбольшого числа коррелированных деревьев. Корреляция по признакам с большой \\nпрогнозирующей способностью препятствует повышению точности предсказания. \\nВысокая эффективность ансамбля моделей объясняется тем, что хорошие модели, \\nвероятнее всего, согласятся с одним и тем же прогнозом, а плохие — не согласятся \\nи дадут разные прогнозы. Корреляция сделает плохие модели более склонными \\nк согласию, что исказит картину голосования или повлияет на среднее значение.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='120   Глава 7. Проблемы и решения\\nНаиболее важными гиперпараметрами для настройки являются количество \\nдеревьев B и размер случайного подмножества признаков, которые необходимо \\nучитывать при каждом расщеплении.\\nСлучайный лес — один из наиболее широко используемых алгоритмов обучения \\nансамблей. Чем обусловлена его эффективность? Причина в том, что, используя \\nнесколько выборок из исходного набора данных, мы уменьшаем дисперсию конеч-\\nной модели. Помните, что низкая дисперсия означает слабую предрасположенность \\nк переобучению. Переобучение происходит, когда модель пытается объяснить \\nнебольшие вариации в наборе данных, потому что набор данных является лишь \\nнебольшой выборкой из всех возможных примеров явления, которое мы пытаемся \\nсмоделировать. В случае неудачного подхода к формированию обучающего набора \\nв него могут попасть некоторые нежелательные (но неизбежные) артефакты: шум, \\nаномальные и чрезмерно или недостаточно представительные данные. Создавая \\nнесколько случайных выборок с заменой обучающего набора, мы уменьшаем \\nвлияние этих артефактов.\\n7.5.3. Градиентный бустинг\\nДругой эффективный алгоритм обучения ансамблей, основанный на идее бу -\\nстинга, — градиентный бустинг. Сначала рассмотрим применение градиентного \\nбустинга в регрессии. Построение эффективной регрессионной модели мы начнем \\nс константной модели f = f0 (как мы это делали в ID3):\\nЗатем изменим метки во всех образцах i = 1, ..., N в обучающем наборе:\\n \\n   (7.2)\\nгде \\n  называется остатком и является новой меткой образца xi.\\nТеперь используем модифицированный обучающий набор с остатками вместо \\nоригинальных меток, чтобы построить новую модель дерева решений, f1. Модель \\nбустинга теперь определяется как \\n , где α — скорость обучения (гипер-\\nпараметр).\\nЗатем пересчитаем остатки с использованием уравнения 7.2, заменим метки в обу-\\nчающих данных еще раз, обучим новую модель дерева решений f2, переопределим \\nмодель бустинга как \\n  и будем повторять процесс, пока не объеди-\\nним предопределенное максимальное число M деревьев.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='7.5. Обучение ансамбля   121\\nДавайте интуитивно разберемся в том, что тут происходит. Вычисляя остатки, \\nмы определяем, насколько хорошо (или плохо) предсказывается цель каждого \\nобучающего образца текущей моделью f. Затем мы обучим другое дерево для \\nисправления ошибок текущей модели (именно поэтому мы используем остатки \\nвместо фактических меток) и добавим новое дерево в существующую модель \\nс некоторым весом α. В результате каждое новое дерево, добавленное в модель, \\nчастично исправляет ошибки, допущенные предыдущими деревьями. Процесс \\nпродолжается, пока не будет объединено максимальное количество M (еще один \\nгиперпараметр) деревьев.\\nТеперь попробуем ответить на вопрос, почему этот алгоритм называется градиент-\\nным бустингом. В градиентном бустинге мы не вычисляем градиент, в отличие от \\nтого, что мы делали в  главе 4, решая задачу линейной регрессии. Чтобы увидеть \\nсходство между градиентным бустингом и градиентным спуском, вспомните, для чего \\nмы вычисляли градиент в линейной регрессии: чтобы узнать направление изменения \\nзначений параметров для минимизации функции стоимости MSE. Градиент показы-\\nвает направление, но не показывает, как далеко идти в этом направлении, поэтому \\nв каждой итерации мы делали небольшой шаг, а затем вновь определяли направле-\\nние. То же происходит в градиентном бустинге, только вместо непосредственного \\nвычисления градиента мы используем его оценку в форме остатков: они показывают, \\nкак следует скорректировать модель, чтобы уменьшить ошибку (остаток).\\nВ градиентном бустинге доступны для настройки три основных гиперпараметра: \\nколичество деревьев, скорость обучения и глубина деревьев. Все три влияют на \\nточность модели. Глубина деревьев также влияет на скорость обучения и прогно-\\nзирования: чем меньше глубина, тем быстрее.\\nМожно показать, что обучение по остаткам оптимизирует общую модель f для \\nкритерия среднеквадратичной ошибки. Здесь можно заметить отличие от бэг -\\nгинга: бустинг уменьшает смещение (или недообученность) вместо дисперсии. \\nКак результат, бустинг подвержен переобучению. Однако, настраивая глубину \\nи количество деревьев, можно в значительной степени избежать переобучения.\\nВ задачах классификации градиентный бустинг применяется аналогично, но шаги \\nнемного отличаются. Рассмотрим случай бинарной классификации. Предположим, \\nесть M деревьев решений регрессии. По аналогии с логистической регрессией прогноз \\nансамбля деревьев решений моделируется с использованием сигмоидной функции:\\nгде \\n  и fm — дерево регрессии.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='122   Глава 7. Проблемы и решения\\nИ снова, как в логистической регрессии, при попытке найти модель f, максими-\\nзирующую \\n , применяется принцип максимального \\nправдоподобия. Точно так же, чтобы избежать числового переполнения, мы мак-\\nсимизируем сумму логарифмов правдоподобий, а не произведение правдоподобий.\\nАлгоритм начинает работу с  начальной константной модели \\n , где \\n. (Можно показать, что такая инициализация оптимальна для сигмо-\\nидной функции.) Затем в каждой итерации m в модель добавляется новое дерево fm. \\nЧтобы найти наилучшее дерево fm, сначала вычисляется частная производная gi \\nтекущей модели для каждого i = 1, ..., N:\\nгде f — модель ансамблевого классификатора, построенная на предыдущей итера-\\nции m — 1. Чтобы вычислить gi, нужно найти производные от \\n  \\nпо f для всех i. Обратите внимание, что \\n . Произ-\\nводная по f правого члена в предыдущем уравнении равна \\n.\\nЗатем выполняется преобразование обучающего набора заменой исходной мет -\\nки yi соответствующей частной производной gi, и на основе преобразованного \\nобучающего набора строится новое дерево fm. Далее определяется оптимальный \\nшаг обновления ρm как:\\nВ конце итерации m мы обновляем модель ансамбля f, добавляя новое дерево fm:\\nИтерации продолжаются, пока не выполнится условие m = M, после чего обучение \\nпрекращается и в результате получается модель ансамбля f.\\nГрадиентный бустинг является одним из самых мощных алгоритмов машинного \\nобучения. Не только потому, что создает очень точные модели, но и потому, что спо-\\nсобен обрабатывать огромные наборы данных с миллионами данных и признаков. \\nКак правило, он превосходит в точности случайный лес, но из-за последовательной \\nприроды может обучаться намного медленнее.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='7.6. Обучение маркировке последовательностей   123\\n7.6. Обучение маркировке \\nпоследовательностей\\nПоследовательность — один из наиболее распространенных типов структурирован-\\nных данных. Мы общаемся, используя последовательности слов и предложений, \\nмы выполняем действия в определенной последовательности, наши гены, музыка, \\nкоторую мы слушаем, видеофильмы, которые смотрим, наши наблюдения за не -\\nпрерывным процессом, таким как движение автомобиля или изменение цен акций \\nна бирже, — все это последовательности.\\nМаркировка последовательностей — это задача автоматического назначения ме-\\nток элементам последовательности. Обучающим набором для задачи маркировки \\nпоследовательностей является пара списков (X, Y), где X — список векторов при-\\nзнаков, по одному для каждого шага во времени, Y — список меток той же длины. \\nНапример, X может содержать слова в предложении, такие как [«большой», «кра-\\nсивый», «автомобиль»], а Y может содержать соответствующие части речи, такие \\nкак [«прилагательное», «прилагательное», «существительное»]). Более формально: \\nдля образца i, \\n , где sizei — длина последовательности в образце i, \\n и \\n .\\nВы уже знаете, что для маркировки последовательностей можно использовать RNN. \\nНа каждом временном шаге t она читает входной вектор признаков \\n , а послед-\\nний рекуррентный слой выводит метку \\n  (в случае бинарной маркировки) или \\n (в случае многоклассовой маркировки или маркировки с многими метками).\\nОднако RNN — не единственная возможная модель для маркировки последова -\\nтельностей. Модель, которая называется условные случайные поля (Conditional \\nRandom Fields, CRF), является очень эффективной альтернативой, которая \\nчасто дает хорошие результаты для векторов признаков, имеющих много ин -\\nформативных признаков. Например, представьте, что нам поставили задачу \\nреализовать извлечение именованных сущностей , и мы решили построить \\nмодель, которая маркировала бы каждое слово в предложении, например «Я еду \\nв Санкт-Петербург», одним из следующих классов: {местоположение, имя, назва-\\nние_компании, другое}. Если наши векторы признаков (представляющие слова) \\nсодержат такие бинарные признаки, как «слово начинается с заглавной буквы» \\nи «слово присутствует в списке местоположений», такие признаки будут очень \\nинформативными и помогут классифицировать слова Санкт и Петербург как \\nместоположение (так же, как и дефис между ними).\\nИзвестно, что определение признаков вручную — трудоемкий процесс, требующий \\nзначительных знаний в предметной области.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='124   Глава 7. Проблемы и решения\\nCRF — очень интересная модель, и ее можно рассматривать как обобщение логи-\\nстической регрессии на последовательности. Однако на практике для маркировки \\nпоследовательностей лучше использовать глубокие двунаправ-\\nленные вентильные RNN. CRF значительно медленнее в обуче-\\nнии, что затрудняет ее применение к большим обучающим на-\\nборам (с сотнями тысяч данных). Кроме того, там, где имеются \\nбольшие обучающие наборы, глубокие нейронные сети выглядят \\nособенно привлекательно.\\n7.7. Обучение преобразованию \\nпоследовательностей в последовательности\\nОбучение преобразованию последовательностей в последовательности (sequence-\\nto-sequence, сокращенно seq2seq) является обобщением задачи маркировки после-\\nдовательностей. В seq2seq Xi и Xi могут иметь разную длину. Модели seq2seq нашли \\nприменение в машинном переводе (где, например, вход — это предложение на англий-\\nском языке, а выход — соответствующее предложение на русском), диалоговых интер-\\nфейсах (где вход — это вопрос, введенный пользователем, а выход — ответ машины), \\nобобщении текста, исправлении орфографических ошибок и многих других сферах.\\nМногие, но не все задачи обучения seq2seq в настоящее время лучше всего решают-\\nся с помощью нейронных сетей. Все сетевые архитектуры, используемые в seq2seq, \\nсостоят из двух частей: кодировщика и декодировщика.\\nКодировщик — это нейронная сеть, принимающая последовательность. Это может \\nбыть рекуррентная сеть (RNN), сверточная (CNN) или сеть с какой-то другой ар-\\nхитектурой. Роль кодировщика состоит в том, чтобы прочитать входные данные \\nи сгенерировать некое состояние (аналогичное состоянию в RNN), которое можно \\nрассматривать как числовое представление смысла входных данных, с которым \\nможет работать машина. Смысл изображения, текста, видеоролика или чего-то \\nеще обычно представляется как вектор или матрица с действительными числами. \\nЭтот вектор (или матрица) на жаргоне машинного обучения называется вложением \\n(embedding) входных данных.\\nДекодировщик — это другая нейронная сеть, которая принимает на входе вложение \\nи генерирует выходную последовательность. Как вы уже могли догадаться, это \\nвложение создается кодировщиком. Чтобы создать выходную последовательность, \\nдекодировщик берет вектор признаков x(0) начала последовательности (обычно \\nвсе нули), генерирует первый выход y(1), обновляет свое состояние, комбинируя \\nвложение и вход x(0), а затем использует выход y(1) в качестве своего следующего \\nвхода x(1). Для простоты будем считать, что y(t) имеет ту же размерность, что и x(t),'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='7.7. Обучение преобразованию последовательностей в последовательности   125\\nхотя это необязательно. Как мы видели в главе 6, каждый слой RNN может гене-\\nрировать много выходов сразу: один может использоваться, чтобы сгенерировать \\nметку y(t), а другой, с другой размерностью, может использоваться как x(t).\\nКодировщик и декодировщик обучаются одновременно. Ошибки на выходе деко-\\nдировщика распространяются в кодировщик посредством механизма обратного \\nраспространения.\\nНа рис. 7.4 изображена традиционная архитектура seq2seq. Для \\nполучения более точных прогнозов можно использовать архитек-\\nтуры с механизмом внимания. Механизм внимания реализуется \\nс помощью дополнительного набора параметров, которые объ -\\nединяют некоторую информацию, полученную от кодировщика \\n(в RNN эта информация представлена списком векторов состо -\\nяния последнего рекуррентного уровня из всех временных шагов кодировщика), \\nс текущим состоянием декодировщика для получения метки. Это обеспечивает \\nдаже лучшую сохранность долгосрочных зависимостей, в сравнении с применением \\nвентильных узлов и двунаправленных RNN.\\nКодировщик Декодировщик\\nThe weather is fine < начало >\\nIl fait beau\\nt = 1234 12 3\\nРис. 7.4. Традиционная архитектура для обучения seq2seq. Векторное представление, \\nкоторое обычно определяется состоянием последнего слоя кодировщика, передается \\nиз левой подсети в правую\\nАрхитектура seq2seq с механизмом внимания показана на рис. 7.5.\\nОбучение seq2seq — относительно новая область исследований. Постоянно обна-\\nруживаются и публикуются новые архитектуры сетей. Обучение таких архитектур \\nможет быть сложной задачей, потому что количество настраиваемых гиперпара -'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='126   Глава 7. Проблемы и решения\\nметров и других архитектурных решений может быть огромным. Дополнительные \\nсведения, ссылки на руководства и примеры кода ищите в вики для книги.\\nThe weather is fine < начало >\\nIl faitb eau\\nt = 1234 12 3\\nМеханизм внимания\\nРис. 7.5. Архитектура seq2seq с механизмом внимания\\n7.8. Активное обучение\\nАктивное обучение — интересная парадигма обучения с учителем. Она обычно \\nприменяется, когда получение размеченных данных обходится слишком дорого. \\nЭто часто имеет место в медицинской или финансовой областях, где для марки -\\nровки данных о пациентах или клиентах может потребоваться привлекать экс -\\nпертов. Идея состоит в том, чтобы начать обучение с относительно небольшого \\nколичества размеченных и большого количества неразмеченных образцов, а затем \\nмаркировать только те образцы, которые в наибольшей степени способствуют по-\\nвышению качества модели.\\nЕсть несколько стратегий активного обучения. Здесь мы рассмотрим следующие \\nдве:\\n1. На основе плотности и неопределенности данных.\\n2. На основе метода опорных векторов.\\nПервая стратегия применяет текущую модель f, обученную с использованием \\nимеющихся размеченных данных, к  каждому из остальных неразмеченных дан -\\nных (или, чтобы сэкономить время, к некоторой случайной выборке из них). \\nДля каждого неразмеченного образца x вычисляется оценка его важности:'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='7.8. Активное обучение   127\\n. Плотность отражает количество ближай -\\nших данных, окружающих x, а неопределенностьf(x) — насколько неопределенным \\nявляется прогноз модели f для x. В бинарной классификации с сигмоидной функ-\\nцией чем ближе прогнозная оценка к 0.5, тем неопределеннее прогноз. В SVM: чем \\nближе образец к границе решения, тем неопределеннее прогноз.\\nВ многоклассовой классификации в качестве меры неопределенности можно ис-\\nпользовать энтропию:\\nгде \\n  — оценка вероятности, с какой модель f отнесет образец x к клас-\\nсу y(c). Как видите, если для каждого y(c) выполняется условие \\n , тогда \\nмодель является полностью неопределенной, а энтропия имеет максимальное зна-\\nчение 1; с другой стороны, если для некоторого y(c) выполняется условие \\n , \\nтогда модель полностью определена относительно класса y(c), а энтропия имеет \\nминимальное значение 0.\\nПлотность для образца x можно получить, взяв среднее значение расстояний от x \\nдо каждого из k ближайших к нему соседей (где k является гиперпараметром).\\nПосле вычисления оценок важности для всех неразмеченных дан-\\nных выбираем наибольшую и просим эксперта присвоить метку \\nсоответствующему образцу. Затем добавляем новый размеченный \\nобразец в обучающий набор, сроим модель заново и продолжаем \\nпроцесс, пока не будет удовлетворен некоторый критерий оста -\\nновки. Критерий остановки можно выбрать заранее (например, \\nмаксимальное количество обращений к эксперту, исходя из выделенного бюджета) \\nили положиться на некоторую метрику, определяющую качество работы модели.\\nСтратегия активного обучения с использованием метода опорных векторов за -\\nключается в построении модели SVM с использованием размеченных данных, \\nпосле чего эксперту предлагается присвоить метку неразмеченному образцу, нахо-\\nдящемуся ближе всех к гиперплоскости, разделяющей два класса. Идея в том, что, \\nесли образец ближе всех лежит к гиперплоскости, значит, он наименее определен \\nи его маркировка внесет наибольший вклад в определение точек, через которые \\nпроходит истинная (та, которую мы ищем) гиперплоскость.\\nНекоторые стратегии активного обучения могут включать стоимость обращения \\nк эксперту для маркировки. Другие учатся спрашивать мнение эксперта. Стратегия \\n«запрос комитетом» (query by committee) предполагает обучение нескольких мо-'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='128   Глава 7. Проблемы и решения\\nделей с применением разных методов, после чего эксперту предлагается присвоить \\nметку образцу, на котором модели разошлись во мнении больше всего. Некоторые \\nстратегии пытаются выбирать для маркировки такие данные, чтобы максимально \\nуменьшить смещение или дисперсию модели.\\n7.9. Обучение с частичным \\nпривлечением учителя\\nВ обучении с частичным привлечением учителя (Semi-Supervised Learning, SSL) \\nточно так же маркируется небольшая часть набора данных; большинство данных \\nостаются неразмеченными. Цель — использовать большое количество неразмечен-\\nных данных для повышения эффективности модели без запроса дополнительных \\nразмеченных данных.\\nВ истории науки было несколько попыток решить эту задачу. Но ни одно из реше-\\nний не получило общего признания и широкого применения на практике. Чаще \\nдругих упоминается метод SSL, который называется самообучением. В этом ме-\\nтоде с помощью алгоритма обучения и размеченных данных строится начальная \\nмодель. Затем эта модель применяется ко всем неразмеченным примерам и произ-\\nводится их маркировка. Если показатель достоверности прогноза для некоторого \\nнеразмеченного примера x выше некоторого порогового значения (выбранного \\nэкспериментально), этот размеченный пример добавляется в обучающий набор, \\nпроизводится повторное обучение модели, и так повторяется, пока не будет удов-\\nлетворен критерий остановки. Критерием остановки, например, может служить \\nотсутствие роста правильности модели в течение последних m итераций.\\nМетод, описанный выше, может обеспечить некоторое улучшение модели по \\nсравнению с использованием только исходного размеченного набора данных, но \\nобычно это улучшение не особо впечатляет. Кроме того, качество модели может \\nдаже снизиться. Это зависит от свойств статистического распределения, из кото-\\nрого взяты данные, которые обычно неизвестны.\\nС другой стороны, недавние достижения в обучении нейронных сетей привели к до-\\nвольно впечатляющим результатам. Например, было показано, что для некоторых \\nнаборов данных, таких как MNIST (тестовый набор, состоящий из размеченных \\nизображений рукописных цифр от 0 до 9, известный в сфере распознавания об-\\nразов), модель, обученная с частичным привлечением учителя, показывает почти \\nидеальную эффективность при наличии 10 размеченных образцов на класс (всего \\n100 размеченных данных). Для сравнения, MNIST содержит 70 000 размеченных \\nобразцов (60 000 для обучения и 10 000 для тестирования). Архитектура нейрон-'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='7.9. Обучение с частичным привлечением учителя   129\\nной сети, которая достигла такой замечательной производительности, называется \\nлестничной сетью . Чтобы понять идею, лежащую в основе лестничных сетей, \\nнужно сначала разобраться с понятием автокодировщик.\\nАвтокодировщик — это нейронная сеть прямого распространения с архитектурой \\nкодировщик-декодировщик. Она обучается восстанавливать свой вход. Соот -\\nветственно обучающий образец — это пара ( x, x). Нам нужно, чтобы, выход \\n  \\nмодели f(x) был максимально похож на вход x.\\nВажно отметить, что сеть автокодировщика напоминает песочные часы, имея узкий \\nслой «горлышка» в середине, который содержит вложение D-мерного входного \\nвектора. Обычно слой вложения имеет гораздо меньше узлов, чем D. Цель декоди-\\nровщика — восстановить входной вектор признаков из этого вложения. Теоретиче-\\nски достаточно 10 узлов в узком слое, чтобы успешно закодировать изображения \\nMNIST. В типичном автокодировщике, схематически изображенном на рис. 7.6, \\nв роли функции стоимости обычно используется либо среднеквадратическая \\nошибка (когда признаками могут быть любые числа), либо бинарная перекрест -\\nная энтропия (когда признаки имеют бинарную природу и узлы последнего слоя \\nдекодировщика имеют сигмоидную функцию активации). Когда используется \\nсреднеквадратическая ошибка, она определяется так:\\nгде \\n  — евклидово расстояние между двумя векторами.\\nКодировщик\\nДекодировщик\\nВложение\\nРис. 7.6. Автокодировщик'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='130   Глава 7. Проблемы и решения\\nАвтокодировщик с шумоподавлением  искажает левый элемент x в обучающем \\nобразце (x, x), добавляя в признаки некоторые случайные возмущения. В случае, \\nкогда данные являются черно-белыми изображениями — с пикселами, представлен-\\nными значениями от 0 до 1, — в каждый признак обычно добавляется нормальный \\nгауссов шум. Для каждого признака j во входном векторе x значение шума n(j) \\nвыбирается из следующего распределения:\\nгде символ ~ означает «выбирается из», π — это константа и θ =  \\ndef\\n [μ, s] — гипер-\\nпараметр. Новое искаженное значение признака x(j) получается путем сложения \\nx(j) + n(j) .\\nЛестничная сеть — это усовершенствованный шумоподавляющий автокодиров -\\nщик. Кодировщик и декодировщик имеют одинаковое количество слоев. Слой \\nузкого горлышка используется непосредственно для прогнозирования метки (с по-\\nмощью функции активации softmax). Сеть имеет несколько функций стоимости. \\nДля каждого слоя l в кодировщике и соответствующего слоя l в декодировщике \\nприменяется функция \\n , штрафующая за разность между выходами двух уровней \\n(квадрат евклидова расстояния). Когда во время обучения используется разме -\\nченный образец, применяется другая функция стоимости, Cc, которая штрафует \\nза ошибку в прогнозировании метки (отрицательный логарифм правдоподобия). \\nКомбинированная функция стоимости, \\n  (усредненная по всем об -\\nразцам в пакете), оптимизируется с помощью мини-пакетного стохастического \\nградиентного спуска с обратным распространением. Гиперпараметры λl для каждого \\nслоя l определяют компромисс между стоимостью классификации и кодирования-\\nдекодирования.\\nВ лестничной сети шумом искажается не только вход, но и выход каждого слоя \\nкодировщика (в процессе обучения). При применении обученной модели к ново-\\nму входу x для предсказания его метки этот вход не искажается.\\nСуществуют и другие методы обучения с частичным привлече-\\nнием учителя, не связанные с нейронными сетями. Один из них \\nпредполагает построение модели с использованием размеченных \\nданных и кластеризацию размеченных и неразмеченных данных \\nвместе с использованием любого метода кластеризации (не -\\nкоторые из них мы рассмотрим в главе 9). Для каждого нового \\nобразца выводится прогноз — метка, присущая большинству данных в кластере, \\nкоторому он принадлежит.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='7.10. Обучение с первого раза   131\\nЕще один метод, называемый S3VM, основан на использовании SVM. При его \\nиспользовании строится одна модель SVM для каждого возможного способа \\nмаркировки неразмеченных данных, а затем выбирается модель с наибольшим \\nзазором. В статье о S3VM (ссылку на которую вы найдете в вики) описывается \\nподход, который позволяет решить эту проблему без фактического перебора всех \\nвозможных способов маркировки.\\n7.10. Обучение с первого раза\\nЭта глава была бы неполной без упоминания двух других важных парадигм обу-\\nчения с учителем. Одна из них — обучение с первого раза (one-shot learning). \\nВ обучении с первого раза, которое обычно применяется для распознавания лиц, \\nтребуется построить модель, которая распознает, что две фотографии одного \\nчеловека действительно представляют одного и того же человека. Если показать \\nмодели две фотографии двух разных людей, она должна распознать, что это два \\nразных человека.\\nМожно попробовать решить эту задачу традиционным путем и построить бинарный \\nклассификатор, который принимает два изображения на входе и предсказывает \\nлибо истинное значение (если два изображения представляют одного и того же \\nчеловека), либо ложное (когда два изображения принадлежат разным людям). \\nОднако на практике это приведет к тому, что нейронная сеть окажется в два раза \\nбольше типичной нейронной сети, потому что для представления каждого из двух \\nизображений нужна своя подсеть. Обучить такую сеть будет сложно не только из-\\nза ее размера, но и потому, что получить положительные данные гораздо сложнее, \\nчем отрицательные. То есть задача крайне несбалансированная.\\nОдним из эффективных решений этой задачи является обучение сиамской нейрон\\xad\\nной сети (Siamese Neural Network, SNN). SNN можно реализовать как нейронную \\nсеть любого типа: CNN, RNN или MLP. Сеть принимает изображения по одному; \\nпоэтому размер сети не удваивается. Чтобы получить из сети бинарный класси -\\nфикатор «тот_же_человек»/«другой», который принимает на вход только одно \\nизображение за раз, сеть обучается особым образом.\\nДля обучения SNN мы используем функцию триплетной потери  (triplet loss). \\nНапример, пусть есть три изображения лица: изображение A (для привязки), \\nизображение P (положительное изображение) и изображение N (отрицательное \\nизображение). А и Р — два разных изображения одного и того же человека; N — \\nизображение другого человека. Каждый обучающий образец i теперь является \\nтриплетом (Ai, Pi, Ni).'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='132   Глава 7. Проблемы и решения\\nДопустим, у нас есть модель нейронной сети f, которая принимает изображение \\nлица на входе и выводит его векторное представление. Потеря триплета для об -\\nразца i определяется как\\n max(||f(Ai) – f(Pi)||2 – ||f(Ai) – f(Ni)||2 + α, 0).  (7.3)\\nФункция стоимости определяется как среднее потери триплета:\\nгде α — положительный гиперпараметр. Очевидно, что значение || f(A) – f(P) ||2 \\nнизко, когда нейронная сеть выводит одинаковые векторные представления для A \\nи P; значение || f(Ai) – f(Ni) ||2 высоко, когда векторные представления изображений \\nдвух разных людей различны. Если модель работает правильно, тогда член m =  \\n= (|| f(Ai) – f(Pi)||2 – || f(Ai) – f(Ni) ||2 всегда будет отрицательным, потому что большое \\nзначение будет вычитаться из маленького. Увеличивая α, можно еще уменьшить \\nчлен m, чтобы убедиться, что модель научилась надежно распознавать одинаковые \\nи разные лица. Если значение m недостаточно мало, то из-за α стоимость полу -\\nчится положительной и параметры модели скорректируются на этапе обратного \\nраспространения.\\nВместо выбора случайного изображения N лучший способ создания триплетов для \\nобучения — использовать текущую модель после нескольких эпох обучения и оты-\\nскивать кандидатов на N, которые похожи на A и P, согласно этой модели. Исполь-\\nзование случайных данных в качестве N значительно замедлит процесс обучения, \\nпоскольку нейронная сеть легко будет находить различия между изображениями \\nдвух случайных людей, из-за чего средняя потеря триплета в большинстве случаев \\nбудет низкой и параметры будут обновляться недостаточно быстро.\\nЧтобы построить SNN, сначала нужно выбрать архитектуру нейронной сети. На-\\nпример, для обработки изображений часто выбирается CNN. Чтобы вычислить \\nсредние потери триплета в нашем примере, мы последовательно применяем модель \\nк A, затем к P, затем к N, а потом вычисляем потери, используя уравнение 7.3. Про-\\nцедура повторяется для всех триплетов в партии, а затем вычисляется стоимость; \\nградиентный спуск с обратным распространением распространяет стоимость через \\nсеть и тем самым корректирует ее параметры.\\nМногие заблуждаются, думая, что для обучения с первого раза нужен только \\nодин обучающий образец каждой сущности. В действительности, чтобы модель \\nидентификации получилась точной, необходимо подобрать несколько образцов \\nдля каждого человека. Это обучение называется «с первого раза» из-за сферы \\nприменения таких моделей: для идентификации по лицу. Например, такую модель'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='7.11. Обучение без подготовки   133\\nможно использовать для разблокировки телефона. Если модель хорошо обучена, \\nвам достаточно будет хранить в телефоне только одну свою фотографию , и она \\nбудет уверенно узнавать вас, а также отличать других людей. Имея модель, которая \\nспособна определить, принадлежат ли два изображения A и \\n  одному и тому же \\nлицу, мы сравниваем \\n  с τ — гиперпараметром.\\n7.11. Обучение без подготовки\\nВ завершение главы я упомяну метод обучения без подготовки. Это относитель-\\nно новая область исследований, поэтому пока отсутствуют алгоритмы, доказав -\\nшие свою практическую ценность. Я только обрисую основную идею и оставлю \\nзнакомство с различными алгоритмами вам, как самостоятельное упражнение. \\nВ обу чении без подготовки (Zero-Shot Learning, ZSL) модель обучается назначать \\nметки объектам. Наиболее часто этот метод обучения применяется для назначения \\nметок изображениям. Однако, в отличие от стандартной классификации, модель \\nдолжна уметь прогнозировать метки, отсутствующие в обучающих данных. Как \\nтакое возможно?\\nХитрость заключается в использовании вложений, которые представляют не только \\nвходные данные x, но и выходные данные y. Представьте, что у нас есть модель, \\nкоторая для любого слова может сгенерировать вектор вложения, обладающий \\nследующим свойством: если по значению слово yi похоже на слово yk, векторы \\nвложения этих двух слов должны быть одинаковыми. Например, если yi — это \\nПариж, а yk — Рим, они будут иметь похожие векторные представления; с другой \\nстороны, если yk — это картошка, векторы вложения слов yi и yk должны быть \\nразными. Такие векторы вложения называют вложениями слов (word embeddings) \\nи обычно сравниваются с использованием мер косинусного сходства1.\\nВложения слов обладают важным свойством: каждое измерение во вложении \\nпредставляет определенную особенность значения слова. Например, если вло -\\nжение слов имеет четыре измерения (обычно их намного больше, от 50 до 300), \\nэти измерения могут представлять такие особенности значения, как животность, \\nабстрактность, кислость и желтизна (да, выглядит забавно, но это всего лишь \\nпример). Согласно такому определению, слово пчела будет иметь такое вложение: \\n[1, 0, 0, 1]. Слово желтый — такое: [0, 1, 0, 1]. Слово единорог — такое: [1, 1, 0, 0]. \\nЗначения для каждого вложения получаются с помощью специальной процедуры \\nобучения, применяемой к обширному текстовому корпусу.\\n1 В главе 10 я покажу, как получать вложения слов из данных.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='134   Глава 7. Проблемы и решения\\nТеперь, продолжая нашу задачу классификации, заменим метку yi каждого образ-\\nца i в обучающем наборе ее вложением слова и обучим модель классификации \\nс многими метками, которая предсказывает вложения слов. Чтобы получить мет-\\nку для нового образца x, нужно применить модель f к x, получить векторное пред-\\nставление \\n , а затем найти среди всех слов те, вложения которых наиболее похожи \\nна \\n , используя косинусное сходство.\\nПочему это работает? Возьмем, к примеру, зебру. Это млекопи-\\nтающее белого цвета с полосами. Теперь возьмем рыбу-клоуна: \\nэто не млекопитающее, имеет оранжевую окраску с полосами. \\nТеперь возьмем тигра: это млекопитающее оранжевого цвета \\nс полосами. Если эти три признака присутствуют во вложениях \\nслов, CNN научится обнаруживать эти признаки на изображени-\\nях. Даже если метка тигр отсутствовала в обучающих данных, но другие объекты, \\nвключая зебру и рыбу-клоуна, присутствовали, то CNN, скорее всего, научится \\nопределять понятия млекопитающее, оранжевый и полосы для предсказания меток \\nэтих объектов. Когда мы передадим в модель изображение тигра, эти признаки бу-\\nдут правильно идентифицированы на изображении, и, скорее всего, самым близким \\nвложением слова из нашего словаря окажется вложение слова тигр.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='8 Продвинутые методики\\nВ этой главе описываются методики, которые могут пригодиться вам в вашей \\nпрактике для решения некоторых задач. Она называется «Продвинутые методики» \\nне потому, что представленные здесь методы более сложные, а потому что они при-\\nменяются для решения узкоспециализированных задач. Во многих ситуациях эти \\nметодики вам едва ли потребуются, но иногда они оказываются очень полезными.\\n8.1. Работа с несбалансированными \\nнаборами данных\\nНа практике некоторые классы часто оказываются недостаточно представленны-\\nми в обучающих данных. Примером могут служить наборы данных, используе -\\nмые для обучения классификатора, различающего законные и мошеннические \\nтранзакции в электронной коммерции: данные законных транзакций встречаются \\nгораздо чаще. При использовании SVM с мягким зазором можно определить \\nстоимость для неправильно классифицированных данных. Поскольку в обуча-\\nющих данных всегда присутствует шум, высока вероятность, что многие данные \\nзаконных транзакций окажутся не на той стороне границы и это будет способ -\\nствовать увеличению цены.\\nАлгоритм SVM попытается сместить гиперплоскость, чтобы избежать как можно \\nбольшего числа ошибок в классификации данных. При этом стремление правильно \\nклассифицировать данные, принадлежащие к классу подавляющего большинства, \\nувеличивает риск неправильной классификации «мошеннических» данных, кото-\\nрые находятся в меньшинстве. Эта ситуация показана на рис. 8.1a. Эта проблема \\nнаблюдается в большинстве алгоритмов обучения, применяемых к несбалансиро-\\nванным наборам данных.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='136   Глава 8. Продвинутые методики\\nЕсли увеличить стоимость ошибочной классификации данных из класса меньшин-\\nства, то модель постарается избежать неправильной классификации этих данных, \\nно ценой неправильной классификации некоторых данных из класса большинства, \\nкак показано на рис. 8.1б.\\nНекоторые реализации SVM позволяют задавать вес каждого класса. Алгоритм \\nобучения учтет эту информацию при поиске лучшей гиперплоскости.\\nx(2)\\nx(1)         \\n(а)\\nx(2)\\nx(1)         \\n(б)\\nРис. 8.1. Иллюстрация проблемы несбалансированности набора данных. (a) Оба класса \\nимеют одинаковый вес; (б) данные в классе меньшинства имеют более высокий вес'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='8.2. Объединение моделей   137\\nЕсли алгоритм обучения не позволяет задавать вес классов, можно попробовать \\nметод увеличения выборки (oversampling). Он позволяет увеличить важность не-\\nкоторого класса путем создания нескольких копий данных из этого класса.\\nПротивоположный подход, сокращение выборки (undersampling), состоит в слу-\\nчайном исключении из обучающего набора некоторых данных из класса боль -\\nшинства.\\nТакже можно попробовать создать синтетические данные, случайно выбирая \\nзначения признаков из нескольких данных класса меньшинства и объединяя их \\nв новые данные этого класса. Есть два популярных алгоритма увеличения выбор-\\nки с образцами из класса меньшинства путем создания синтетических примеров: \\nметод расширения выборки меньшинства синтетическими образцами (Synthetic \\nMinority Oversampling Technique, SMOTE) и метод адаптивной синтетической \\nвыборки (Adaptive Synthetic Sampling, ADASYN).\\nМетоды SMOTE и ADASYN во многих отношениях действуют одинаково. Для \\nданного образца xi класса меньшинства они выбирают k ближайших его соседей \\n(обозначим этот набор из k данных как Sk), а затем создают синтетический обра-\\nзец xнов. как xi + λ(xzi –xi), где xzi — представитель класса меньшинства, выбранный \\nслучайным образом из Sk. Гиперпараметр интерполяции λ — это любое число \\nв диапазоне [0, 1].\\nОба метода, SMOTE и ADASYN, случайно выбирают все возможные xi в наборе \\nданных. В ADASYN число синтетических данных, генерируемых для каждого xi, \\nпропорционально количеству данных в Sk, не принадлежащих классу меньшинства. \\nСоответственно, в областях, где данные класса меньшинства встречаются редко, \\nгенерируется больше синтетических данных.\\nНекоторые алгоритмы менее чувствительны к проблеме несбалансированности \\nнабора данных. Деревья решений, а также случайный лес и градиентный бустинг ча-\\nсто показывают неплохую эффективность на несбалансированных наборах данных.\\n8.2. Объединение моделей\\nАнсамблевые алгоритмы, такие как случайный лес, обычно объединяют модели \\nодинаковой природы. Они увеличивают эффективность, объединяя сотни слабых \\nмоделей. На практике иногда можно получить дополнительный выигрыш в эффек-\\nтивности, комбинируя сильные модели, созданные с использованием различных \\nалгоритмов обучения. В этом случае обычно используются только две или три \\nтакие модели.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='138   Глава 8. Продвинутые методики\\nТри типичных способа объединения моделей: 1) усреднение, 2) большинство го -\\nлосов и 3) штабелирование.\\nУ среднение может применяться к  моделям регрессии, а  также к моделям клас-\\nсификации, которые дают классификационные баллы. В этом случае все модели, \\nназовем их базовыми моделями, применяются к входу x, а их прогнозы усредняются. \\nЧтобы увидеть, обеспечивает ли модель «усреднения» более высокое качество про-\\nгнозирования, чем каждый отдельный алгоритм, ее можно проверить на тестовом \\nнаборе с использованием метрики по вашему выбору.\\nМетод большинства голосов используется в моделях классификации. Согласно \\nэтому методу, все базовые модели применяются к входу x, а в качестве общего ре-\\nзультата возвращается класс, выбранный большинством моделей. Если несколько \\nклассов получили одинаковое число голосов, результат выбирается случайным \\nобразом или возвращается сообщение об ошибке (если неправильная классифи -\\nкация имеет высокую цену).\\nШтабелирование заключается в создании метамодели, которая принимает на вход \\nвыходы базовых моделей. Допустим, нужно объединить классификаторы f1 и f2, \\nкоторые выбирают предсказание из одного набора классов. Чтобы создать обуча-\\nющий образец \\n  для суммирующей модели, нужно задать \\n  \\nи \\n .\\nЕсли какие-то из базовых моделей возвращают не только класс, но и оценку прав-\\nдоподобия для каждого класса, эти оценки тоже можно использовать как признаки.\\nДля обучения штабелирующей модели рекомендуется использовать данные из \\nобучающего набора, а настройку гиперпараметров производить с помощью пере-\\nкрестной проверки.\\nРазумеется, эффективность штабелирующей модели следует проверить на кон -\\nтрольном наборе и сравнить с эффективностью базовых моделей.\\nУвеличение эффективности объединения нескольких моделей обусловлено \\nтем, что при согласии нескольких сильных некоррелированных моделей высока \\nвероятность, что они сойдутся во мнении в отношении правильного результата. \\nКлючевое слово здесь «некоррелированный». В идеале базовые модели должны \\nбыть получены с использованием разных признаков или алгоритмов с разной при-\\nродой — например, SVM и случайный лес. Объединение разных версий алгоритма \\nдерева решений или нескольких SVM с разными гиперпараметрами может не дать \\nзначительного увеличения качества прогнозирования.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='8.3. Обучение нейронных сетей   139\\n8.3. Обучение нейронных сетей\\nОдним из сложных аспектов в обучении нейронной сети является преобразование \\nданных во входы, которые сеть сможет обрабатывать. Если сеть должна обрабаты-\\nвать изображения, прежде всего необходимо привести все изображения к одному \\nразмеру. После этого обычно выполняется сначала стандартизация пикселов, а за-\\nтем нормализация в диапазон [0, 1].\\nТекст необходимо разбить на лексемы (то есть на такие части, как слова, знаки \\nпрепинания и другие символы). Для CNN и RNN каждая лексема преобразуется \\nв вектор с использованием унитарного кодирования, в результате чего текст пре-\\nвращается в список векторов. Другой, часто лучший способ представления лексем \\nзаключается в создании вложений слов. Для многослойного перцептрона неплохие \\nрезультаты, особенно для длинных текстов (длиннее, чем SMS-сообщения и тви-\\nты), можно получить, преобразуя тексты в векторы с использованием подхода \\n«мешок слов».\\nВыбор конкретной архитектуры нейронной сети является сложной задачей. На -\\nпример, для задачи обучения seq2seq уже создано множество архитектур и почти \\nкаждый год появляются новые. Я советую отыскать современные решения, подхо-\\nдящие для вашей конкретной задачи, с помощью поисковых систем Google Scholar \\nили Microsoft Academic, которые позволяют находить научные публикации по \\nключевым словам и диапазонам времени. Если вы не имеете ничего против менее \\nсовременных архитектур, поищите уже реализованные архитектуры на GitHub \\nи выберите такую, которую можно применить к вашим данным с минимальными \\nизменениями.\\nНа практике преимущество современной архитектуры перед более старой не так \\nважно, когда выполняются предварительная обработка, очистка и  нормализа-\\nция данных и создается больший обучающий набор. Современные архитектуры \\nнейронных сетей являются результатом сотрудничества ученых из нескольких \\nлабораторий и компаний; такие модели могут быть очень сложными для самосто-\\nятельной реализации и обычно требуют большой вычислительной мощности для \\nобучения. Время, потраченное на попытки воспроизвести результаты недавней \\nнаучной работы, может не стоить того. Это время лучше потратить на создание \\nрешения на основе пусть и менее современной, но стабильной модели, и получение \\nбольшего количества обучающих данных.\\nОпределившись с выбором архитектуры сети, нужно также определиться с ко-\\nличеством слоев, их типами и размерами. Рекомендую начать с одного или двух \\nслоев, обучить модель и посмотреть, хорошо ли она предсказывает обучающие \\nданные (имеет малое смещение). Если результат не удовлетворит вас, постепенно'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='140   Глава 8. Продвинутые методики\\nувеличивайте размер каждого слоя и  их количество, пока модель не будет иде -\\nально прогнозировать обучающие данные. Если модель дает высокое качество \\nна обучающих данных, но низкое на контрольных (имеет высокую дисперсию), \\nдобавьте в модель регуляризацию. Если после добавления регуляризации модель \\nначала плохо предсказывать обучающие данные, немного увеличьте размер сети. \\nПродолжайте итеративно наращивать сеть и регуляризовать, пока модель не до-\\nстигнет достаточно высокого качества предсказания обучающих и контрольных \\nданных в соответствии с вашей метрикой.\\n8.4. Продвинутая регуляризация\\nВ нейронных сетях кроме L1- и L2-регуляризации можно также использовать \\nтипы регуляризации, характерные для нейронных сетей: прореживание, ранняя \\nостановка и пакетная нормализация. Последний технически не является методом \\nрегуляризации, но он часто оказывает регулирующее влияние на модель.\\nИдея прореживания очень проста. Каждый раз, передавая в сеть обучающий обра-\\nзец, нужно на время отключать некоторые узлы. Чем выше процент отключенных \\nузлов, тем выше эффект регуляризации. Библиотеки нейронных сетей позволяют \\nдобавлять прореживающий слой между двумя соседними слоями или определить \\nв самом слое параметр, управляющий прореживанием. Параметр прореживания \\nможет иметь значение в диапазоне [0, 1], и его необходимо подобрать эксперимен-\\nтально, по результатам прогнозирования на контрольных данных.\\nРанняя остановка — это метод обучения нейронной сети, предусматривающий \\nсохранение предварительной модели после каждой эпохи и оценку ее эффектив-\\nности на контрольном наборе. Как рассказывалось в разделе о градиентном спуске \\nв главе 4, с увеличением количества эпох ошибка уменьшается. Уменьшение ошиб-\\nки означает высокое качество модели на обучающих данных. Однако в какой-то \\nмомент, после некоторой эпохи, может начать развиваться эффект переобучения: \\nошибка продолжает снижаться, но качество модели на контрольных данных ухуд-\\nшается. Если сохранять в файле версию модели после каждой эпохи, вы можете \\nпрекратить обучение, как только начнет наблюдаться снижение качества прогно-\\nзирования на контрольном наборе. Как вариант, можно продолжить процесс об -\\nучения в течение определенного количества эпох, а затем выбрать лучшую модель. \\nМодели, сохраненные после каждой эпохи, называются контрольными точками. \\nНекоторые специалисты, использующие машинное обучение на практике, очень \\nчасто используют этот прием; другие пытаются найти подходящий метод регуля-\\nризации, чтобы избежать такого нежелательного поведения.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='8.5. Обработка нескольких входов   141\\nПакетная нормализация (которую правильнее называть пакетной стандартизаци-\\nей) — это метод, заключающийся в стандартизации выходов каждого слоя перед \\nпередачей их узлам последующего слоя. На практике пакетная нормализация \\nувеличивает скорость и стабильность обучения, а также дает некоторый эффект \\nрегуляризации. Поэтому всегда полезно попробовать использовать пакетную \\nнормализацию. В библиотеках нейронных сетей часто есть возможность вставить \\nслой пакетной нормализации между двумя соседними слоями.\\nЕще один метод регуляризации, который можно применять не только к нейронным \\nсетям, но и практически к любому алгоритму обучения, называется расширением \\nданных (data augmentation). Этот метод часто используется для регуляризации \\nмоделей, работающих с изображениями. Получив исходный размеченный обу-\\nчающий набор, вы можете создать синтетический образец из исходного образца, \\nприменяя различные преобразования: слегка увеличивая размеры исходного \\nобразца, поворачивая, переворачивая, затемняя и т. д. В таких синтетических об-\\nразцах сохраняется оригинальная метка. На практике это часто дает увеличение \\nкачества модели.\\n8.5. Обработка нескольких входов\\nНа практике часто приходится работать с мультимодальными данными. Например, \\nна вход могут подаваться изображение и текст, а бинарный выход может опреде-\\nлять, описывает ли текст это изображение.\\nАлгоритмы поверхностного обучения трудно адаптировать для работы с мульти-\\nмодальными данными. Тем не менее это возможно. Можно попробовать обучить \\nдве поверхностные модели — одну для изображений, а другую для текста. После \\nэтого можно применить метод объединения моделей, описанный выше.\\nЕсли не получается разделить задачу на две независимые подзадачи, можно по -\\nпытаться преобразовать в вектор каждый вход (применяя соответствующий метод \\nпроектирования признаков), а затем просто объединить два вектора признаков, \\nчтобы сформировать один более широкий вектор признаков. Например, если \\nизображение имеет признаки [i(1), i(2), i(3)], а текст имеет признаки [t(1), t(2), t(3), t(4)], \\nтогда объединенный вектор признаков будет иметь вид [i(1), i(2), i(3), t(1), t(2), t(3), t(4)].\\nНейронные сети дают больше гибкости. Можно создать две подсети, по одной для \\nвхода каждого типа. Например, подсеть CNN может читать изображение, а под-\\nсеть RNN — текст. Последние слои обеих подсетей будут возвращать вложение: \\nCNN — вложение изображения, а RNN — вложение текста. После этого можно объ-\\nединить (конкатенировать) два вложения и добавить слой классификации, такой'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='142   Глава 8. Продвинутые методики\\nкак softmax или sigmoid, принимающий объединенные вложения. Библиотеки \\nнейронных сетей предлагают простые в использовании инструменты, которые \\nпозволяют объединять или усреднять выходы слоев из нескольких подсетей.\\n8.6. Обработка нескольких выходов\\nВ некоторых задачах требуется предсказать несколько выходов для одного входа. \\nВ предыдущей главе мы рассмотрели классификацию с многими метками. Неко-\\nторые задачи с несколькими выходами можно эффективно преобразовать в задачу \\nклассификации с многими метками. Особенно если они имеют метки одинаковой \\nприроды (например, теги). Или можно создать фиктивные метки, как комбинации \\nоригинальных меток.\\nОднако в некоторых случаях с мультимодальными выходами нет возможности \\nперечислить их комбинации. Рассмотрим следующий пример: нужно построить \\nмодель, которая обнаруживает объект на изображении и возвращает его коорди-\\nнаты. Кроме того, модель должна возвращать тег, описывающий объект, например: \\n«человек», «кошка» или «хомяк». В обучающих образцах имеется вектор при -\\nзнаков, представляющий изображение. Метка представлена вектором координат \\nобъекта и еще одним вектором с закодированным тегом.\\nВ ситуациях, подобных этой, можно создать одну подсеть, которая будет работать \\nкак кодировщик и читать входное изображение, используя, например, один или \\nнесколько сверточных слоев. Последним слоем кодировщика будет вложение \\nизображения. Поверх слоя с вложением можно добавить еще две подсети, одна \\nиз которых будет принимать вложение и предсказывать координаты объекта. Эта \\nпервая подсеть может иметь выходной слой ReLU, что является хорошим выбором \\nдля прогнозирования положительных действительных чисел, таких как коорди -\\nнаты, и использовать в качестве функции стоимости среднеквадратичную ошибку \\nC1. Вторая подсеть будет принимать то же вложение и прогнозировать вероятность \\nкаждой метки. Эта вторая подсеть может иметь выходной слой softmax, который \\nхорошо подходит для прогнозирования вероятностей, и использовать в качестве \\nфункции стоимости усредненный отрицательный логарифм правдоподобия C2 \\n(также называется стоимостью перекрестной энтропии).\\nОчевидно, что в этом случае важно, насколько точно предсказываются и коорди-\\nнаты, и метка. Однако невозможно оптимизировать сразу две функции стоимости. \\nЕсть риск, что оптимизация одного критерия пойдет в  ущерб другому. В такой \\nситуации можно добавить еще один гиперпараметр γ в диапазоне (0, 1) и опреде-'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='8.7. Перенос обучения   143\\nлить комбинированную функцию стоимости как γC1 + (1 – γ)C2, а затем настроить \\nзначение γ с использованием контрольных данных, как еще один гиперпараметр.\\n8.7. Перенос обучения\\nПеренос обучения (transfer learning) — это тот случай, когда нейронные сети имеют \\nуникальное преимущество перед поверхностными моделями. При переносе обуче-\\nния выбирается существующая модель, обученная на некотором наборе данных, \\nи адаптируется для прогнозирования данных из другого набора данных, отличного \\nот того, на котором была построена модель. Этот второй набор данных не похож \\nна контрольные наборы, которые используются для проверки и тестирования. \\nОн может представлять какое-то другое явление или, как говорят специалисты \\nпо машинному обучению, он может происходить из другого статистического рас-\\nпределения.\\nНапример, представьте, что вы обучили модель распознавать (и маркировать) \\nдиких животных, использовав большой набор размеченных данных. Через неко -\\nторое время вам предложили решить еще одну задачу: построить модель, которая \\nраспознавала бы домашних животных. С поверхностными алгоритмами обучения \\nу вас не так много вариантов: вам придется создать еще один большой набор раз-\\nмеченных данных, но уже для домашних животных.\\nПри использовании нейронных сетей ситуация обстоит намного лучше. Можно \\nвоспользоваться переносом обучения, который в нейронных сетях работает сле-\\nдующим образом.\\n1. На основе оригинального набора данных (с дикими животными) строится \\nглубокая модель.\\n2. Собирается намного меньший набор размеченных данных для второй модели \\n(с домашними животными).\\n3. С конца первой модели удаляется один или несколько слоев. Обычно это слои, \\nотвечающие за классификацию или регрессию, и следуют за слоем, создающим \\nвекторное представление (вложение).\\n4. Удаленные слои заменяются новыми, адаптированными для решения новой \\nзадачи.\\n5. Фиксируются («замораживаются») параметры слоев, доставшихся от первой \\nмодели.\\n6. С использованием небольшого набора размеченных данных и градиентного \\nспуска производится обучение параметров новых слоев.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='144   Глава 8. Продвинутые методики\\nВ интернете можно найти множество глубоких моделей для задач распознавания \\nобразов, и среди них вам вполне вероятно удастся найти ту, которая окажется \\nполезной для вашей задачи. Скачайте эту модель, удалите несколько последних \\nслоев (количество слоев для удаления — это гиперпараметр), добавьте свои слои \\nпрогнозирования и обучите полученную модель на ваших данных.\\nДаже если вы не найдете готовые модели, прием переноса обучения все равно смо-\\nжет помочь вам в ситуациях, когда задача требует очень дорогостоящего набора \\nразмеченных данных и есть возможность получить другой, более доступный набор \\nразмеченных данных. Допустим, вы строите модель классификации документов \\nи получили от заказчика список, содержащий тысячу категорий. В этом случае \\nвам нужно будет заплатить кому-то, чтобы тот: а) прочитал, понял и запомнил раз-\\nличия между категориями и б) прочитал до миллиона документов и разметил их.\\nЧтобы сэкономить на маркировке такого большого количества данных, вы можете \\nиспользовать страницы «Википедии» в качестве обучающего набора данных и по-\\nстроить свою первую модель. Метки для страницы в «Википедии» можно получить \\nавтоматически, взяв, например, категории, к которым относится страница. Обучив \\nпервую модель предсказывать категории из «Википедии», вы сможете «настроить» \\nэту модель, чтобы предсказать категории из списка вашего заказчика. Для решения \\nпоставленной задачи вам, вероятно, понадобится гораздо меньше размеченных \\nданных, чем если бы вы начали решать ее с нуля.\\n8.8. Эффективность алгоритмов\\nНе все алгоритмы, способные решить задачу, являются практичными. Некоторые \\nмогут работать слишком медленно. Некоторые задачи можно решить с помощью \\nбыстрого алгоритма, для других задач быстрых алгоритмов может и вовсе не су -\\nществовать.\\nРаздел информатики, называемый анализом алгоритмов, занимается проблемами \\nопределения и сравнения сложности алгоритмов. Для классификации алгоритмов \\nв соответствии с ростом их требований к времени выполнения или объему памяти \\nпри увеличении размера входных данных используется критерий О большое.\\nНапример, допустим, что у нас есть задача поиска двух самых удаленных друг \\nот друга одномерных данных в множестве S размера N. Один алгоритм для ре -\\nшения этой задачи мог бы выглядеть так (здесь и далее приводится реализация \\nна Python):'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='8.8. Эффективность алгоритмов   145\\n1 def find_max_distance(S):\\n2     result = None\\n3     max_distance = 0\\n4     for x1 in S:\\n5         for x2 in S:\\n6             if abs(x1 - x2) >= max_distance:\\n7                 max_distance = abs(x1 - x2)\\n8                 result = (x1, x2)\\n9     return result\\nАлгоритм выше перебирает все значения в S и в каждой итерации первого цикла \\nповторно перебирает все значения в S. То есть этот алгоритм выполняет N 2 сравне-\\nний чисел. Если время выполнения сравнения, вычисления абсолютного значения \\nи присваивания принять за единицу времени, тогда временная сложность (или про-\\nсто сложность) этого алгоритма в худшем случае составит 5N 2. (В каждой итерации \\nмы имеем одно сравнение, две операции вычисления абсолютного значения и две \\nоперации присваивания.) Когда измеряется сложность алгоритма в худшем случае, \\nиспользуется запись O большое. Сложность алгоритма выше можно записать как \\nO (N2); константы, такие как число 5, игнорируются.\\nТ у же задачу можно решить с помощью другого алгоритма:\\n1 def find_max_distance(S):\\n2     result = None\\n3     min_x = float(\"inf\")\\n4     max_x = float(\"-inf\")\\n5     for x in S:\\n6         if x < min_x:\\n7             min_x = x\\n8         if x > max_x:\\n9             max_x = x\\n10     result = (max_x, min_x)\\n11     return result\\nЭтот алгоритм предусматривает обход элементов множества S только один раз, \\nпоэтому он имеет сложность O (N). В таких случаях мы говорим, что этот алгоритм \\nэффективнее предыдущего.\\nАлгоритм считается эффективным, когда его сложность находится в полиноми-\\nальной зависимости от объема входных данных. Следовательно, эффективны оба \\nалгоритма, со сложностью O (N) и O (N 2), потому что N — это полином степени 1, \\nа N2 — полином степени 2. Однако для очень больших объемов входных данных \\nалгоритм O (N 2) может оказаться слишком медленным. В эпоху больших данных \\nученые часто стремятся отыскать алгоритмы O (log N).'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='146   Глава 8. Продвинутые методики\\nС практической точки зрения, реализуя свой алгоритм, старайтесь по возможности \\nизбегать циклов. Например, вместо циклов используйте операции с  матрицами \\nи векторами. В Python для вычисления wx вы должны написать:\\n1 import numpy\\n2 wx = numpy.dot(w,x),\\nа не\\n1 wx = 0\\n2 for i in range(N):\\n3     wx += w[i]*x[i]\\nИспользуйте подходящие структуры данных. Если порядок элементов в коллек-\\nции не имеет значения, используйте set вместо list. В Python операция провер-\\nки принадлежности конкретного экземпляра x множеству S выполняется более \\nэффективно, когда S объявлено как множество set, и менее эффективно, когда S \\nобъявлено как список list.\\nДругая важная структура данных, которую можно использовать для увеличения \\nэффективности кода на Python, — это словарь dict. В других языках он называется \\nтакже ассоциативным массивом. Словарь позволяет определить набор пар ключ/\\nзначение и обеспечивает очень быстрый поиск ключей.\\nЕсли у вас нет абсолютной уверенности в своих действиях, всегда старайтесь ис-\\nпользовать популярные библиотеки для научных вычислений. Пакеты для Python, \\nтакие как numpy, scipy и scikit-learn, были созданы опытными учеными и инженерами \\nи реализуют очень эффективные алгоритмы. Они предлагают множество методов, \\nнаписанных на языке программирования C, для максимальной эффективности.\\nЕсли вам понадобится выполнить обход элементов очень большой коллекции, ис-\\nпользуйте генераторы, которые создают функцию, возвращающую один элемент \\nза раз, а не все сразу.\\nИспользуйте пакет cProfile для поиска неэффективных фрагментов в своем коде \\nна Python.\\nНаконец, когда в вашем коде не осталось ничего, что можно было бы улучшить \\nс алгоритмической точки зрения, у вас все равно остается возможность увеличить \\nскорость выполнения кода, если задействовать:\\n  пакет multiprocessing для параллельного выполнения сразу нескольких вычис-\\nлений;\\n  PyPy, Numba или другие похожие инструменты для компиляции кода на \\nPython в быстрый и оптимизированный машинный код.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='9 Обучение без учителя\\nОбучение без учителя используется для решения задач, когда отсутствуют раз -\\nмеченные данные. Это свойство делает данный подход трудноприменимым для \\nрешения многих практических задач. Отсутствие меток, представляющих желаемый \\nрезультат, означает отсутствие надежной контрольной точки для оценки качества \\nмодели. В этой книге я представляю только методы обучения без учителя, позволя-\\nющие строить модели, которые можно оценить исключительно на основе данных, \\nа не человеческих суждений.\\n9.1. Оценка плотности\\nОценка плотности — это задача моделирования функции плотности вероятности \\n(probability density function, pdf) неизвестного распределения, из которого был по-\\nлучен набор данных. Этот метод может пригодиться во многих случаях, в частности \\nдля обнаружения новизны или факта вторжения. В главе 7 мы уже использовали \\nоценку функции плотности вероятности, когда решали задачу одноклассовой клас-\\nсификации. Тогда мы решили, что наша модель будет параметрической, а точнее, \\nмногомерным нормальным распределением (Multivariate Normal Distribution, \\nMND). Это решение было несколько произвольным, потому что, если фактическое \\nраспределение, из которого получен набор данных, отличается от MVN, модель, \\nскорее всего, будет далека от идеальной. Мы также знаем, что модели могут быть \\nнепараметрическими. Мы использовали непараметрическую модель в ядерной \\nрегрессии. Как оказывается, тот же подход можно применять для оценки плотности.\\nПусть \\n  — набор одномерных данных (решение задачи для многомерного слу-\\nчая выглядит аналогично), полученный из распределения с неизвестной функцией \\nплотности вероятности f с \\n  для всех i = 1, ..., N. Нам требуется смоделировать \\nформу f. Наша ядерная модель f, обозначенная как \\n , определяется как\\n \\n   (9.1)'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='148   Глава 9. Обучение без учителя\\nгде b — гиперпараметр, управляющий компромиссом между смещением и диспер-\\nсией модели, а k — ядро. Так же как в главе 7, используем ядро Гаусса:\\nТребуется найти значение b, минимизирующее разницу между фактической фор-\\nмой f и формой нашей модели \\n . Для оценки разницы разумно выбрать средний \\nнакопленный квадрат ошибки (Mean Integrated Squared Error, MISE):\\n \\n   (9.2)\\nВ уравнении 9.2 мы возводим в квадрат разницу между фактической pdf f и нашей \\nмоделью \\n . Интеграл \\n  заменяет суммирование \\n  в среднеквадратичной \\nошибке, а оператор ожидания \\n  заменяет среднее значение \\n .\\nДействительно, когда потеря является функцией с непрерывной областью значе-\\nний, такой как \\n , мы должны заменить суммирование интегралом. \\nОперация ожидания \\n  означает, что b должно быть оптимальным для всех возмож-\\nных реализаций обучающего набора \\n . Это важно, потому что \\n  определена \\nна конечной выборке некоторого распределения вероятностей, а фактическая pdf f \\nопределена в бесконечной области (множество \\n ).\\nТеперь перепишем правую сторону уравнения 9.2, как показано ниже:\\nТретий член в формуле выше не зависит от b, следовательно, его можно игнориро-\\nвать. Несмещенная оценка первого слагаемого задается как \\n , тогда как \\nнесмещенную оценку второго слагаемого можно аппроксимировать перекрестной \\nпроверкой \\n , где \\n  — ядерная модель f, вычисленная на обучаю-\\nщем наборе после исключения образца xi.\\nЧлен \\n  известен в статистике как оценка с одним отделяемым объектом, \\nформа перекрестной проверки, в которой каждый блок состоит из одного образца. \\nВозможно, вы заметили, что член \\n  (назовем его a) — это ожидаемое \\nзначение функции \\n , потому что f — это функция плотности вероятности (pdf). \\nМожно показать, что оценка с одним отделяемым объектом является несмещенной \\nоценкой \\n .'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='9.2. Кластеризация   149\\nобучающие данные\\nистинная pdf\\n    \\nобучающие данные\\nистинная pdf\\n (а)  (б)\\nистинная pdf\\nобучающие данные\\n    \\n (в) (г)\\nРис. 9.1. Ядерная оценка плотности: (a) хорошее соответствие; (б) модель переобучена; \\n(в) модель недообучена; (г) кривая поиска по сетке для выбора оптимального значения b\\nТеперь, чтобы найти оптимальное значение b* для b, минимизируем стоимость, \\nкоторая определяется как\\nНайти b* можно с помощью поиска по сетке. Для D-мерных векторов признаков член \\nошибки x – xi в уравнении 9.1 можно заменить евклидовым расстоянием || x – xi ||. На \\nрис. 9.1 показаны оценки для одной и той же pdf, полученные с тремя разными зна-\\nчениями b из набора данных со 100 образцами, а также кривая поиска по сетке. Мы \\nвыбираем значение b*, соответствующее нижней точке на кривой поиска по сетке.\\n9.2. Кластеризация\\nКластеризация — это задача обучения выбору меток для данных с использовани-\\nем набора неразмеченных данных. Поскольку набор данных не содержит меток,'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='150   Глава 9. Обучение без учителя\\nоценить оптимальность полученной модели намного сложнее, чем в обучении \\nс учителем.\\nСуществует множество алгоритмов кластеризации, и, к сожалению, сложно сказать, \\nкакой из них окажется лучшим для того или иного набора данных. Обычно каче-\\nство работы каждого алгоритма зависит от неизвестных свойств распределения, \\nиз которого был получен набор данных. В этой главе я опишу наиболее полезные \\nи широко используемые алгоритмы кластеризации.\\n9.2.1. Кластеризация k средних\\nАлгоритм кластеризации k средних работает следующим образом. Сначала вы -\\nбирается k — количество кластеров. Затем в пространстве признаков случайным \\nобразом выбираются k векторов признаков, называемых центроидами.\\nЗатем, с использованием некоторой метрики, например евклидова расстояния, вы-\\nчисляется расстояние от каждого образца x до каждого центроида. Затем каждому \\nобразцу ставится в соответствие ближайший центроид (как если бы мы назначали \\nкаждому образцу метку с идентификатором центроида). Для каждого центроида \\nвычисляется средний вектор признаков данных, связанных с ним. Эти средние \\nвекторы признаков становятся новыми местоположениями центроидов.\\nДалее снова вычисляется расстояние от каждого образца до каждого центроида и из-\\nменяется его метка. Процедура повторяется до тех пор, пока после очередного пере-\\nсчета местоположений центроидов связи не останутся неизменными. Модель пред-\\nставляет собой список связей между идентификаторами центроидов и образцами.\\nНачальное положение центроидов влияет на конечные положения, поэтому два \\nпрогона алгоритма k средних могут дать две разные модели. Некоторые вариан -\\nты k средних вычисляют начальные положения центроидов, исходя из некоторых \\nсвойств набора данных.\\nНа рис. 9.2 показан один прогон алгоритма k средних. Кружки на рис. 9.2 представля-\\nют двумерные векторы признаков; квадраты — движущиеся центроиды. Различные \\nцвета фона представляют области, в которых все точки принадлежат одному кластеру.\\nЗначение k — количество кластеров — является гиперпараметром, который вы -\\nбирается аналитиком. Существует несколько методов выбора k, но ни один не \\nявляется оптимальным. Большинство из этих методов требуют, чтобы аналитик \\nсделал «обоснованное предположение», просматривая некоторые метрики или \\nвизуально изучая разбиение на кластеры. В этой главе я представлю один из под-\\nходов, помогающий выбрать достаточно хорошее значение для k, не требующий \\nпросматривать данные и делать какие-либо предположения.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='9.2. Кластеризация   151\\n    \\n Исходные данные Итерация 1\\n    \\n Итерация 3 Итерация 5\\nРис. 9.2. Ход выполнения алгоритма k средних для k = 3\\n9.2.2. DBSCAN и HDBSCAN\\nВ отличие от k средних и других подобных алгоритмов, основанных на центрои -\\nдах, алгоритм DBSCAN осуществляет кластеризацию на основе плотности. Алго-\\nритм DBSCAN не требует угадывать количество кластеров, вместо этого нужно \\nопределить два гиперпараметра: ϵ и n. В самом начале выбирается случайный \\nобразец x и маркируется как принадлежащий кластеру 1. Затем подсчитывается \\nчисло данных, расстояние от которых до x меньше или равно ϵ. Если это число \\nбольше или равно n, тогда все эти ϵ-соседи помещаются в один и тот же кластер 1. \\nЗатем проверяется каждый член кластера 1 и выявляются соответствующие им \\nϵ-соседи. Если какой-либо член кластера 1 имеет n или больше ϵ-соседей, все они \\nтоже добавляются в кластер 1. Процесс расширения кластера 1 продолжается, пока \\nне останется данных, которые можно было бы добавить в него. После этого из на-\\nбора данных выбирается другой образец, не принадлежащий ни одному кластеру,'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='152   Глава 9. Обучение без учителя\\nи помещается в кластер 2. Так продолжается до тех пор, пока все данные не будут \\nпринадлежать какому-либо кластеру или не будут отмечены как аномальные. \\nАномальный образец — это образец, имеющий меньше n ϵ-соседей.\\nПреимущество алгоритма DBSCAN состоит в том, что он может создавать кластеры \\nпроизвольной формы, в то время как k средних и другие алгоритмы на основе цен-\\nтроидов создают кластеры, имеющие форму гиперсферы. Очевидный недостаток \\nDBSCAN в том, что он имеет два гиперпараметра, выбор хороших значений для \\nкоторых (особенно для ϵ) может вызывать затруднения. Кроме того, с фиксирован-\\nным гиперпараметром ϵ алгоритм кластеризации не может эффективно работать \\nс кластерами, имеющими различную плотность.\\nHDBSCAN — это алгоритм кластеризации, сохраняющий преимущества DBSCAN \\nи устраняющий необходимость выбирать значение ϵ. Алгоритм способен строить \\nкластеры, имеющие разную плотность. HDBSCAN  — это искусная комбинация \\nмножества идей, так что полное описание алгоритма выходит за рамки этой книги.\\nHDBSCAN имеет только один важный гиперпараметр: n, минимальное количество \\nданных в одном кластере. Этот гиперпараметр относительно легко выбрать, осно-\\nвываясь на интуиции. HDBSCAN имеет очень быстрые реализации, способные \\nэффективно работать с миллионами данных. Современные реализации k средних \\nнамного быстрее, чем HDBSCAN, однако качества последнего могут перевесить \\nего недостатки при решении многих практических задач. Я рекомендую всегда \\nпробовать использовать HDBSCAN для ваших данных в первую очередь.\\n9.2.3. Определение числа кластеров\\nСамый важный вопрос — сколько кластеров в наборе данных? Когда векторы при-\\nзнаков одно-, дву- или трехмерные, можно нарисовать распределение данных на \\nграфике и увидеть «облака» точек в пространстве признаков. Каждое облако — это \\nпотенциальный кластер. Однако для D-мерных данных, с D > 3, нарисовать такой \\nграфик проблематично1.\\nОдин из способов определения разумного количества кластеров основан на идее \\nпрогнозирующей силы. Суть состоит в том, чтобы разделить данные на обучающий \\nи тестовый наборы, как это делается в обучении с учителем. Выделив обучающий \\nи тестовый наборы, Str с размером Ntr и Ste с размером Nte соответственно, вы фикси-\\n1 Некоторые аналитики строят несколько двумерных графиков, на которых одновременно \\nприсутствует только пара признаков. Это тоже может дать представление о количестве \\nкластеров. Однако такой подход страдает субъективностью, подвержен ошибкам и счи-\\nтается обоснованным предположением, а не научным методом.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='9.2. Кластеризация   153\\nруете количество кластеров k, запускаете алгоритм кластеризации C на наборах Str \\nи Ste и получаете результаты кластеризации C(Str, k) и C(Ste, k).\\nПусть A — результат кластеризации C(Str, k), полученный для обучающего набора. \\nКластеры в A можно рассматривать как области. Если образец попадает в одну из \\nэтих областей, значит, он принадлежит некоторому конкретному кластеру. Напри-\\nмер, если применить алгоритм k средних к некоторому набору данных, в результате \\nполучится разбиение пространства признаков на k многоугольных областей, как \\nпоказано на рис. 9.2.\\nОпределим матрицу N te × Nte совместной принадлежности D[A, Ste], элементы \\nкоторой D[A, Ste](i, i`) = 1 тогда и только тогда, когда данные xi и xi`  из тестового на-\\nбора принадлежат тому же кластеру, согласно разбиению A. В противном случае \\nD[A, Ste](i, i`) = 0.\\nА теперь прервемся и посмотрим, что у нас получилось. Мы создали разбиение A, \\nиспользовав обучающий набор данных, на k кластеров. Затем построили матрицу \\nсовместной принадлежности, которая указывает, принадлежат ли два образца из \\nтестового набора одному кластеру в A.\\nОчевидно, что если величина k является разумной, тогда два образца, принадлежа-\\nщие одному кластеру в решении C(Ste, k), скорее всего, будут принадлежать одному \\nкластеру в решении и C(Str, k). С другой стороны, если значение k не является \\nразумным (слишком высокое или слишком низкое), тогда разбиения на основе \\nобучающих и тестовых данных, вероятно, будут менее согласованными.\\nНа рис. 9.3 показаны использованные данные, а рис. 9.4 иллюстрирует идею. Гра-\\nфики на рис. 9.4a и 9.4б показывают результаты C(Str, 4) и C(Ste, 4) с соответству-\\nющими областями кластеров. На рис. 9.4в показаны тестовые данные, нанесенные \\nна области кластеров, полученных в ходе кластеризации обучающих данных. На \\nрис. 9.4в можно видеть, что оранжевые тестовые данные больше не принадлежат \\nодному кластеру в соответствии с областями, полученными на обучающих данных. \\nВ результате в матрице D[A, Ste] появляется множество нулей, что в свою очередь \\nпоказывает, что k = 4, вероятно, не лучшее число кластеров.\\nБолее формально прогнозирующая сила числа кластеров k определяется как\\nгде \\n , Aj — j-й кластер из разбиения C(Ste, k) и | Aj | — число данных \\nв кластере Aj.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='154   Глава 9. Обучение без учителя\\n    \\n Полный набор данных Обучающий набор\\nТестовый набор\\nРис. 9.3. Данные, использованные в задаче кластеризации,  \\nрешение которой показано на рис. 9.4\\nС учетом разбиения C(Str, k) для каждого тестового кластера вычисляется доля \\nпар в нем, которые также попали в один и тот же кластер, определяемый центро-\\nидом для обучающего набора. Прогнозирующая сила определяется как минимум \\nэтой величины для k тестовых кластеров.\\nКак показывают эксперименты, разумное количество кластеров \\nявляется наибольшим k при ps(k) выше 0.8. На рис 9.5 показаны \\nпримеры определения прогнозирующей силы разных значений k \\nдля данных, делящихся на два, три и четыре кластера.\\nДля недетерминированных алгоритмов кластеризации, таких как \\nk средних, которые могут генерировать разные варианты разбиения, в зависимо-\\nсти от начальных положений центроидов, рекомендуется выполнить несколько \\nпрогонов алгоритма кластеризации для одного и того же k и вычислить среднюю \\nпрогнозирующую силу \\n .'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='9.2. Кластеризация   155\\n   \\n (а) (б)\\n(в)\\nРис. 9.4. Результат кластеризации для k = 4: (a) результат кластеризации обучающего \\nнабора; (б) результат кластеризации тестового набора; (в) тестовые данные, нанесенные \\nповерх результатов кластеризации обучающего набора\\nДругой эффективный метод оценки количества кластеров называется статистикой \\nразрывов (gap statistic). К другим, менее автоматизированным методам, которые \\nвсе еще используются некоторыми аналитиками, относятся метод «локтя» (elbow \\nmethod) и метод среднего силуэта (average silhouette).\\n9.2.4. Другие алгоритмы кластеризации\\nМетоды DBSCAN и k средних реализуют так называемую жесткую кластери \\xad\\nзацию, в которой каждый образец может принадлежать только одному класте -\\nру.  Модель смеси гауссовых распределений  (Gaussian Mixture Model, GMM) \\nдопускает включение каждого образца в несколько кластеров с разным баллом \\nчленства (HDBSCAN тоже поддерживает такую возможность). Кластеризация'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='156   Глава 9. Обучение без учителя\\n    \\n    \\n    \\nРис. 9.5. Прогнозирующая сила разных значений k для данных, делящихся на два, \\nтри и четыре кластера\\nметодом GMM очень похожа на оценку плотности на основе модели. В GMM \\nвместо одного многомерного нормального распределения (MND) используется \\nвзвешенная сумма нескольких MND:'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='9.2. Кластеризация   157\\nгде fμj, Σj\\n — многомерное нормальное распределение j, а ϕj — его вес в сумме. Значения \\nпараметров μj, Σj и ϕj для всех j = 1, ..., k получаются с использованием алгоритма \\nмаксимизации ожидания  (Expectation Maximization, EM), оптимизирующего \\nкритерий максимального правдоподобия.\\nИ снова ради простоты рассмотрим пример с одномерными данными. Также пред-\\nположим, что есть два кластера: k = 2. В этом случае мы имеем два распределения \\nГаусса\\n  (9.3)\\nгде \\n  и \\n  — две функции плотности вероятности (pdf), опре-\\nделяющие вероятность X = x.\\nИспользуем алгоритм EM (максимизации ожидания) для оценки μ1, \\n , μ2, \\n , ϕ1 \\nи ϕ2. Параметры ϕ1 и ϕ2 больше пригодятся для оценки плотности, чем для класте-\\nризации, как мы увидим ниже.\\nАлгоритм EM действует, как описывается далее. Сначала выбираем наугад на -\\nчальные значения μ1, σ1\\n2, μ2 и \\n  и устанавливаем ϕ1 = ϕ2 = 1/2 (в общем случае 1/k \\nдля каждого ϕj, j ∈ 1, …, k).\\nВ каждой итерации алгоритма EM выполняются четыре шага:\\n1. Для всех i = 1, ..., N вычисляется вероятность для каждого xi с использованием \\nуравнения 9.3:\\n2. С использованием правила Байеса для каждого образца xi вычисляется веро-\\nятность \\n  его принадлежности кластеру j ∈ {1, 2} (то есть вероятность, что \\nобразец получен из распределения Гаусса j):\\nПараметр ϕj отражает вероятность, что распределение Гаусса j с параметрами μj и \\n  \\nмогло дать наш набор данных. Вот почему вначале мы устанавливаем ϕ1 = ϕ2 = 1/2: \\nмы не знаем, насколько вероятно каждое из двух распределений, и отражаем нашу \\nнеосведомленность, устанавливая вероятность того и другого равной одной второй.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='158   Глава 9. Обучение без учителя\\nистинная pdf\\nобучающие данные\\n   \\nистинная pdf\\nобучающие данные\\nистинная pdf\\nобучающие данные\\n    \\nистинная pdf\\nобучающие данные\\nРис. 9.6. Ход создания модели смеси гауссовых распределений с использованием \\nалгоритма EM для двух кластеров (k = 2)\\n3. Вычисляются новые значения \\n  и \\n , \\n  как\\n \\n   (9.4)\\n4. Корректируется \\n , \\n  как\\nШаги 1–4 повторяются, пока значения μ j и \\n  не перестанут существенно из -\\nменяться: например, изменение становится меньше, чем некоторое пороговое \\nзначение ϵ. Этот процесс иллюстрирует рис. 9.6.\\nВозможно, вы обратили внимание, что алгоритм EM очень похож на алгоритм k \\nсредних: сначала случайно выбираются кластеры, затем в цикле корректируются'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='9.3. Сокращение размерности   159\\nпараметры каждого кластера путем усреднения данных, связанных с этим класте-\\nром. Единственное отличие GMM от EM состоит в том, что образец xi связывается \\nс кластером j не жестко: xi принадлежит кластеру j с вероятностью \\n . Вот поче-\\nму новые значения для μj и \\n  в уравнении 9.4 вычисляются не как средние (как \\nв методе k средних), а как средневзвешенные, с весами \\n .\\nПосле определения значений параметров μ j и \\n  для каждого кластера j, оценка \\nвероятности принадлежности образца x к кластеру j определяется как \\n .\\nОписанный алгоритм легко распространить на случай D-мерных данных (D > 1). \\nЕдинственное отличие — вместо дисперсии σ2 потребуется использовать ковари-\\nационную матрицу Σ, которая параметризует полиномиальное нормальное рас -\\nпределение (MND).\\nВ отличие от метода k средних, где кластеры могут быть только сферическими, \\nкластеры в GMM имеют эллиптическую форму с произвольным удлинением и углом \\nповорота. Эти свойства определяются значениями в ковариационной матрице.\\nНе существует общепризнанного метода выбора правильного \\nзначения k в GMM. Я советую сначала разбить набор данных \\nна обучающий и тестовый наборы. Затем выбрать разные значе-\\nния k, для каждого построить модель \\n  на основе обучающих \\nданных и по окончании выбрать значение k, максимизирующее \\nвероятности принадлежности данных в тестовом наборе:\\nгде | Nte | — размер тестового набора.\\nВ литературе можно найти описание многих других алгоритмов кластеризации. \\nОтдельно стоит упомянуть алгоритмы спектральной и иерархической класте \\xad\\nризации . Они могут оказаться более оптимальными для некоторых наборов \\nданных. Однако в большинстве случаев вполне достаточно алгоритмов k средних, \\nHDBSCAN и модели гауссовой смеси.\\n9.3. Сокращение размерности\\nСовременные алгоритмы машинного обучения, такие как ансамблевые алгоритмы \\nи нейронные сети, хорошо справляются с многомерными образцами, имеющими \\nочень большую размерность, вплоть до миллионов признаков. В настоящее время, \\nна современном уровне развития вычислительной техники с мощными графиче-\\nскими процессорами, методы сокращения размерности используются реже, чем'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='160   Глава 9. Обучение без учителя\\nв прошлом. Чаще всего этот прием применяется для визуализации данных: люди \\nмогут интерпретировать графики, имеющие не больше трех измерений.\\nДругая ситуация, где можно извлечь выгоду из сокращения размерности, — когда \\nнужно построить интерпретируемую модель и вы ограничены в выборе алгорит-\\nмов обучения. Например, вам разрешено использовать только обучение деревьев \\nрешений или линейную регрессию. Сокращая размерность данных и выясняя, \\nкакое качество исходного образца отражает каждый новый признак в сокращенном \\nпространстве признаков, вы получаете возможность использовать более простые \\nалгоритмы. Сокращение размерности устраняет избыточные или сильно коррели-\\nрованные признаки, а также уменьшает долю шума в данных — все это способствует \\nувеличению интерпретируемости модели.\\nНа практике для сокращения размерности широко используются три основных \\nметода: метод главных компонент (Principal Component Analysis, PCA), равномер\\xad\\nная аппроксимация и проекция многообразия (Uniform Manifold Approximation \\nand Projection, UMAP) и автокодировщики.\\nЯ уже рассказывал об автокодировщиках в главе 7. Используя этот подход, в каче-\\nстве вектора с уменьшенной размерностью можно использовать низкоразмерный \\nвыход слоя узкого горлышка  автокодировщика, который представляет вектор \\nвходных объектов с высокой размерностью. Известно, что этот низкоразмерный \\nвектор представляет значимую информацию, содержащуюся во входном векторе, \\nблагодаря чему автокодировщик способен восстановить входной вектор признаков, \\nопираясь исключительно на слой узкого горлышка.\\n9.3.1. Метод главных компонент\\nМетод главных компонент (Principal Component Analysis, PCA) является одним из \\nстарейших методов сокращения размерности. Математический аппарат, лежащий \\nв его основе, опирается на выполнение операций с матрицами, о которых я ничего \\nне говорил в главе 2, поэтому оставлю знакомство с PCA как самостоятельное \\nупражнение. Здесь я приведу только краткий пример применения этого метода.\\nПусть имеется массив двумерных данных, как показано на рис. 9.7a. Основными \\nкомпонентами являются векторы, определяющие новую систему координат, в ко-\\nторой первая ось направлена в сторону наибольшей дисперсии в данных. Вторая \\nось ортогональна первой и направлена в сторону второй наибольшей дисперсии \\nв данных. Если бы данные были трехмерными, можно было бы провести третью \\nось, ортогональную к первой и ко второй осям, направленную в сторону третьей \\nнаибольшей дисперсии, и т. д. На рис. 9.7б показаны две основные компоненты \\nв виде стрелок. Длина стрелки отражает дисперсию в данном направлении.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='9.3. Сокращение размерности   161\\n   \\n (а) (б)\\n(в)\\nРис. 9.7. Метод главных компонент: (a) исходные данные; (б) две главные компоненты \\nв виде векторов; (в) проекция данных на первую главную компоненту\\nТеперь, чтобы сократить размерность данных до Dнов. < D, нужно выбрать Dнов. самых \\nбольших главных компонент и спроецировать на них точки данных. Для нашей \\nдвумерной иллюстрации можно принять Dнов. = 1, спроецировать данные на первую \\nглавную компоненту и получить оранжевые точки, как на рис. 9.7в.\\nЧтобы описать каждую оранжевую точку, нужна только одна ко-\\nордината вместо двух: координата относительно первой главной \\nкомпоненты. Когда данные имеют очень большую размерность, \\nна практике часто случается так, что первые две или три главные \\nкомпоненты «объясняют» большую часть дисперсии в данных, \\nпоэтому, отображая данные на двух- или трехмерном графике, \\nмы действительно можем получить наглядную картину, отражающую основные \\nсвойства многомерных данных.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='162   Глава 9. Обучение без учителя\\n9.3.2. UMAP\\nМногие современные алгоритмы сокращения размерности, особенно разработан-\\nные специально для целей визуализации, такие как t\\xadSNE и UMAP, основываются \\nна схожих идеях. Сначала разрабатывается метрика сходства двух данных. Для \\nцелей визуализации, помимо евклидова расстояния между двумя образцами, эта \\nметрика сходства часто отражает некоторые локальные свойства двух данных, \\nтакие как плотность других данных вокруг них.\\nВ UMAP такая метрика сходства w определяется как\\n \\n   (9.5)\\nФункция wi(xi, xj) определяется как\\nгде d(xi, xj) — евклидово расстояние между двумя образцами, ρi — расстояние от \\nxi до ближайшего соседа, σi — расстояние от xi до k-го ближайшего соседа (k — ги-\\nперпараметр алгоритма).\\nМожно показать, что метрика, определяемая уравнением 9.5, изменяется в диа-\\nпазоне от 0 до 1 и симметрична, то есть w (xi, xj) = w (xj, xi).\\nОбозначим через w сходство двух данных в исходном многомерном пространстве, \\nи пусть \\n  представляет сходство, заданное тем же уравнением 9.5, в новом про-\\nстранстве с меньшей размерностью.\\nЧтобы продолжить, я должен ввести понятие нечеткого множества . Нечеткое \\nмножество является обобщением множества. Для каждого элемента x нечеткого \\nмножества S существует функция принадлежности μS (x) ϵ [0, 1] , которая опреде-\\nляет степень принадлежности x к множеству S. Мы говорим, что x в малой степени \\nпринадлежит нечеткому множеству S, если значение  μS (x) близко к нулю. С другой \\nстороны, если значение μS (x) близко к 1, тогда x имеет сильную принадлежность \\nк S. Если μS (x) = 1 для всех x ϵ S, то нечеткое множество S становится эквивалент-\\nным нормальному, четкому множеству.\\nТеперь посмотрим, зачем нам здесь нужно это понятие нечеткого множества.\\nПоскольку значения w и w′ лежат в диапазоне от 0 до 1, мы можем рассматривать \\nw (xi, xj) как метрику принадлежности пары данных (xi, xj) некоторому нечеткому'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='9.3. Сокращение размерности   163\\nмножеству. То же самое можно сказать и о w′. Сходство двух нечетких множеств \\nназывается перекрестной энтропией нечетких множеств и определяется как\\n \\n   (9.6)\\nгде x′ — низкоразмерная «версия» оригинального образца x с б\\ue088 ольшим числом \\nизмерений.\\nПараметры xi′ (для всех i = 1, ..., N) в уравнении 9.6 представляют искомые низко-\\nразмерные данные. Их можно вычислить с помощью градиентного спуска, путем \\nминимизации Cw, wʹ.\\n PCA UMAP\\nАвтокодировщик\\nРис. 9.8. Сокращение размерности набора данных MNIST с использованием  \\nтрех разных методов'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='164   Глава 9. Обучение без учителя\\nНа рис. 9.8 показан результат сокращения размерности набора данных MNIST, \\nсодержащего изображения рукописных цифр. Набор MNIST часто используется \\nдля сравнительного анализа разных систем обработки изображений; он содержит \\n70 000 размеченных данных. Десять разных цветов на диаграмме соответствуют \\nдесяти классам. Каждая точка соответствует конкретному образцу в наборе дан-\\nных. Как видите, UMAP визуально лучше разделяет данные (не забывайте, что \\nэтот метод не использует метки). На практике UMAP немного медленнее метода \\nглавных компонент (PCA), но быстрее автокодировщика.\\n9.4. Обнаружение аномалий\\nЗадача обнаружения аномалий заключается в выявлении в некоем наборе данных \\nтаких данных, которые сильно отличаются от типичного представителя из этого \\nнабора. Мы уже познакомились с некоторыми методами, способными помочь ре-\\nшить эту задачу: автокодировщики и обучение классификатора с единственным \\nклассом. В случае с автокодировщиком мы обучаем его на наборе данных, а затем, \\nкогда требуется предсказать, является ли образец аномальным, используем модель \\nавтокодировщика и реконструируем образец из слоя узкого горлышка. Модель \\nвряд ли сможет реконструировать аномальный образец.\\nВ случае с классификатором с одним классом модель предсказывает, что входной \\nобразец принадлежит классу или является аномальным.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='10\\nДругие формы \\nобучения\\n10.1. Определение метрик\\nЯ уже говорил, что чаще всего в качестве метрик сходства (или различий) между \\nдвумя векторами признаков используются евклидово расстояние и косинусное \\nсходство. Такой выбор метрики кажется логичным, но необоснованным, как и вы-\\nбор квадрата ошибки в линейной регрессии (или сама линейная форма регрессии). \\nТот факт, что качество метрики зависит от набора данных, явно показывает, что \\nни одна метрика не является идеальной.\\nВы можете создать метрику, которая лучше подходит для вашего набора данных, \\nи интегрировать ее в любой алгоритм обучения, которому требуется метрика, \\nнапример, k средних или kNN. Как без опробования всех возможных вариантов \\nузнать, какое уравнение будет хорошей метрикой? Как вы уже наверняка догада-\\nлись, метрику можно вывести из самих данных.\\nНапомню, как определяется евклидово расстояние между двумя векторами при -\\nзнаков, x и \\n :\\nЭту метрику можно немного изменить и сделать ее параметризуемой, а затем \\nопределить эти параметры из данных. Рассмотрим следующую модификацию:\\nгде A — матрица D × D. Пусть D = 3. Если принять, что A является единичной \\nматрицей,'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='166   Глава 10. Другие формы обучения\\nтогда \\n  становится евклидовым расстоянием. Если A является неединичной \\nдиагональной матрицей, такой как\\nтогда разные измерения будут иметь в метрике разную важность. (В примере выше \\nвторое измерение является более важным в вычислении метрики.) В общем случае, \\nчтобы называться метрикой, функция двух переменных должна удовлетворять \\nтрем условиям:\\n1. d(x, x′) ≥ 0, неотрицательность;\\n2. d(x, x′) ≤ d(x, z) + d(z, x), неравенство треугольника;\\n3. d(x, x′) = d(x′, x), симметрия.\\nДля удовлетворения первых двух условий матрица A должна быть положительно \\nполуопределенной. Положительно полуопределенную матрицу можно рассматри-\\nвать как обобщение понятия неотрицательного действительного числа. Любая \\nположительно полуопределенная матрица M удовлетворяет условию\\nzTMz ≥ 0,\\nдля любого вектора z, размерность которого совпадает с числом строк и столбцов в M.\\nУказанное выше свойство следует из определения положительно полуопреде -\\nленной матрицы. Доказательство выполнения второго условия, когда матрица A \\nявляется положительно полуопределенной, можно найти на веб-сайте книги.\\nЧтобы удовлетворить третье условие, можно просто взять (d(x, x′) + d(x′, x))/2.\\nДопустим, что у нас есть неразмеченное множество \\n . Чтобы построить \\nобучающие данные для задачи определения метрики, вручную создаются два \\nнабора. В первый набор S включаются пары данных ( xi, xk), если xi и xk похожи \\n(с субъективной точки зрения). Во второй набор D включаются пары данных \\n(xi, xk), если xi и xk непохожи.\\nЧтобы получить матрицу параметров A из данных, нужно найти положительную \\nполуопределенную матрицу A, которая решает следующую задачу оптимизации:'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='10.2. Определение ранга   167\\nгде c — положительная константа (может быть любым числом).\\nРешение этой задачи оптимизации находится с помощью модифицированного \\nградиентного спуска, гарантирующего, что найденная матрица A является поло-\\nжительно полуопределенной. Я оставляю описание алгоритма за рамками этой \\nкниги для самостоятельного изучения.\\nСледует отметить, что обучение с первого раза с использованием \\nсиамских сетей и триплетных потерь можно рассматривать как \\nзадачу определения метрики: пары изображений одного человека \\nпринадлежат множеству S, а пары случайных изображений при-\\nнадлежат D.\\nСуществует много других способов определения метрики, в том числе нелинейных \\nи ядерных. Однако метода, представленного в книге, а также адаптации метода \\nобучения с первого раза должно быть достаточно для большинства практических \\nприменений.\\n10.2. Определение ранга\\nОпределение ранга является задачей обучения с учителем. Среди прочего определе-\\nние ранга часто используется для оптимизации результатов поиска, возвращаемых \\nпоисковой системой в ответ на запрос. В оптимизации рангов результатов поиска \\nразмеченный образец Xi в обучающем наборе с размером N является ранжирован-\\nной коллекцией документов размера ri (метки определяют ранг документов). Век-\\nтор признаков представляет каждый документ в коллекции. Цель обучения — найти \\nфункцию ранжирования f, возвращающую значения, которые можно использовать \\nдля ранжирования документов. Для каждого обучающего образца идеальная функ-\\nция f будет возвращать значения, которые определяют тот же ранг, что и метки.\\nКаждый образец Xi, i = 1, ..., N — это коллекция векторов признаков с метками: \\n. Элементы в векторе признаков xi,j представляют документ j = 1, \\n..., ri. Например, \\n  может представлять давность создания документа, \\n  — на-\\nличие искомых слов в названии документа, \\n  — размер документа и т. д. Метка yi,j \\nможет быть рангом (1, 2, ..., ri) или оценкой. Например, чем ниже оценка, тем выше \\nрейтинг документа.\\nСуществует три подхода к решению этой задачи: поточечный, попарный и спи\\xad\\nсочный.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='168   Глава 10. Другие формы обучения\\nПри использовании поточечного подхода каждый обучающий образец преоб -\\nразуется в несколько данных: по одному на документ. Задача обучения в этом \\nслучае превращается в стандартную задачу обучения с учителем, регрессии или \\nлогистической регрессии. В каждом образце (x, y) в задаче поточечного обучения \\nx — это вектор признаков некоторого документа, а y — исходная оценка (если \\nyi, j — оценка) или синтетическая оценка, полученная из ранжирования (чем выше \\nранг, тем ниже синтетическая оценка). В этом случае можно использовать любой \\nалгоритм обучения с учителем. Однако решение обычно получается далеким от \\nидеального. В основном это связано с тем, что каждый документ рассматривается \\nизолированно, в то время как исходное ранжирование (заданное метками yi,j в ис-\\nходном обучающем наборе) может оптимизировать позиции всего набора докумен-\\nтов. Например, если мы уже присвоили высокий ранг странице из «Википедии» \\nв некоторой коллекции документов, мы бы предпочли не давать высокий ранг \\nдругой странице с этого же сайта в ответ на тот же запрос.\\nПри использовании попарного подхода документы тоже рассматриваются изоли-\\nрованно, однако в этом случае рассматривается сразу пара документов. Для пары \\nдокументов (xi, xk) строится модель f, которая получает пару (xi, xk) и возвращает \\nзначение, близкое к 1, если ранг документа xi должен быть выше ранга документа xk; \\nв противном случае f возвращает значение, близкое к 0. Во время тестирования \\nокончательный ранг для неразмеченного образца X получается путем агрегиро -\\nвания прогнозов для всех пар документов в X. Попарный подход работает лучше \\nпоточечного, но все еще далек от совершенства.\\nСовременные алгоритмы обучения, такие как LambdaMART, реализуют подход, \\nоснованный на списках. При использовании списочного подхода модель оптими-\\nзируется непосредственно по некоторому показателю, который отражает качество \\nранжирования. Существуют разные метрики для оценки ранжирования результа-\\nтов в поисковых системах, в том числе точность и полнота. Одна из популярных \\nметрик, которая сочетает в себе точность и полноту, называется усредненной \\nсредней точностью (Mean Average Precision, MAP).\\nЧтобы определить MAP , попросим экспертов (в Google их называют ранжиров-\\nщиками) изучить коллекцию результатов поиска для запроса и присвоить оценки \\nрелевантности каждому результату. Метки могут быть бинарными (1 для «реле -\\nвантных» и 0 для «нерелевантных») или иметь некоторый масштаб, скажем, от 1 \\nдо 5: чем выше значение, тем более релевантным для запроса является документ. \\nПусть наши эксперты выполнят такую маркировку для коллекции из 100 запро -\\nсов. Теперь проверим нашу модель ранжирования для этой коллекции. Точность \\nмодели для некоторого запроса определяется как'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='10.2. Определение ранга   169\\nгде запись \\n  означает «число документов». Метрика средней точности, AveP , \\nопределяется для ранжированной коллекции документов, возвращаемых поис -\\nковой системой в ответ на запрос q как\\nгде n — количество найденных документов, P(k) обозначает точность, вычисленную \\nдля k первых результатов поиска, возвращаемых моделью ранжирования в ответ на \\nзапрос, rel(k) — это индикаторная функция, равная 1, если элемент с рангом k явля-\\nется релевантным документом (по мнению экспертов), и ноль в противном случае. \\nНаконец, MAP для коллекции поисковых запросов размера Q определяется как\\nТеперь вернемся к алгоритму LambdaMART. Он реализует попарный подход \\nи использует градиентный бустинг для обучения функции ранжирования h(x). \\nЗатем бинарная модель f(xi, xk), предсказывающая, что документ xi должен иметь \\nболее высокий ранг, чем документ xk (для того же поискового запроса), задается \\nсигмоидой с гиперпараметром α:\\nИ снова, как во многих моделях, предсказывающих вероятность, функция стоимо-\\nсти является перекрестной энтропией, вычисляемой с использованием модели f. \\nВ нашем градиентном бустинге мы объединяем несколько деревьев регрессии, \\nчтобы построить функцию h, пытаясь минимизировать стоимость. Напомню, что \\nв градиентном бустинге мы добавляем дерево в модель, чтобы уменьшить ошибку \\nтекущей модели на обучающих данных. Для задачи классификации мы вычисляем \\nпроизводную функции стоимости, чтобы заменить фактические метки обучающих \\nданных этими производными. Алгоритм LambdaMART работает аналогично, за \\nодним исключением. Он заменяет фактический градиент комбинацией градиента \\nи еще одного фактора, который зависит от метрики, такой как MAP. Этот фактор \\nизменяет исходный градиент, увеличивая или уменьшая его, что способствует \\nулучшению метрики.\\nЭто блестящая идея, и не многие алгоритмы обучения с учителем могут похва -\\nстаться тем, что оптимизируют метрику напрямую. Оптимизация метрики — это \\nто, в чем мы действительно заинтересованы, однако типичный алгоритм обучения \\nс учителем оптимизирует стоимость вместо метрики (это делается потому, что'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='170   Глава 10. Другие формы обучения\\nобычно метрики не дифференцируемы). В обучении с учителем после создания \\nмодели, оптимизирующей функцию стоимости, мы часто пытаемся настроить ги-\\nперпараметры, чтобы улучшить метрику. Алгоритм LambdaMART оптимизирует \\nметрику непосредственно.\\nОстается вопрос: как построить ранжированный список результатов, опираясь на \\nпрогнозы модели f, которая предсказывает, должен ли ее первый вход иметь более \\nвысокий ранг, чем второй. В общем случае это сложная вычислительная задача, \\nи существует множество реализаций механизмов ранжирования, способных пре-\\nобразовывать попарные сравнения в список ранжирования.\\nСамый простой подход — использовать существующий алгоритм \\nсортировки. Алгоритмы сортировки сортируют коллекцию чисел по \\nвозрастанию или убыванию. (Самый простой алгоритм сортировки \\nназывается пузырьковой сортировкой. Его часто преподают в вузах.) \\nОбычно алгоритмы сортировки итеративно сравнивают пары чисел \\nв коллекции и меняют их местами, исходя из результатов сравнения. \\nЕсли внедрить функцию f в алгоритм сортировки, чтобы выполнить это сравнение, \\nалгоритм сортировки будет сортировать документы, а не числа.\\n10.3. Обучение делать рекомендации\\nОбучение делать рекомендации — это подход к созданию рекомендательных си-\\nстем. Обычно есть пользователь, который потребляет контент, есть история потреб-\\nления и требуется предложить этому пользователю новый контент, который мог бы \\nему понравиться. Это может быть фильм на «Нетфликсе» или книга на «Амазоне».\\nДля реализации рекомендаций традиционно используются два подхода: фильтра\\xad\\nция контента и совместная фильтрация.\\nФильтрация контента заключается в изучении того, что нравится пользователям, \\nна основе описания потребляемого ими контента. Например, если пользователь \\nновостного сайта часто читает статьи по науке и технике, мы могли бы предложить \\nему больше документов по науке и технике. В более общем случае мы могли бы \\nсоздать обучающий набор для каждого пользователя  и добавить в него статьи, \\nкаждая из которых представлена в виде вектора признаков x, а также метки y, от-\\nражающей то, что пользователь недавно читал данную статью. После этого остается \\nтолько построить модель каждого пользователя и регулярно проверять каждый \\nновый контент, чтобы определить, заинтересует ли он конкретного пользователя.\\nПодход на основе контента имеет много ограничений. Например, пользователь \\nможет оказаться в так называемом пузыре фильтров: система всегда будет пред -'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='10.3. Обучение делать рекомендации   171\\nлагать пользователю информацию, которая выглядит очень похожей на то, что он \\nуже потреблял. В  результате пользователь может оказаться в  полной изоляции \\nот информации, которая не соответствует его точке зрения или дополняет ее. \\nВ итоге пользователи могут просто перестать следовать таким рекомендациям, \\nчто нежелательно.\\nСовместная фильтрация имеет важное преимущество перед фильтрацией контента: \\nрекомендации для конкретного пользователя вычисляются на основе того, что по-\\nтребляют или оценивают другие пользователи. Например, если два пользователя \\nдали высокие оценки одним и тем же десяти фильмам, тогда весьма вероятно, что \\nпользователь 1 высоко оценит новые фильмы, рекомендованные на основе вкусов \\nпользователя 2, и наоборот. Недостаток этого подхода заключается в игнорирова-\\nнии содержания рекомендуемых элементов.\\nПри совместной фильтрации информация о пользовательских предпочтениях \\nорганизована в виде матрицы. Каждая строка соответствует пользователю, а каж-\\nдый столбец — контенту, который пользователь оценил или потребил. Обычно \\nэта матрица огромна и чрезвычайно разрежена, то есть большинство ее ячеек не \\nзаполнены (или заполнены нулями). Причина разреженности заключается в том, \\nчто большинство пользователей потребляют или оценивают лишь небольшую \\nчасть доступного контента. На основе таких разреженных данных очень сложно \\nдать содержательные рекомендации.\\nВ большинстве действующих рекомендательных систем используется гибридный \\nподход: они сочетают рекомендации, полученные с помощью моделей фильтрации \\nконтента и совместной фильтрации.\\nЯ уже отмечал, что модель рекомендаций на основе контента можно построить \\nс использованием модели классификации или регрессии, которая предсказывает \\nотношение пользователя к контенту на основе признаков этого контента. Приме-\\nрами признаков могут служить слова в книгах или статьях, которые понравились \\nпользователю, цена, актуальность контента, личность автора контента и т. д.\\nДвумя наиболее эффективными алгоритмами обучения системы рекомендаций \\nсчитаются метод факторизации (Factorization Machines, FM) и автокодировщики \\nс шумоподавлением (Denoising Autoencoders, DAE).\\n10.3.1. Метод факторизации\\nМетод факторизации — это относительно новый вид алгоритмов. Он специально \\nразрабатывался для разреженных наборов данных. Проиллюстрируем его при -\\nменение на примере.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='172   Глава 10. Другие формы обучения\\nx(1)\\nx(2)\\nx(3)\\nx(4)\\nx(5)\\nx(6)\\n...\\nx(D)\\n1\\n1\\n1\\n1\\n1\\n1\\n000\\n... ... ... ...\\n00\\n00\\n00\\n00\\n00\\n00 ...\\n...\\n...\\n...\\n...\\n...\\n...\\nпользователь\\nEd Al Zak It Up Jaws HerIt Up Jaws Her...\\n1\\n0\\n0\\n0\\n0\\n0\\n100\\n... ... ... ...\\n00\\n01\\n01\\n01\\n00\\n10 ...\\n...\\n...\\n...\\n...\\n...\\n...\\n0\\n0\\n...\\n0\\n0\\n0\\n0\\n1\\nфильм\\n0.2\\n0.2\\n0.2\\n0\\n0\\n0\\n100\\n... ... ... ...\\n0.8 0.4\\n0.40.8\\n0.8 0.4\\n0 0.7\\n0 0.7\\n0.8 0 ...\\n...\\n...\\n...\\n...\\n...\\n...\\n0.6\\n0\\n...\\n0\\n0\\n0.7\\n0.1\\n0.1\\nоцененные фильмы\\nx99 x100\\n0.3\\n0.3\\n0.3\\n0.35\\n0.35\\n0.5\\n0.95\\n...\\n0.8\\n0.8\\n0.8 \\n0.78\\n0.78\\n0.77\\n...\\n0.85\\n1\\n3\\n2\\n3\\n1\\n4\\n5\\n...\\ny \\ny(1)\\ny(2)\\ny(3)\\ny(4)\\ny(5)\\ny(6)\\ny(D)\\n...\\nx1 x2 x3 x21 x22 x23 x24... ... x40 x41 x42 x43 ...\\nРис. 10.1. Пример разреженных векторов признаков x и соответствующих им меток y\\nНа рис. 10.1 показан пример разреженных векторов признаков с метками. Каждый \\nвектор признаков представляет информацию об одном конкретном пользователе \\nи одном конкретном фильме. Признаки в синей области представляют пользова-\\nтеля. Векторы, представляющие пользователей, получены методом унитарного \\nкодирования. Элементы в зеленой области представляют фильмы. Эти векторы \\nтакже получены методом унитарного кодирования. Признаки в желтой области \\nпредставляют оценки, которые пользователь из синей области присвоил каждому \\nоцененному им фильму. Признак x99 представляет долю фильмов, получивших \\nОскара, среди просмотренных пользователем. Признак x100 представляет процент \\nобщей протяженности фильма, просмотренного пользователем из синей области, до \\nтого, как он оценил фильм в зеленой области. Цель y представляет оценку, данную \\nпользователем из синей области фильму из зеленой области.\\nВ настоящих рекомендательных системах количество пользователей может исчис-\\nляться миллионами, поэтому матрица на рис. 10.1 будет насчитывать сотни милли-\\nонов строк. Количество признаков может составлять сотни тысяч, в зависимости от \\nбогатства выбора контента и вашей изобретательности, как аналитика, в разработке \\nпризнаков. Элементы x99 и x100 были определены вручную, в процессе проектирования \\nпризнаков, и в этом примере я остановлюсь только на двух признаках.\\nПопытка обучить регрессионную модель или модель классификации на таком \\nчрезвычайно разреженном наборе данных приведет к плохому обобщению. Метод \\nфакторизации решает эту задачу по-другому.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='10.3. Обучение делать рекомендации   173\\nМодель метода факторизации определяется следующим образом:\\nгде b и wi, i = 1, ..., D — скалярные параметры, подобные тем, что используются \\nв линейной регрессии. Векторы vi — это k-мерные векторы факторов. k является \\nгиперпараметром и обычно имеет значение намного меньше, чем D. Выражение \\nvivj — это скалярное произведение i-го и j-го векторов факторов.\\nКак видите, вместо попытки отыскать один большой вектор параметров, который \\nможет плохо отражать взаимосвязи между признаками из-за разреженности, мы \\nдополняем его дополнительными параметрами, отражающими парные взаимосвязи \\nxi xj между признаками. Однако вместо параметра wi,j для каждой взаимосвязи, что \\nдобавило бы огромное1 количество новых параметров в модель, мы факторизуем \\nwi,j на vivj, добавляя Dk << D(D – 1) параметров в модель2.\\nВ зависимости от задачи функция потерь может быть квадратом ошибок потерь \\n(для регрессии) или кусочно-линейной функцией потерь. Для классификации \\nс y ϵ {–1, +1}, прогнозирование с кусочно-линейной функцией потерь или логи -\\nстическими потерями осуществляется по формуле y = sign(f(x)). Логистические \\nпотери определяются как\\nДля оптимизации средней потери можно использовать градиентный спуск. В при-\\nмере на рис. 10.1 метки принадлежат множеству {1, 2, 3, 4, 5}, соответственно, это \\nзадача классификации с многими классами. Мы можем использовать стратегию \\n«один против всех», чтобы преобразовать эту задачу в пять задач бинарной клас-\\nсификации.\\n10.3.2. Автокодировщики с шумоподавлением\\nВ главе 7 вы узнали, что такое автокодировщик с шумоподавлением: это нейрон-\\nная сеть, которая восстанавливает входные данные из слоя узкого горлышка. Тот \\nфакт, что входные данные искажены шумом, а выход должен быть свободен от \\nнего, делает автокодировщики с шумоподавлением идеальным инструментом для \\nпостроения модели рекомендации.\\n1 Точнее, добавилось бы D (D – 1) параметров wi, j.\\n2 Запись << означает «намного меньше, чем».'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='174   Глава 10. Другие формы обучения\\nИдея очень проста: новые фильмы, которые могут понравиться пользователю, вы-\\nглядят так, будто они были удалены из полного набора предпочтительных фильмов \\nв результате какого-то процесса. Цель автокодировщика с шумоподавлением — \\nвосстановить эти удаленные элементы.\\nЧтобы подготовить обучающий набор для автокодировщика с шумоподавлением, \\nнужно удалить синие и зеленые элементы из обучающего набора на рис. 10.1. По-\\nскольку после этого некоторые примеры будут повторять друг друга, их нужно \\nудалить и оставить только уникальные элементы.\\nЗатем производится обучение автокодировщика восстановлению поврежденного \\nвхода, с заменой нулями некоторых ненулевых признаков в желтой области слу-\\nчайным образом во время обучения.\\nВо время прогнозирования нужно создать вектор признаков, представляющий \\nпользователя, содержащий неповрежденные признаки из желтой области, а также \\nэлементы, созданные вручную, такие как x99 и x100. С помощью обученной модели \\nDAE восстановить неповрежденный вход и вернуть пользователю рекомендован-\\nные фильмы, имеющие самые высокие оценки в выходе модели.\\nДругая эффективная модель совместной фильтрации — FFNN \\nс двумя входами и одним выходом. Как говорилось в главе 8, \\nнейронные сети хорошо справляются сразу с несколькими вхо-\\nдами. Обучающим образцом здесь является триплет ( u, m, r). \\nВходной вектор u представляет пользователя и получен методом \\nунитарного кодирования. Второй входной вектор m представляет \\nфильм и тоже получен методом унитарного кодирования. Выходной слой может \\nбыть сигмоидой (в этом случае метка r принадлежит диапазону [0, 1]) или ReLU, \\nкогда r может принадлежать некоторому типичному диапазону, например [1, 5].\\n10.4. Самообучение с учителем: \\nвложения слов\\nМы уже обсуждали вложения слов в главе 7. Напомню, что вложения — это век-\\nторы признаков, представляющие слова. Главное их свойство заключается в том, \\nчто похожие слова имеют похожие векторы признаков. Вопрос, который наверняка \\nвозник у вас — откуда берутся эти вложения. Ответ: они извлекаются из данных.\\nЕсть много алгоритмов для создания вложений слов. Здесь мы рассмотрим толь-\\nко один из них: word2vec, и только одну версию, которая называется skip\\xadgram, \\nхорошо зарекомендовавшую себя на практике. В интернете можно найти готовые \\nвложения word2vec для многих языков, доступные для скачивания.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='10.4. Самообучение с учителем: вложения слов   175\\nГлавная цель при создании вложений слов — получить модель, которую можно \\nиспользовать для преобразования векторов, полученных методом унитарного \\nкодирования, во вложения слов. Пусть словарь содержит 10 000 слов. При исполь-\\nзовании унитарного кодирования для каждого слова получается 10 000-мерный \\nвектор с нулями во всех элементах, кроме одного, содержащего 1. Разные слова \\nимеют значение 1 в разных измерениях.\\nРассмотрим предложение: «Я почти закончил читать книгу по машинному обу-\\nчению». Теперь рассмотрим то же предложение, из которого мы удалили одно \\nслово, например «книгу». Теперь предложение выглядит так: «Я почти закончил \\nчитать · по машинному обучению». Теперь оставим только три слова перед · и три \\nпосле: «почти закончил читать · по машинному обучению». Посмотрите на этот \\nфрагмент из семи слов с · в центре. А теперь представьте, что я предложил вам \\nугадать, что означает ·. Вы почти наверняка дадите ответ: «книга», «статья» или \\n«документ». Именно так слова из контекста позволяют предсказать слово, которое \\nони окружают. Машина тоже может определить, что слова «книга», «документ» \\nи «статья» имеют схожее значение: потому что они имеют схожий контекст во \\nмножестве текстов.\\nКак оказывается, обратное тоже верно: слово может предсказать контекст, который \\nего окружает. Часть «почти закончил читать · по машинному обучению» называется \\nскипграммой (skip-gram) с размером окна 7 (3 + 1 + 3). Используя документы, до-\\nступные в интернете, можно создать сотни миллионов скипграмм.\\nОбозначим скипграмму следующим образом: [x–3, x–2, x–1, x, x+1, x+2, x+3]. В нашем \\nпредложении x –3 — это вектор унитарного кодирования для слова «почти», x–2 со-\\nответствует «закончил», x — пропущенное слово (·), x+1 — «по» и т. д. Скипграмма \\nс размером окна 5 будет выглядеть следующим образом: [x–2, x–1, x, x+1, x+2].\\nМодель скипграммы с размером окна 5 схематически изображена на рис. 10.2. \\nЭто полносвязанная сеть, подобная многослойному перцептрону. Входное слово \\nобозначено в скипграмме как ·. Нейронная сеть должна научиться предсказывать \\nконтекстные слова скипграммы с учетом центрального слова.\\nТеперь должно быть понятно, почему обучение такого рода называется самообу\\xad\\nчением с учителем: размеченные данные извлекаются из неразмеченных данных, \\nтаких как текст.\\nВ выходном слое используется функция активации softmax. \\nФункция стоимости — отрицательное логарифмическое прав -\\nдоподобие. Вложение слова возвращается слоем вложения после \\nпередачи на вход модели вектора унитарного кодирования этого \\nслова.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='176   Глава 10. Другие формы обучения\\nРис. 10.2. Модель скипграммы с размером окна 5 и слоем вложения с 300 узлами\\nМодели word2vec имеют большое количество параметров, поэтому для повыше -\\nния эффективности вычислений используются два метода: иерархический softmax \\n(эффективный способ вычисления softmax, заключающийся в представлении \\nвыходных данных softmax в виде листьев бинарного дерева) и отрицательная вы-\\nборка (идея которой состоит в обновлении в каждой итерации градиентного спуска \\nслучайной выборки из всех выходов). Знакомство с этими методами я оставляю \\nвам для самостоятельного изучения.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='11 Заключение\\nУх ты, как быстро! Вы отлично поработали, если попали сюда и сумели понять \\nб\\ue088ольшую часть того, о чем рассказывалось в книге.\\nКнига получилась чуть больше, чем планировалось. В конце концов, если бы я хо-\\nтел ограничить эту книгу, например, ровно сотней страниц, то мог бы уменьшить \\nразмер шрифта, поля и межстрочный интервал или удалить раздел об алгоритме \\nUMAP и отправить вас к оригинальному источнику. Уверяю вас: вам едва ли по-\\nнравилось бы самостоятельно знакомиться с оригинальной статьей об UMAP! \\n(Шутка!)\\nЯ уверен, что вы получили все необходимое, чтобы стать отличным современным \\nаналитиком или специалистом по машинному обучению. Это не значит, что я ох-\\nватил все, что только можно, но то, что мне удалось описать, в других книгах рас-\\nтянуто на тысячи страниц. Многое из того, о чем я рассказал, вообще отсутствует \\nв книгах: типичные книги по машинному обучению консервативны и академичны, \\nя же сделал упор на алгоритмах и методах, которые пригодятся вам в повседневной \\nработе.\\nО чем бы я рассказал в книге по машинному обучению в тысячу страниц? \\n11.1. Что не было затронуто\\n11.1.1. Тематическое моделирование\\nВ текстовом анализе широко используется метод обучения без учителя, который \\nназывается тематическим моделированием. Представьте, что у вас есть коллекция'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='178   Глава 11. Заключение\\nтекстовых документов и вам нужно определить тему каждого документа. Латентное \\nразмещение Дирихле (Latent Dirichlet Allocation, LDA) — очень эффективный \\nалгоритм определения темы. Вы сами решаете, сколько тем присутствует в кол-\\nлекции документов, а алгоритм назначает тему каждому слову в этой коллекции. \\nЗатем, чтобы определить тему документа, вы просто подсчитываете количество \\nслов в этом документе, соответствующих каждой теме.\\n11.1.2. Гауссовские процессы\\nГауссовские процессы (Gaussian Processes, GP)  — это метод обучения с  учите-\\nлем, конкурирующий с ядерной регрессией. Он имеет некоторые преимущества \\nперед последней. Например, поддерживает доверительные интервалы для линии \\nрегрессии в каждой точке. Я решил не объяснять этот метод, потому что не смог \\nпридумать простой способ объяснить его, но вам определенно стоит потратить \\nнекоторое время, чтобы познакомиться с гауссовскими процессами поближе. Это \\nне будет пустой тратой времени.\\n11.1.3. Обобщенные линейные модели\\nОбобщенная линейная модель (Generalized Linear Model, GLM) — это обобщение \\nлинейной регрессии для моделирования разного вида зависимостей между вход-\\nным вектором признаков и целью. Например, логистическая регрессия является \\nодной из форм GLM. Если вас интересует регрессия и вы ищете простые и объ-\\nяснимые модели, обязательно познакомьтесь с GLM поближе.\\n11.1.4. Вероятностные графические модели\\nЯ упомянул один пример вероятностных графических моделей  (Probabilistic \\nGraphical Models, PGM) в главе 7: условные случайные поля (Conditional Random \\nFields, CRF). С помощью CRF можно смоделировать входную последовательность \\nслов и отношения между признаками и метками в этой последовательности в виде \\nпоследовательного графа зависимостей. В общем случае PGM может быть любым \\nграфом. Граф — это структура, состоящая из набора узлов и ребер, соединяющих \\nпары узлов. Каждый узел в PGM представляет некоторую случайную переменную \\n(значения которой могут наблюдаться или не наблюдаться), а ребра представля-\\nют условную зависимость одной случайной переменной от другой. Например, \\nслучайная переменная «влажность тротуара» зависит от случайной переменной \\n«погодные условия». Наблюдая значения некоторых случайных переменных, алго-\\nритм оптимизации способен извлечь из данных зависимости между наблюдаемыми \\nи ненаблюдаемыми переменными.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='11.1. Что не было затронуто   179\\nВероятностные графические модели позволяют аналитику увидеть, как значения \\nодного признака зависят от значений других признаков. Если ребра графа зависи-\\nмостей ориентированы, появляется возможность вывести причинно-следственную \\nсвязь. К сожалению, создание таких моделей вручную требует значительного опыта \\nв предметной области и глубокого понимания теории вероятностей и математи-\\nческой статистики. Последнее требование часто оказывается невыполнимым для \\nмногих экспертов в предметной области. Некоторые алгоритмы могут определять \\nструктуру зависимостей на основе данных, но полученные таким способом модели \\nчасто трудно поддаются интерпретации и поэтому они малополезны для понимания \\nсложных вероятностных процессов, которые генерируют данные. На сегодняшний \\nдень CRF является наиболее часто используемой вероятностно графической моде-\\nлью, применяемой в основном для обработки текста и изображений. Однако в этих \\nдвух областях этот метод уступил пальму первенства нейронным сетям. Другая \\nграфическая модель, скрытая марковская модель (Hidden Markov Model, HMM), \\nв прошлом часто использовалась в задачах распознавания речи, анализе временных \\nрядов и других задачах определения временн\\ue088ых зависимостей, но HMM точно так \\nже проиграла нейронным сетям.\\nЕсли вы все же решите узнать больше о PGM, то знайте, что они также известны под \\nназваниями байесовские сети, сети доверия и вероятностные сети независимости.\\n11.1.5. Методы Монте-Карло с цепями Маркова\\nЕсли при работе с графическими моделями возникает необходимость выбрать \\nданные из очень сложного распределения, определяемого графом зависимостей, \\nможно попробовать использовать алгоритмы  Монте\\xadКарло с цепями Маркова \\n(Markov Chain Monte Carlo, MCMC). MCMC — это целый класс алгоритмов для \\nвыборки из любого распределения вероятностей, определенного математически. \\nКогда мы говорили об автокодировщиках с шумоподавлением, мы отбирали шум \\nиз нормального распределения. Выборка из стандартных распределений, таких как \\nнормальное или равномерное, осуществляется относительно просто, потому что \\nих свойства хорошо известны. Однако задача выборки значительно усложняется, \\nкогда распределение вероятностей может иметь произвольную форму, определя-\\nемую сложной формулой.\\n11.1.6. Генеративно-состязательные сети\\nГенеративно-состязательные сети (Generative Adversarial Networks, GAN) — это \\nкласс нейронных сетей, использующих обучение без учителя. Они реализуются \\nкак система двух нейронных сетей, состязающихся друг с другом в условиях игры'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='180   Глава 11. Заключение\\nс нулевой суммой. Самое популярное применение GAN — обучение созданию \\nфотографий, которые для людей-наблюдателей выглядят достоверно. Первая из \\nдвух сетей принимает случайный вход (обычно гауссовский шум) и учится гене-\\nрировать изображение в виде матрицы пикселов. Вторая сеть принимает на входе \\nдва изображения: одно «реальное», взятое из некоторой коллекции, и второе — \\nсгенерированное первой сетью. Она должна научиться распознавать, какое из двух \\nизображений сгенерировано первой сетью. Первая сеть получает отрицательные \\nпотери, если вторая распознала «поддельное» изображение.  \\nВторая сеть, в свою очередь, получает штраф, если не может распознать, какое из \\nдвух изображений является поддельным.\\n11.1.7. Генетические алгоритмы\\nГенетические алгоритмы  (Genetic Algorithms, GA) — это методика численной \\nоптимизации, используемая для оптимизации недифференцируемых целевых \\nфункций. В ней для поиска глобального оптимума (минимума или максимума) \\nиспользуются понятия эволюционной биологии и имитируются эволюционные \\nбиологические процессы.\\nПри использовании генетических алгоритмов сначала создается первоначальное \\nпоколение решений-кандидатов. Если мы хотим найти оптимальные значения па-\\nраметров модели, сначала случайным образом генерируется несколько комбинаций \\nтаких значений. Затем каждая комбинация проверяется по отношению к целевой \\nфункции. Представьте себе каждую комбинацию значений параметров как точку \\nв многомерном пространстве. Затем из предыдущего поколения генерируется \\nпоследующее поколение точек, с  применением таких понятий, как «селекция», \\n«пересечение» и «мутация».\\nВ итоге это приводит к тому, что в каждом новом поколении сохраняется боль -\\nше точек, схожих с теми, которые имелись в предыдущем поколении и которые \\nпоказали лучшие результаты по отношению к цели. Точки в новом поколении, \\nкоторые показали худшие результаты в предыдущем поколении, заменяются \\n«мутациями» и «пересечениями» точек, показавших лучшие результаты. Мута -\\nция точки получается случайным искажением некоторых атрибутов исходной \\nточки. Пересечение — это определенная комбинация нескольких точек (напри -\\nмер, среднее значение).\\nГенетические алгоритмы позволяют находить решения для любых измеримых \\nкритериев оптимизации. Например, GA можно использовать для оптимизации \\nгиперпараметров алгоритма обучения. Они обычно намного медленнее методов \\nоптимизации на основе градиента.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='11.2. Благодарности   181\\n11.1.7. Обучение с подкреплением\\nКак уже говорилось, обучение с подкреплением (Reinforcement Learning, RL) ре-\\nшает очень специфическую задачу, когда решения принимаются последовательно. \\nОбычно агент действует в неизвестном окружении. Каждое действие приносит \\nвознаграждение и переносит агента в другое состояние окружения (обычно в ре-\\nзультате какого-то случайного процесса с неизвестными свойствами). Цель аген-\\nта — оптимизировать долгосрочное вознаграждение.\\nАлгоритмы обучения с подкреплением, такие как Q-обучение (Q-learning), а также \\nего аналоги на основе нейронной сети используются при обучении видеоиграм, \\nроботизированной навигации и координации, управлению запасами и цепочками \\nпоставок, оптимизации сложных электроэнергетических систем (электросетей) \\nи изучении финансовых торговых стратегий.\\nНа этом книга заканчивается. Не забывайте время от времени посещать вики-\\nстраницу книги, чтобы быть в курсе событий в областях машинного обучения, \\nрассмотренных в книге. Как я уже говорил в предисловии, благодаря постоянно \\nобновляемой вики-странице эта книга, как хорошее вино, со временем становится \\nтолько лучше.\\n11.2. Благодарности\\nВысокое качество этой книги было бы невозможно без редакторов-волонтеров. \\nЯ особенно благодарен следующим читателям за их систематический вклад: Мар-\\nтейну ван Аттекуму (Martijn van Attekum), Даниэлю Мараини (Daniel Maraini), \\nАли Азизу (Ali Aziz), Рэйчел Мак (Rachel Mak), Кельвину Сундли (Kelvin Sundli) \\nи Джону Робинсону (John Robinson).\\nТакже я очень благодарен за помощь: Кнуту Свердрупу (Knut Sverdrup), Фредди \\nДреннану (Freddy Drennan), Карлу У. Хэндлину (Carl W. Handlin), Абхиджиту \\nКумару (Abhijit Kumar), Лаззе Веддбарду (Lazze Veddbärd), Рикардо Рейсу (Ricardo \\nReis), Даниэлю Гроссу (Daniel Gross), Иогану Фаузи (Johann Faouzi), Акашу Агра-\\nвалу (Akash Agrawal), Натанаэлю Вайлю (Nathanael Weill), Филипу Джекичу (Filip \\nJekic), Абишеку Бабуджи (Abhishek Babuji), Луану Виейре (Luan Vieira), Саяку \\nПолу (Sayak Paul), Вахейду У оллетсу (Vaheid Wallets), Лоренцо Буффони (Lorenzo \\nBuffoni), Эли Фридман (Eli Friedman), Лукашу Мёдри ( Łukasz Madry), Хаолану \\nЦиню (Haolan Qin), Бибеку Бехере (Bibek Behera), Дженнифер Купер (Jennifer \\nCooper), Нишанту Тяги (Nishant Tyagi), Денису Ахиярову (Denis Akhiyarov), Арону \\nДжанарву (Aron Janarv), Александру Овчаренко, Рикардо Риосу (Ricardo Rios), \\nМайклу Муллену (Michael Mullen), Мэтью Эдвардсу (Matthew Edwards), Дэвиду'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='182   Глава 11. Заключение\\nЭтлину (David Etlin), Манодж Баладжи Дж. (Manoj Balaji J), Давиду Руа (David \\nRoy), Луису Феликсу (Luiz Felix), Ананду Мохану (Anand Mohan), Хади Сотуде \\n(Hadi Sotudeh), Чарли Ньюи (Charlie Newey), Замиру Акимбекову, Хесусу Ренеро \\n(Jesus Renero), Карану Гадия (Karan Gadiya), Мустафе Анил Дербенту (Mustafa \\nAnıl Derbent), Джейкью Веенстра (JQ Veenstra), Жолту Крезису (Zsolt Kreisz), \\nЯну Келли (Ian Kelly), Лукашу Заваде (Lukasz Zawada), Роберту Уэрхэму (Robert \\nWareham), Томасу Босману (Thomas Bosman), Льву Стивену (Lv Steven), Ариэлю \\nРоссаниго (Ariel Rossanigo), Майклу Лумпкинсу (Michael Lumpkins), Сесил Созуер \\n(Secil Sozuer), Борису Куамбо (Boris Kouambo), И Джеону (Yi Jayeon), Тиму Фло-\\nку (Tim Flocke), Мохамеду Бехери (Mohamed Behery), Ане Фотине (Ana Fotina), \\nСамину Иштяку (Samin Ishtiaq), Алексею Шматову, Кристиану Йеншу (Christian \\nJaensch) и Лучано Сегуре (Luciano Segura).'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='Алфавитный указатель\\nA\\nAdam  66\\nI\\nID3  50\\nK\\nkNN  113\\nL\\nL1-регуляризация  81\\nL2-регуляризация  81\\nLambdaMART  168\\nR\\nReLU  95\\nRMSprop  66\\nRNN\\nпреобразование последовательностей \\nв последовательности  109\\nс механизмом внимания  109\\nS\\nSkip-gram  174\\nSVM  113\\nс жестким зазором  55\\nс мягким зазором  55\\nT\\nTanH  95\\nt-SHE  162\\nU\\nUMAP  162\\nW\\nWord2vec  174\\nА\\nАвтокодировщик  129, 160\\nАвтокодировщик с шумоподавлением  \\n130, 171, 179\\nАктивное обучение  126\\nАлгоритм\\nГаусса  113\\nмаксимизации ожидания  157\\nМонте-Карло с цепями Маркова  179\\nАлгоритм обучения  19, 22\\nбез учителя  19\\nклассификации  39\\nрегрессии  40\\nслабый  118\\nс учителем  19\\nАномалия  25\\nАприорная вероятность  38\\nАрхитектура полносвязанная  93'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='184   Алфавитный указатель\\nБ\\nБайесовская оптимизация гиперпара-\\nмет ров  89\\nБалл членства  155\\nБинарная перекрестная энтропия  117\\nБинарная функция потерь  44\\nБиннинг  71\\nБольшинство голосов  138\\nБольшое смещение  78\\nБустинг  118\\nБэггинг  118\\nВ\\nВектор  27\\nпризнака  18, 69\\nВентильный RNN  108\\nВентильный рекуррентный узел  108\\nВзрывной рост градиента  95\\nВложение входных данных  124\\nВложения  174\\nслов  133, 139\\nВложенная функция  91\\nВознаграждение  20\\nВыборка  37\\nс заменой  119\\nВыборочное среднее  37\\nВысокая дисперсия  79\\nВыявление аномалий  19\\nГ\\nГауссовские процессы  178\\nГенератор  146\\nГенетический алгоритм  180\\nГлобальный минимум  32\\nГрадиент  34\\nГрадиентный бустинг  75, 120\\nГрадиентный спуск  46, 49, 59\\nГраница принятия решения  22\\nГраф  49, 178\\nГребневая регуляризация  82\\nД\\nДействие  20\\nДекодировщик  124\\nДилемма смещения-дисперсии  81\\nДискретная величина  34\\nслучайная  34\\nДисперсия  120\\nДифференцирование  33\\nДолгая краткосрочная  108\\nДоля\\nистинно положительного результата  \\n87\\nложноположительного результата  87\\nДополнение  101\\nЕ\\nЕвклидово расстояние  57, 165\\nЗ\\nЗазор  23\\nЗатухание градиента  95\\nИ\\nИзвлечение именнованных сущностей  \\n123\\nИзмерение  27\\nИнкрементальный алгоритм обучения  \\n75\\nИнтервал  32\\nИнформативный признак  70\\nК\\nКвадратичная функция потерь  44\\nКласс  19, 40'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='Алфавитный указатель   185\\nКлассификация  39\\nбинарная  40\\nмногоклассовая  40\\nмультиномиальная  40\\nодноклассовая  113\\nс многими метками  116\\nс несколькими классами  40\\nунарная  113\\nКластеризация  149\\nk средних  150\\nжесткая  155\\nиерархическая  159\\nспектральная  159\\nКодировщик  124\\nКонтрольный набор  76\\nКосинусное сходство  58, 165\\nКусочно-линейная функция потерь  54\\nЛ\\nЛассо  82\\nЛатентное размещение Дирихле  178\\nЛестничная сеть  129, 130\\nЛиния поведения  20\\nЛогарифм правдоподобия  49\\nЛогистический сигмоид  47\\nЛокальный минимум  32\\nМ\\nМаксимальное правдоподобие  48, 114, \\n157\\nМаксимум апостериорной вероятности  \\n39\\nМалое смещение  70\\nМаркировка последовательностей  123\\nМатрица  28\\nМатрица ошибок  83\\nМетамодели  118\\nМетка  19, 39\\nМетод\\nk ближайших соседей  57\\nадаптивного градиента  66\\nадаптивной синтетической выборки  \\n137\\nглавных компонент  160\\n«локтя»  155\\nмножителей Лагранжа  56\\nмоментов  66\\nна основе градиента  89\\nопорных векторов  22\\nрасширения выборки меньшинства \\nсинтетическими образцами  137\\nсреднего силуэта  155\\nунитарного кодирования  174\\nфакторизации  171\\nэволюционной оптимизации  89\\nМеханизм внимания  125\\nМешок слов  21\\nМинимальный вентильный узел  108\\nМини-пакетный стохастический гради-\\nентный спуск  65\\nМногослойный перцептрон  92\\nМножество  29\\nМоделирование класса  113\\nМодель  19, 22, 23, 40\\nансамблевая  119\\nвероятностная графическая  178\\nнепараметрическая  50, 147\\nобобщенная линейная  178\\nпараметрическая  50, 147\\nразреженная  81\\nрегуляризации эластичных сетей  82\\nскрытая марковская  179\\nсмеси гауссовых распределений  155\\nсредних  82\\nстатистическая  23'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='186   Алфавитный указатель\\nН\\nНабор данных  18, 22, 37, 69\\nНедообученность  78\\nНейронная сеть  41, 75\\nглубокая  41\\nклассическая  92\\nостаточная  96\\nпрямого распространения  92\\nрекуррентная  105\\nрекурсивная  109\\nсверточная  97\\nсиамская  131\\nНепрерывная величина  34\\nслучайная  36\\nНеразмеченный образец  19, 39\\nНесмещенная оценка  37\\nНечеткое множество  162\\nНормализация  71\\nz-оценки  72\\nНормальный гауссов шум  130\\nО\\nОбласть значений  32\\nОбласть определения  31\\nОбнаружение аномалий  164\\nОбобщение  23\\nО большое  144, 145\\nОбразец  37\\nОбратное распространение  96\\nОбратное распространение во времени  \\n107\\nОбучение  23\\nансамбля  118\\nбез подготовки  133\\nбез учителя  19\\nпреобразованию последовательно-\\nстей в последовательности  124\\nс первого раза  131, 167\\nс подкреплением  20\\nс учителем  18\\nОбъединение  29\\nОграничение градиента  95\\nОдин против всех  112\\nОдноклассовая версия алгоритма Гаусса  \\n113\\nОжидаемое значение  36\\nОжидаемое среднее вознаграждение  20\\nОжидание  36\\nОстаток  120\\nОтбор признаков  82\\nОтложенная выборка  76\\nОценка плотности  147\\nП\\nПакетная нормализация  82, 140\\nПараметр  22, 40\\nПерекрестная проверка  90, 148\\nПеренос обучения  143\\nПереобучение  45, 79, 120\\nПересечение  29\\nПодвыборки  103\\nПоиск по сетке  88\\nПолнота  84, 87\\nПопарный подход  167\\nПоточечный подход  167\\nПравдоподобие  48\\nПравило Байеса  38, 157\\nПравило дифференцирования сложной \\nфункции  33\\nПравильность  85\\nс учетом цены  87\\nПризнак  18, 69\\nПрогнозирующая сила  152\\nПрогнозирующая способность  70'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='Алфавитный указатель   187\\nПроектирование признака  69\\nПроекция многообразия  160\\nПроизводная  33\\nПрореживание  82, 140\\nР\\nРавномерная аппроксимация  160\\nРазмеченные данные  39\\nРазмеченный образец  18, 69\\nРанняя остановка  82, 140\\nРаспределение вероятности  35\\nРасширение данных  82, 141\\nРегрессия  40\\nРегуляризация  80\\nРезультат\\nистинно отрицательный  84\\nистинно положительный  84\\nложноотрицательный  84\\nложноположительный  84\\nС\\nСамообучение  128\\nс учителем  175\\nСвертка  98\\nСиамские сети  167\\nСкаляр  27\\nСкалярное произведение  30\\nСкользящее окно  97\\nСлой  41, 91, 92\\nполносвязанный  93\\nскрытый  96\\nузкого горлышка  160\\nСлучайная величина  34\\nСлучайный лес  119\\nСлучайный поиск  89\\nСмещение  78\\nСовместная фильтрация  170\\nСоединение с пропуском слоя  96\\nСокращение выборки  137\\nСостояние  20, 105\\nСписочный подход  167\\nСреднее значение  36\\nСреднеквадратичная ошибка  48\\nСредний накопленный квадрат ошибки  \\n148\\nСредняя точность  169\\nСтандартизация  72\\nСтандартная логистическая функция   \\n47\\nСтандартное отклонение  36\\nСтатистика разрывов  155\\nСтатистическая характеристика  36\\nСтатистическая характеристика выбор-\\nки  37\\nСтохастический градиентный спуск  59\\nТ\\nТеорема Байеса  38\\nТом  99\\nТочность  25, 84, 168\\nТранспонирование  31\\nТриплетная потеря  131, 167\\nУ\\nУвеличения выборки  137\\nУзел  92\\nУменьшение размерности  19\\nУ словные случайные поля  123\\nУ среднение  138\\nУ средненная средняя точность  168\\nФ\\nФактор  173\\nФильтрация контента  170'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='188   Алфавитный указатель\\nФункция\\nsoftmax  107, 112\\nактивации  91\\nплотности вероятности  36\\nпотерь  44\\nраспределения дискретной случай-\\nной величины  35\\nстоимости  44\\nстрого возрастающая  49\\nядра  56\\nЦ\\nЦелевое значение  40\\nЦентроид  150\\nЧ\\nЧастная производная  34\\nЧисловое переполнение  72\\nШ\\nШаг  101\\nШтабелирование  138\\nЭ\\nЭмпирический риск  44\\nЭнтропия  51\\nЭпоха  62\\nЯ\\nЯдерный трюк  55\\nЯдро  24, 56, 110\\nЯдро RBF  57'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='Андрей Бурков\\nМашинное\\tобучение\\tбез\\tлишних\\tслов\\nПеревел с английского А. Киселев\\n Заведующая редакцией Ю. Сергиенко\\n Ведущий редактор К. Тульцева\\n Литературный редактор А. Руденко\\n Художественный редактор В. Мостипан\\n Корректоры С. Беляева, М. Молчанова\\n Верстка Л. Егорова\\nИзготовлено в России. Изготовитель: ООО «Прогресс книга». \\nМесто нахождения и фактический адрес: 194044, Россия, г. Санкт-Петербург, \\nБ. Сампсониевский пр., д. 29А, пом. 52. Тел.: +78127037373.\\nДата изготовления: 02.2020. Наименование: книжная продукция. Срок годности: не ограничен.\\nНалоговая льгота — общероссийский классификатор продукции ОК 034-2014, 58.11.12 — Книги печатные  \\nпрофессиональные, технические и научные.\\nИмпортер в Беларусь: ООО «ПИТЕР М», 220020, РБ, г. Минск, ул. Тимирязева, д. 121/3, к. 214, тел./факс: 208 80 01.\\nПодписано в печать 23.01.20. Формат 70×100/16. Бумага офсетная. У сл. п. л. 15,480. Тираж 1700. Заказ 0000.'),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content=''),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content=''),\n",
       " Document(metadata={'source': 'data\\\\book3.pdf'}, page_content='')]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimal_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4b8ad1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(minimal_docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500, chunk_overlap=20\n",
    "    )\n",
    "    texts_chunk = text_splitter.split_documents(minimal_docs)\n",
    "    return texts_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f3969606",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_chunks = text_split(minimal_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bf7fe042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "796"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e1e979e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def download_embeddings():\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_name\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "embedding = download_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "832041b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "43f7fab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\romoc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "vector = embedding.embed_query(\"привет\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9c7b0fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01188887283205986,\n",
       " 0.05277395248413086,\n",
       " -0.015860583633184433,\n",
       " 0.005013542715460062,\n",
       " -0.1094951331615448,\n",
       " 0.03158048912882805,\n",
       " 0.129938542842865,\n",
       " 0.06225423514842987,\n",
       " 0.0596298985183239,\n",
       " -0.010895008221268654,\n",
       " 0.04514491930603981,\n",
       " 0.029110023751854897,\n",
       " 0.006442241836339235,\n",
       " 0.014589093625545502,\n",
       " -0.020311059430241585,\n",
       " -0.07316505163908005,\n",
       " -0.010771682485938072,\n",
       " -0.0013697915710508823,\n",
       " 0.004280601628124714,\n",
       " 0.03440452367067337,\n",
       " -0.0382724367082119,\n",
       " -0.09565497189760208,\n",
       " 0.08402137458324432,\n",
       " 0.0008564451709389687,\n",
       " -0.0693507120013237,\n",
       " 0.09305378794670105,\n",
       " -0.035104554146528244,\n",
       " 0.03603536635637283,\n",
       " 0.07073073834180832,\n",
       " 0.0019175794441252947,\n",
       " 0.0368557944893837,\n",
       " -0.012808534316718578,\n",
       " 0.043291762471199036,\n",
       " -0.008459714241325855,\n",
       " 0.02607104741036892,\n",
       " 0.037902846932411194,\n",
       " -0.033274006098508835,\n",
       " -0.04586319625377655,\n",
       " 0.015422811731696129,\n",
       " 0.047682490199804306,\n",
       " -0.010341893881559372,\n",
       " -0.07590299099683762,\n",
       " -0.0808224231004715,\n",
       " 0.06813427805900574,\n",
       " 0.060506608337163925,\n",
       " 0.04950595647096634,\n",
       " -0.04682282358407974,\n",
       " 0.033982571214437485,\n",
       " 0.012938559986650944,\n",
       " -0.02878730557858944,\n",
       " -0.05362052842974663,\n",
       " 0.012455018237233162,\n",
       " 0.010357111692428589,\n",
       " -0.016825633123517036,\n",
       " 0.036963462829589844,\n",
       " -0.07517268508672714,\n",
       " 0.07789289951324463,\n",
       " -0.013982071541249752,\n",
       " -0.009158912114799023,\n",
       " -0.09512851387262344,\n",
       " 0.00014882245159242302,\n",
       " -0.0024204517249017954,\n",
       " -0.04422726109623909,\n",
       " -0.00988694466650486,\n",
       " -0.010889238677918911,\n",
       " -0.02365458570420742,\n",
       " 0.052680853754282,\n",
       " 0.018602123484015465,\n",
       " 0.006772628054022789,\n",
       " 0.07363905757665634,\n",
       " -0.03388948366045952,\n",
       " 0.009932029992341995,\n",
       " -0.09001472592353821,\n",
       " 0.007727428805083036,\n",
       " -0.10574044287204742,\n",
       " -0.04389616474509239,\n",
       " 7.344835466938093e-05,\n",
       " -0.059364281594753265,\n",
       " -0.06091487780213356,\n",
       " 0.0182455163449049,\n",
       " 0.1113847866654396,\n",
       " -0.05460811406373978,\n",
       " -0.12097349017858505,\n",
       " 0.006349892355501652,\n",
       " -0.005144110415130854,\n",
       " -0.025126207619905472,\n",
       " 0.013773166574537754,\n",
       " 0.0051599242724478245,\n",
       " 0.0676192045211792,\n",
       " 0.030118148773908615,\n",
       " -0.027715766802430153,\n",
       " 0.045996010303497314,\n",
       " 0.020213115960359573,\n",
       " -0.02140338532626629,\n",
       " -0.04148397222161293,\n",
       " -0.0165084321051836,\n",
       " -0.04350021854043007,\n",
       " -0.09766452014446259,\n",
       " -0.004414520226418972,\n",
       " 0.05372603237628937,\n",
       " -0.04519640654325485,\n",
       " -0.010715062730014324,\n",
       " 0.017300309613347054,\n",
       " 0.04004277288913727,\n",
       " -0.15120641887187958,\n",
       " -0.06833503395318985,\n",
       " -0.034377798438072205,\n",
       " -0.0920364037156105,\n",
       " 0.028462756425142288,\n",
       " -0.005395294167101383,\n",
       " -0.12597592175006866,\n",
       " -0.0831131637096405,\n",
       " -0.018928540870547295,\n",
       " -0.011717403307557106,\n",
       " 0.022372029721736908,\n",
       " 0.059820301830768585,\n",
       " 0.027847206220030785,\n",
       " -0.0356871597468853,\n",
       " 0.028357846662402153,\n",
       " -0.026403797790408134,\n",
       " 0.026535343378782272,\n",
       " 0.030816441401839256,\n",
       " 0.0016880237963050604,\n",
       " 0.048530977219343185,\n",
       " -0.00729057751595974,\n",
       " -0.07295476645231247,\n",
       " 0.0228095892816782,\n",
       " -1.4989050809926503e-33,\n",
       " -0.002053705044090748,\n",
       " -0.023130793124437332,\n",
       " 0.0043545872904360294,\n",
       " 0.041944194585084915,\n",
       " -0.03302137553691864,\n",
       " 0.045031242072582245,\n",
       " -0.029122842475771904,\n",
       " -0.03883810341358185,\n",
       " 0.0074901282787323,\n",
       " 0.007875647395849228,\n",
       " -0.01466044969856739,\n",
       " -0.027290616184473038,\n",
       " 0.011614063754677773,\n",
       " 0.015302080661058426,\n",
       " 0.04523731395602226,\n",
       " 0.06025964766740799,\n",
       " 0.019775094464421272,\n",
       " 0.05904320254921913,\n",
       " -0.008832519873976707,\n",
       " 0.03096998669207096,\n",
       " 0.02770099975168705,\n",
       " 0.0811021476984024,\n",
       " -4.103963510715403e-05,\n",
       " 0.04703504592180252,\n",
       " 0.09693404287099838,\n",
       " -0.06191568076610565,\n",
       " -0.0326412171125412,\n",
       " 0.0002298783656442538,\n",
       " 0.0019914796575903893,\n",
       " -0.021174095571041107,\n",
       " 0.0334300622344017,\n",
       " -0.009940831921994686,\n",
       " 0.013989667408168316,\n",
       " -0.017154153436422348,\n",
       " -0.023446284234523773,\n",
       " -0.05024974048137665,\n",
       " -0.06253630667924881,\n",
       " 0.02047593891620636,\n",
       " 0.017242440953850746,\n",
       " 0.0748857781291008,\n",
       " 0.0280702356249094,\n",
       " -0.14454825222492218,\n",
       " 0.0388350673019886,\n",
       " -0.02272535115480423,\n",
       " 0.08452623337507248,\n",
       " -0.0077982316724956036,\n",
       " 0.017007119953632355,\n",
       " 0.024939686059951782,\n",
       " -0.027763046324253082,\n",
       " 0.004712135065346956,\n",
       " 0.029863091185688972,\n",
       " 0.0001547038264106959,\n",
       " -0.0970032587647438,\n",
       " 0.052525702863931656,\n",
       " -0.06972101330757141,\n",
       " 0.022218625992536545,\n",
       " 0.0032330534886568785,\n",
       " 0.02904476784169674,\n",
       " -0.03654913604259491,\n",
       " -0.048423826694488525,\n",
       " 0.08449361473321915,\n",
       " -0.05238202586770058,\n",
       " -0.01728757470846176,\n",
       " -0.07322301715612411,\n",
       " -0.01908617466688156,\n",
       " -0.06700985878705978,\n",
       " -0.016854405403137207,\n",
       " 0.07001365721225739,\n",
       " 0.061988674104213715,\n",
       " 0.10572538524866104,\n",
       " -0.08609765022993088,\n",
       " -0.025041023269295692,\n",
       " -0.00048410831368528306,\n",
       " 0.016091108322143555,\n",
       " 0.04416152089834213,\n",
       " 0.0053532663732767105,\n",
       " -0.10888461768627167,\n",
       " 0.06443897634744644,\n",
       " -0.034196190536022186,\n",
       " 0.02513621374964714,\n",
       " -0.15650007128715515,\n",
       " 0.06769514083862305,\n",
       " 0.07920530438423157,\n",
       " 0.036950573325157166,\n",
       " 0.0774369016289711,\n",
       " 0.06563736498355865,\n",
       " 0.045028965920209885,\n",
       " -0.03523685410618782,\n",
       " -0.008663435466587543,\n",
       " 0.0319519080221653,\n",
       " -0.05382264032959938,\n",
       " -0.05302673205733299,\n",
       " 0.03837542608380318,\n",
       " -0.009366851300001144,\n",
       " 0.0014855839544907212,\n",
       " -2.1175788699254553e-33,\n",
       " 0.026266641914844513,\n",
       " -0.07094887644052505,\n",
       " 0.0030513491947203875,\n",
       " 0.0296782199293375,\n",
       " 0.03389505669474602,\n",
       " 0.030801108106970787,\n",
       " -0.023624978959560394,\n",
       " 0.06513913720846176,\n",
       " -0.02308734878897667,\n",
       " 0.07498923689126968,\n",
       " 0.03436633571982384,\n",
       " -0.11941052228212357,\n",
       " 0.015331924892961979,\n",
       " -0.00789610669016838,\n",
       " -0.03222087398171425,\n",
       " 0.06830326467752457,\n",
       " 0.08588527888059616,\n",
       " 0.06231341138482094,\n",
       " -0.12720948457717896,\n",
       " 0.010071178898215294,\n",
       " -0.07721156626939774,\n",
       " -0.03171708434820175,\n",
       " 0.10597372055053711,\n",
       " 0.044698815792798996,\n",
       " -0.015419593080878258,\n",
       " -0.03854780271649361,\n",
       " 0.2139633148908615,\n",
       " -0.025892410427331924,\n",
       " -0.06918323040008545,\n",
       " -0.00259325560182333,\n",
       " -0.04722808301448822,\n",
       " -0.01702364720404148,\n",
       " -0.010134225711226463,\n",
       " 0.04629659652709961,\n",
       " 0.04937504231929779,\n",
       " 0.06449726969003677,\n",
       " 0.04602694511413574,\n",
       " -0.05634206905961037,\n",
       " -0.09691647440195084,\n",
       " 0.06940815597772598,\n",
       " 0.026777690276503563,\n",
       " 0.014957407489418983,\n",
       " 0.07131637632846832,\n",
       " 0.054472990334033966,\n",
       " -0.03582911193370819,\n",
       " -0.03767115995287895,\n",
       " -0.08263158798217773,\n",
       " -0.017015617340803146,\n",
       " -0.019613349810242653,\n",
       " -0.0034519960172474384,\n",
       " 0.07660997658967972,\n",
       " 0.04051337018609047,\n",
       " 0.02601807191967964,\n",
       " 0.004082298371940851,\n",
       " 0.05701204016804695,\n",
       " -0.042675405740737915,\n",
       " -0.04850199073553085,\n",
       " -0.009654390625655651,\n",
       " -0.01746586710214615,\n",
       " 0.016100648790597916,\n",
       " 0.000661527446936816,\n",
       " 0.0015448867343366146,\n",
       " 0.024678584188222885,\n",
       " 0.0087581817060709,\n",
       " 0.041229087859392166,\n",
       " -0.01995791122317314,\n",
       " -0.003220157464966178,\n",
       " 0.07850311696529388,\n",
       " 0.09130316972732544,\n",
       " 0.004639959428459406,\n",
       " 0.045198190957307816,\n",
       " -0.042829643934965134,\n",
       " -0.0286965724080801,\n",
       " 0.04045451804995537,\n",
       " -0.11026746779680252,\n",
       " 0.002079840749502182,\n",
       " -0.07886746525764465,\n",
       " 0.0746837854385376,\n",
       " 0.07986291497945786,\n",
       " 0.00692157493904233,\n",
       " -0.034964390099048615,\n",
       " -0.04939227178692818,\n",
       " -0.08002515882253647,\n",
       " 0.010579697787761688,\n",
       " -0.040151599794626236,\n",
       " -0.054234862327575684,\n",
       " -0.014318746514618397,\n",
       " 0.0035244182217866182,\n",
       " 0.043218739330768585,\n",
       " -0.025028439238667488,\n",
       " 0.0035129343159496784,\n",
       " 0.04622014984488487,\n",
       " 0.029924940317869186,\n",
       " -0.033506061881780624,\n",
       " -0.022486452013254166,\n",
       " -1.7040175492866183e-08,\n",
       " -0.0027520458679646254,\n",
       " -0.056670449674129486,\n",
       " -0.006947371643036604,\n",
       " 0.06101946532726288,\n",
       " 0.030558019876480103,\n",
       " -0.05713840574026108,\n",
       " -0.06494638323783875,\n",
       " -0.09674781560897827,\n",
       " -0.08721838146448135,\n",
       " -0.027866166085004807,\n",
       " 0.03504612296819687,\n",
       " -0.038393717259168625,\n",
       " -0.011944539844989777,\n",
       " -0.03169640526175499,\n",
       " -0.020204022526741028,\n",
       " 0.019767140969634056,\n",
       " -0.051133107393980026,\n",
       " 0.01706053502857685,\n",
       " 0.02144356071949005,\n",
       " -0.04863046854734421,\n",
       " -0.026764871552586555,\n",
       " -0.035159289836883545,\n",
       " -0.06830703467130661,\n",
       " -0.035374198108911514,\n",
       " 0.009294470772147179,\n",
       " 0.047939278185367584,\n",
       " -0.031004048883914948,\n",
       " -0.0650535300374031,\n",
       " 0.039548538625240326,\n",
       " -0.03344609588384628,\n",
       " 0.09146932512521744,\n",
       " 0.02729489840567112,\n",
       " -0.041555602103471756,\n",
       " -0.04624241963028908,\n",
       " -0.06604723632335663,\n",
       " 0.003470334690064192,\n",
       " 0.09551594406366348,\n",
       " -0.008733469061553478,\n",
       " 0.008631568402051926,\n",
       " -0.020616192370653152,\n",
       " 0.04330074042081833,\n",
       " 0.023163584992289543,\n",
       " 0.053526826202869415,\n",
       " 0.007641925010830164,\n",
       " -0.03915105387568474,\n",
       " 0.052071359008550644,\n",
       " -0.03152847662568092,\n",
       " -0.025171078741550446,\n",
       " -0.03134620562195778,\n",
       " -0.013103735633194447,\n",
       " -0.013286538422107697,\n",
       " 0.11154834181070328,\n",
       " 0.02755890227854252,\n",
       " 0.0660889595746994,\n",
       " -0.04255474731326103,\n",
       " 0.07659520953893661,\n",
       " 0.04829579219222069,\n",
       " -0.0028914399445056915,\n",
       " -0.0699043869972229,\n",
       " -0.016335170716047287,\n",
       " 0.04015929251909256,\n",
       " 0.02513209916651249,\n",
       " 0.04828906059265137,\n",
       " 0.007448209449648857]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a196f643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f1af3e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2532815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7e4b63e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "pinecone_api_key = PINECONE_API_KEY\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f9596c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.pinecone.Pinecone at 0x29978795d80>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cf411efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pinecone import ServerlessSpec\n",
    "\n",
    "# index_name = \"medical_bot\"\n",
    "\n",
    "# if not pc.has_index(index_name):\n",
    "#     pc.create_index(name=index_name, dimension=384, metric=\"cosine\", spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"))\n",
    "\n",
    "# index = pc.Index(index_name)\n",
    "\n",
    "from pinecone import ServerlessSpec \n",
    "\n",
    "index_name = \"chatbot\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name = index_name,\n",
    "        dimension=384,  # Dimension of the embeddings\n",
    "        metric= \"cosine\",  # Cosine similarity\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c2625664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents = texts_chunks,\n",
    "    embedding=embedding,\n",
    "    index_name = index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b26dda25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1410c7c8-0a2d-4d11-b2e8-820edf660eca']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# это если векторный поиск уже есть и нужно добавить дополнительно чтото\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embedding\n",
    ")\n",
    "\n",
    "# создается документ который будет добавлен в индекс\n",
    "dswith = Document(\n",
    "    page_content=\"В число ансамблевых методов машинного обучения входят: беггинг, стекинг, градиентный бустинг\",\n",
    "    metadata={\"source\": \"книга\"}\n",
    ")\n",
    "\n",
    "# добавляем в индекс\n",
    "docsearch.add_documents(documents=[dswith])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "17af8e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "70f94e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\romoc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='736cae2d-39b2-407c-b1e1-1427e378d452', metadata={'source': 'data\\\\book3.pdf'}, page_content='присутствует только пара признаков. Это тоже может дать представление о количестве \\nкластеров. Однако такой подход страдает субъективностью, подвержен ошибкам и счи-\\nтается обоснованным предположением, а не научным методом.'),\n",
       " Document(id='314964f2-7143-410a-a0c8-4ae3fba7cc67', metadata={'source': 'data\\\\book3.pdf'}, page_content='методов. Существуют также специализированные библиотеки настроек гиперпа-'),\n",
       " Document(id='07da4f0e-1c0b-4efd-9f6e-e17097fdc5eb', metadata={'source': 'data\\\\book3.pdf'}, page_content='преобразования меток в числа. Например, некоторые алгоритмы требуют исполь-'),\n",
       " Document(id='ceaf012a-7634-45ef-9b72-96b0b9eaf826', metadata={'source': 'data\\\\book3.pdf'}, page_content='дач этого конкретного типа градиентный спуск не требуется. Однако линейная регрессия \\nявляется идеальным примером для объяснения градиентного спуска.'),\n",
       " Document(id='5eca7341-2000-4203-9889-c9add52aa792', metadata={'source': 'data\\\\book3.pdf'}, page_content='нейронные сети в главе 6.')]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_docs = retriever.invoke(\"что такое субъект?\")\n",
    "retriever_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "115f6dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "chatModel = OllamaLLM(model=\"llama3.1:8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc20610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_ollama import OllamaLLM\n",
    "\n",
    "# chatModel = OllamaLLM(model=\"llama3.1:8b\")\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# chatModel = ChatOpenAI(model = \"gpt-4o\")\n",
    "\n",
    "# chatModel = ChatOpenAI(\n",
    "#     model='deepseek-chat',\n",
    "#     openai_api_key=\"\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "81eab484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55eaabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt = (\n",
    "#     \"You are an Medical assistant for question-answering tasks. \"\n",
    "#     \"Use the following pieces of retrieved context to answer \"\n",
    "#     \"the question. If you don't know the answer, say that you \"\n",
    "#     \"don't know. Use three sentences maximum and keep the \"\n",
    "#     \"answer concise.\"\n",
    "#     \"\\n\\n\"\n",
    "#     \"{context}\"\n",
    "# )\n",
    "system_prompt = (\n",
    "    \"Ты русский помощник по машинному обучению.\"\n",
    "    \"Используй следующие части извлеченного контекста, чтобы ответить \"\n",
    "    \"на вопрос. Если ты не знаешь ответ - скажи, что ты не знаешь ответ.\"\n",
    "    # \"Используйте максимум три предложения и сохраните \"\n",
    "    # \"ответ кратким.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c351260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(chatModel, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ecc473cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\romoc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Регуляризация - это важнейший аспект машинного обучения! Итак, давайте разберемся в этом:\n",
      "\n",
      "Регуляризация - это техника, которая добавляет штраф к весам моделей при оптимизации. Это помогает избежать переобучения модели (overfitting) и улучшить ее генерализацию на новых неувязанных данных.\n",
      "\n",
      "Всего существует несколько видов регуляризаций:\n",
      "\n",
      "1. **L1-регуляризация** ( Least Absolute Shrinkage and Selection Operator): добавляет штраф в виде абсолютного значения веса. Это приводит к тому, что некоторые веса уменьшаются до нуля.\n",
      "2. **L2-регуляризация** ( Ridge Regression ): добавляет штраф в виде квадрата веса. Это приводит к тому, что все веса уменьшаются, но не доходят до нуля.\n",
      "3. **L1+L2-регуляризация**: сочетание L1 и L2 регуляризаций. Это дает возможность выбирать между двумя типами штрафов для разных весов.\n",
      "4. **Dropout-регуляризация**: случайное отключение нейронов в сети при каждой итерации обучения. Это помогает избежать переобучения, но может привести к некоторому уменьшению точности.\n",
      "\n",
      "Регуляризация также можно использовать для выбора лучших весов среди множества возможных решений. Например, L1-регуляризация может отбросить некоторые неважные признаки, а L2-регуляризация может привести к более простой модели с меньшим количеством параметров.\n",
      "\n",
      "Это основные виды регуляризаций, но существуют и другие, такие как elastic net, group lasso и т. д. Каждый из них имеет свои преимущества и недостатки, и выбор вида регуляризации зависит от конкретной задачи машинного обучения.\n",
      "\n",
      "И что касается библиотек настроек гиперпараметров, то есть множество вариантов:\n",
      "\n",
      "* scikit-learn (Python)\n",
      "* TensorFlow (Python)\n",
      "* Keras (Python)\n",
      "* PyTorch (Python)\n",
      "* LightGBM (Python и R)\n",
      "* XGBoost (Python)\n",
      "\n",
      "В каждой из этих библиотек можно настроить гиперпараметры с помощью различных алгоритмов и методов.\n",
      "\n",
      "Если у тебя есть конкретные вопросы по регуляризации или настройкам гиперпараметров, я буду рад помочь!\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"расскажи про регуляризацию, какие виды бывают\"})\n",
    "\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54c9f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
